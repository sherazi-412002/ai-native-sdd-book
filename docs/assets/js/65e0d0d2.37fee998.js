"use strict";(globalThis.webpackChunkclassic=globalThis.webpackChunkclassic||[]).push([[8313],{4927(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-1/nodes-topics-services","title":"Nodes, Topics, and Services: The Nervous System of Autonomous Humanoid Robots","description":"Introduction to ROS 2 Fundamentals","source":"@site/docs/module-1/nodes-topics-services.md","sourceDirName":"module-1","slug":"/module-1/nodes-topics-services","permalink":"/ai-native-sdd-book/docs/module-1/nodes-topics-services","draft":false,"unlisted":false,"editUrl":"https://github.com/sherazi-412002/ai-native-sdd-book/tree/main/docs/module-1/nodes-topics-services.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"curriculumSidebar","previous":{"title":"Module 1: The Robotic Nervous System (ROS 2)","permalink":"/ai-native-sdd-book/docs/category/module-1-the-robotic-nervous-system-ros-2"},"next":{"title":"rclpy Bridging: Python Integration for Autonomous Humanoid Robotics","permalink":"/ai-native-sdd-book/docs/module-1/rclpy-bridging"}}');var o=t(4848),s=t(8453);const a={sidebar_position:1},r="Nodes, Topics, and Services: The Nervous System of Autonomous Humanoid Robots",l={},c=[{value:"Introduction to ROS 2 Fundamentals",id:"introduction-to-ros-2-fundamentals",level:2},{value:"Theoretical Foundation of ROS 2 Architecture",id:"theoretical-foundation-of-ros-2-architecture",level:2},{value:"Distributed Computing Principles",id:"distributed-computing-principles",level:3},{value:"Middleware Architecture",id:"middleware-architecture",level:3},{value:"Quality of Service (QoS) Policies",id:"quality-of-service-qos-policies",level:3},{value:"Nodes: The Building Blocks of ROS 2",id:"nodes-the-building-blocks-of-ros-2",level:2},{value:"Advanced Node Creation with Parameters and Callbacks",id:"advanced-node-creation-with-parameters-and-callbacks",level:3},{value:"Topics: Asynchronous Communication in ROS 2",id:"topics-asynchronous-communication-in-ros-2",level:2},{value:"Topic Communication Characteristics",id:"topic-communication-characteristics",level:3},{value:"Advanced Topic Usage with Custom Message Types",id:"advanced-topic-usage-with-custom-message-types",level:3},{value:"Services: Synchronous Communication in ROS 2",id:"services-synchronous-communication-in-ros-2",level:2},{value:"Service Definition and Implementation",id:"service-definition-and-implementation",level:3},{value:"Advanced System Architecture for Humanoid Robotics",id:"advanced-system-architecture-for-humanoid-robotics",level:2},{value:"ROS 2 Communication Architecture",id:"ros-2-communication-architecture",level:3},{value:"Advanced ROS 2 Middleware Configuration",id:"advanced-ros-2-middleware-configuration",level:3},{value:"Real-Time Performance Considerations",id:"real-time-performance-considerations",level:3},{value:"1. Memory Management",id:"1-memory-management",level:4},{value:"2. Thread Configuration for Real-Time Priority",id:"2-thread-configuration-for-real-time-priority",level:4},{value:"3. Deterministic Message Processing",id:"3-deterministic-message-processing",level:4},{value:"Advanced Communication Patterns for Humanoid Robotics",id:"advanced-communication-patterns-for-humanoid-robotics",level:3},{value:"NVIDIA Isaac Sim Integration for Humanoid Robotics",id:"nvidia-isaac-sim-integration-for-humanoid-robotics",level:2},{value:"Isaac Sim Configuration Parameters",id:"isaac-sim-configuration-parameters",level:3},{value:"Advanced Communication Patterns for Humanoid Robotics",id:"advanced-communication-patterns-for-humanoid-robotics-1",level:2},{value:"Summary",id:"summary",level:2}];function m(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"nodes-topics-and-services-the-nervous-system-of-autonomous-humanoid-robots",children:"Nodes, Topics, and Services: The Nervous System of Autonomous Humanoid Robots"})}),"\n",(0,o.jsx)(n.h2,{id:"introduction-to-ros-2-fundamentals",children:"Introduction to ROS 2 Fundamentals"}),"\n",(0,o.jsx)(n.p,{children:"ROS 2 (Robot Operating System 2) serves as the fundamental communication and coordination framework for autonomous humanoid robots. This distributed computing framework enables complex robotic systems to be built from modular, reusable components that communicate through standardized interfaces. The architecture of ROS 2 is designed to support real-time performance, distributed computing, and fault tolerance - all critical requirements for humanoid robotics applications."}),"\n",(0,o.jsx)(n.p,{children:"ROS 2 implements a data-centric publish-subscribe model where nodes communicate through topics, services, and actions. This architecture enables the development of complex humanoid robots with multiple subsystems (locomotion, perception, planning, control) that can operate independently while maintaining tight coordination through the ROS 2 middleware. The system uses Data Distribution Service (DDS) as its underlying communication layer, providing reliable message delivery, quality of service (QoS) controls, and real-time performance guarantees essential for humanoid robot control."}),"\n",(0,o.jsx)(n.h2,{id:"theoretical-foundation-of-ros-2-architecture",children:"Theoretical Foundation of ROS 2 Architecture"}),"\n",(0,o.jsx)(n.p,{children:"The ROS 2 architecture is built upon several key theoretical concepts that make it particularly suitable for humanoid robotics applications:"}),"\n",(0,o.jsx)(n.h3,{id:"distributed-computing-principles",children:"Distributed Computing Principles"}),"\n",(0,o.jsx)(n.p,{children:"ROS 2 implements a peer-to-peer distributed computing model where each node operates as an independent process. This architecture provides several advantages for humanoid robotics:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Fault Isolation"}),": Individual node failures do not bring down the entire system"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Scalability"}),": New capabilities can be added without modifying existing nodes"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Language Interoperability"}),": Nodes can be written in different programming languages (C++, Python, etc.)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Resource Management"}),": Individual nodes can be allocated specific computational resources"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"middleware-architecture",children:"Middleware Architecture"}),"\n",(0,o.jsx)(n.p,{children:"The middleware layer in ROS 2 provides several critical services:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Discovery"}),": Automatic detection of available nodes and services"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Transport"}),": Reliable message delivery with configurable QoS policies"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Serialization"}),": Efficient conversion of data structures to network format"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Security"}),": Authentication, encryption, and access control mechanisms"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"quality-of-service-qos-policies",children:"Quality of Service (QoS) Policies"}),"\n",(0,o.jsx)(n.p,{children:"QoS policies in ROS 2 allow fine-tuning of communication behavior based on application requirements. For humanoid robots, these policies are crucial for ensuring real-time performance:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Reliability"}),": Ensuring message delivery (reliable vs best-effort)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Durability"}),": Persistence of messages for late-joining subscribers (transient_local vs volatile)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"History"}),": Number of messages to retain (keep_last vs keep_all)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Deadline"}),": Maximum time between consecutive messages"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Liveliness"}),": Detection of active publishers/subscribers"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"nodes-the-building-blocks-of-ros-2",children:"Nodes: The Building Blocks of ROS 2"}),"\n",(0,o.jsx)(n.p,{children:"Nodes represent the fundamental execution units in ROS 2. They encapsulate specific functionality and communicate with other nodes through topics, services, and actions. In humanoid robotics, nodes typically correspond to specific subsystems such as:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Sensor processing nodes (IMU, cameras, LiDAR)"}),"\n",(0,o.jsx)(n.li,{children:"Control nodes (joint controllers, trajectory planners)"}),"\n",(0,o.jsx)(n.li,{children:"Perception nodes (object detection, SLAM)"}),"\n",(0,o.jsx)(n.li,{children:"Planning nodes (motion planning, path planning)"}),"\n",(0,o.jsx)(n.li,{children:"Communication nodes (network interfaces, data logging)"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"advanced-node-creation-with-parameters-and-callbacks",children:"Advanced Node Creation with Parameters and Callbacks"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom rclpy.qos import QoSProfile, ReliabilityPolicy, DurabilityPolicy\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import JointState\nfrom geometry_msgs.msg import Twist\nfrom builtin_interfaces.msg import Time\nimport numpy as np\nimport threading\nimport time\nfrom collections import deque\n\nclass AdvancedHumanoidNode(Node):\n    \"\"\"\n    Advanced Humanoid Node demonstrating complex ROS 2 patterns for humanoid robotics.\n    This node implements multiple communication patterns and real-time processing capabilities.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('advanced_humanoid_node')\n\n        # Initialize parameters with default values\n        self.declare_parameter('control_frequency', 100)  # Hz\n        self.declare_parameter('robot_name', 'autonomous_humanoid')\n        self.declare_parameter('safety_timeout', 1.0)    # seconds\n        self.declare_parameter('max_velocity', 1.0)      # m/s\n\n        # Get parameter values\n        self.control_frequency = self.get_parameter('control_frequency').value\n        self.robot_name = self.get_parameter('robot_name').value\n        self.safety_timeout = self.get_parameter('safety_timeout').value\n        self.max_velocity = self.get_parameter('max_velocity').value\n\n        # Create QoS profiles for different types of communication\n        self.qos_sensor = QoSProfile(\n            depth=10,\n            reliability=ReliabilityPolicy.RELIABLE,\n            durability=DurabilityPolicy.VOLATILE\n        )\n\n        self.qos_control = QoSProfile(\n            depth=1,\n            reliability=ReliabilityPolicy.RELIABLE,\n            durability=DurabilityPolicy.VOLATILE\n        )\n\n        # Publishers for different types of data\n        self.cmd_vel_publisher = self.create_publisher(\n            Twist,\n            f'/{self.robot_name}/cmd_vel',\n            self.qos_control\n        )\n\n        self.joint_state_publisher = self.create_publisher(\n            JointState,\n            f'/{self.robot_name}/joint_states',\n            self.qos_sensor\n        )\n\n        self.status_publisher = self.create_publisher(\n            String,\n            f'/{self.robot_name}/status',\n            10\n        )\n\n        # Subscribers for sensor data and commands\n        self.cmd_vel_subscriber = self.create_subscription(\n            Twist,\n            f'/{self.robot_name}/cmd_vel_input',\n            self.cmd_vel_callback,\n            self.qos_control\n        )\n\n        # Timer for control loop\n        self.control_timer = self.create_timer(\n            1.0 / self.control_frequency,\n            self.control_loop\n        )\n\n        # Data structures for state management\n        self.current_cmd_vel = Twist()\n        self.joint_positions = {}\n        self.joint_velocities = {}\n        self.joint_efforts = {}\n        self.last_command_time = self.get_clock().now()\n\n        # Initialize joint state\n        self.initialize_joint_state()\n\n        self.get_logger().info(\n            f'Advanced Humanoid Node initialized for {self.robot_name} '\n            f'with control frequency {self.control_frequency}Hz'\n        )\n\n    def initialize_joint_state(self):\n        \"\"\"Initialize joint state with default values for humanoid robot.\"\"\"\n        # Humanoid robot joint names\n        joint_names = [\n            'left_hip_joint', 'left_knee_joint', 'left_ankle_joint',\n            'right_hip_joint', 'right_knee_joint', 'right_ankle_joint',\n            'left_shoulder_joint', 'left_elbow_joint', 'left_wrist_joint',\n            'right_shoulder_joint', 'right_elbow_joint', 'right_wrist_joint',\n            'head_yaw_joint', 'head_pitch_joint'\n        ]\n\n        # Initialize all joints to zero position\n        for joint_name in joint_names:\n            self.joint_positions[joint_name] = 0.0\n            self.joint_velocities[joint_name] = 0.0\n            self.joint_efforts[joint_name] = 0.0\n\n    def cmd_vel_callback(self, msg):\n        \"\"\"Callback for velocity commands.\"\"\"\n        self.current_cmd_vel = msg\n        self.last_command_time = self.get_clock().now()\n        self.get_logger().debug(f'Received velocity command: {msg}')\n\n    def control_loop(self):\n        \"\"\"Main control loop executing at specified frequency.\"\"\"\n        current_time = self.get_clock().now()\n\n        # Check for command timeout\n        time_since_last_cmd = (current_time - self.last_command_time).nanoseconds / 1e9\n        if time_since_last_cmd > self.safety_timeout:\n            # Stop the robot if no command received within timeout\n            self.current_cmd_vel.linear.x = 0.0\n            self.current_cmd_vel.angular.z = 0.0\n\n        # Process control logic here\n        self.process_control_logic()\n\n        # Publish joint states\n        self.publish_joint_states()\n\n        # Publish status\n        status_msg = String()\n        status_msg.data = f'Operating normally - Last command: {time_since_last_cmd:.2f}s ago'\n        self.status_publisher.publish(status_msg)\n\n    def process_control_logic(self):\n        \"\"\"Implement humanoid-specific control logic.\"\"\"\n        # Example: Simple velocity limiting\n        if abs(self.current_cmd_vel.linear.x) > self.max_velocity:\n            self.current_cmd_vel.linear.x = np.sign(self.current_cmd_vel.linear.x) * self.max_velocity\n\n        # Example: Update joint positions based on velocity commands\n        # This is a simplified example - real humanoid control would be much more complex\n        for joint_name in self.joint_positions:\n            # Apply some basic joint movement based on velocity command\n            # In a real implementation, this would involve inverse kinematics,\n            # dynamics calculations, and safety checks\n            self.joint_positions[joint_name] += 0.001  # Small increment for demonstration\n\n    def publish_joint_states(self):\n        \"\"\"Publish current joint states.\"\"\"\n        msg = JointState()\n        msg.header.stamp = self.get_clock().now().to_msg()\n        msg.name = list(self.joint_positions.keys())\n        msg.position = list(self.joint_positions.values())\n        msg.velocity = list(self.joint_velocities.values())\n        msg.effort = list(self.joint_efforts.values())\n\n        self.joint_state_publisher.publish(msg)\n\n    def get_joint_position(self, joint_name):\n        \"\"\"Get position of a specific joint.\"\"\"\n        return self.joint_positions.get(joint_name, 0.0)\n\n    def set_joint_position(self, joint_name, position):\n        \"\"\"Set position of a specific joint.\"\"\"\n        if joint_name in self.joint_positions:\n            self.joint_positions[joint_name] = position\n        else:\n            self.get_logger().warn(f'Joint {joint_name} not found in joint state')\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    node = AdvancedHumanoidNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info('Interrupted by user')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(n.h2,{id:"topics-asynchronous-communication-in-ros-2",children:"Topics: Asynchronous Communication in ROS 2"}),"\n",(0,o.jsx)(n.p,{children:"Topics form the backbone of ROS 2's publish-subscribe communication model. This asynchronous communication pattern is particularly well-suited for humanoid robotics where multiple sensors and actuators need to operate simultaneously without blocking each other."}),"\n",(0,o.jsx)(n.h3,{id:"topic-communication-characteristics",children:"Topic Communication Characteristics"}),"\n",(0,o.jsx)(n.p,{children:"Topics in ROS 2 have several key characteristics that make them ideal for humanoid robotics:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Many-to-Many"}),": Multiple publishers can send to the same topic, and multiple subscribers can receive from the same topic"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Asynchronous"}),": Publishers and subscribers operate independently - no direct coupling"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Real-time Capable"}),": With appropriate QoS settings, topics can provide real-time performance"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Language Agnostic"}),": Publishers and subscribers can be written in different languages"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"advanced-topic-usage-with-custom-message-types",children:"Advanced Topic Usage with Custom Message Types"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-cpp",children:'// Example C++ node demonstrating advanced topic usage for humanoid robotics\n#include <rclcpp/rclcpp.hpp>\n#include <std_msgs/msg/string.hpp>\n#include <sensor_msgs/msg/joint_state.hpp>\n#include <geometry_msgs/msg/twist.hpp>\n#include <nav_msgs/msg/odometry.hpp>\n#include <tf2_msgs/msg/tf_message.hpp>\n#include <message_filters/subscriber.h>\n#include <message_filters/time_synchronizer.h>\n#include <chrono>\n#include <memory>\n#include <vector>\n#include <string>\n#include <map>\n\nclass HumanoidSensorFusionNode : public rclcpp::Node\n{\npublic:\n    HumanoidSensorFusionNode() : Node("humanoid_sensor_fusion_node")\n    {\n        RCLCPP_INFO(this->get_logger(), "Initializing Humanoid Sensor Fusion Node");\n\n        // Create publishers for fused sensor data\n        sensor_fusion_publisher_ = this->create_publisher<std_msgs::msg::String>(\n            "/autonomous_humanoid/sensor_fusion", 10);\n\n        // Create subscribers for various sensor data\n        imu_subscriber_ = this->create_subscription<sensor_msgs::msg::Imu>(\n            "/autonomous_humanoid/imu/data", 10,\n            std::bind(&HumanoidSensorFusionNode::imu_callback, this, std::placeholders::_1));\n\n        joint_state_subscriber_ = this->create_subscription<sensor_msgs::msg::JointState>(\n            "/autonomous_humanoid/joint_states", 10,\n            std::bind(&HumanoidSensorFusionNode::joint_state_callback, this, std::placeholders::_1));\n\n        // Timer for processing loop\n        timer_ = this->create_wall_timer(\n            std::chrono::milliseconds(10), // 100Hz processing\n            std::bind(&HumanoidSensorFusionNode::process_sensor_data, this));\n\n        // Initialize sensor data structures\n        initialize_sensor_data();\n    }\n\nprivate:\n    void initialize_sensor_data()\n    {\n        // Initialize data structures for sensor fusion\n        for (int i = 0; i < 12; ++i) { // Assuming 12 joints for humanoid\n            joint_positions_.push_back(0.0);\n            joint_velocities_.push_back(0.0);\n            joint_efforts_.push_back(0.0);\n        }\n\n        // Initialize IMU data\n        imu_orientation_.w = 1.0;\n        imu_orientation_.x = 0.0;\n        imu_orientation_.y = 0.0;\n        imu_orientation_.z = 0.0;\n\n        for (int i = 0; i < 3; ++i) {\n            imu_angular_velocity_[i] = 0.0;\n            imu_linear_acceleration_[i] = 0.0;\n        }\n    }\n\n    void imu_callback(const sensor_msgs::msg::Imu::SharedPtr msg)\n    {\n        // Store IMU data for fusion\n        imu_orientation_ = msg->orientation;\n        imu_angular_velocity_[0] = msg->angular_velocity.x;\n        imu_angular_velocity_[1] = msg->angular_velocity.y;\n        imu_angular_velocity_[2] = msg->angular_velocity.z;\n        imu_linear_acceleration_[0] = msg->linear_acceleration.x;\n        imu_linear_acceleration_[1] = msg->linear_acceleration.y;\n        imu_linear_acceleration_[2] = msg->linear_acceleration.z;\n\n        last_imu_time_ = this->get_clock()->now();\n    }\n\n    void joint_state_callback(const sensor_msgs::msg::JointState::SharedPtr msg)\n    {\n        // Store joint state data for fusion\n        for (size_t i = 0; i < msg->position.size(); ++i) {\n            if (i < joint_positions_.size()) {\n                joint_positions_[i] = msg->position[i];\n            }\n        }\n\n        for (size_t i = 0; i < msg->velocity.size(); ++i) {\n            if (i < joint_velocities_.size()) {\n                joint_velocities_[i] = msg->velocity[i];\n            }\n        }\n\n        for (size_t i = 0; i < msg->effort.size(); ++i) {\n            if (i < joint_efforts_.size()) {\n                joint_efforts_[i] = msg->effort[i];\n            }\n        }\n\n        last_joint_time_ = this->get_clock()->now();\n    }\n\n    void process_sensor_data()\n    {\n        // Perform sensor fusion calculations\n        auto current_time = this->get_clock()->now();\n\n        // Example: Calculate balance state based on IMU and joint data\n        double balance_state = calculate_balance_state();\n\n        // Example: Detect potential falls based on sensor data\n        bool potential_fall = detect_potential_fall();\n\n        // Create and publish fused sensor data\n        auto fusion_msg = std_msgs::msg::String();\n        fusion_msg.data = "Balance State: " + std::to_string(balance_state) +\n                         ", Potential Fall: " + (potential_fall ? "YES" : "NO");\n\n        sensor_fusion_publisher_->publish(fusion_msg);\n\n        RCLCPP_DEBUG(this->get_logger(), "Published sensor fusion data: %s", fusion_msg.data.c_str());\n    }\n\n    double calculate_balance_state()\n    {\n        // Simplified balance calculation - in real implementation would use\n        // more sophisticated algorithms like ZMP (Zero Moment Point) or\n        // whole-body control approaches\n        double pitch = 2 * asin(imu_orientation_.y); // Simplified pitch calculation\n        double roll = 2 * asin(imu_orientation_.x);  // Simplified roll calculation\n\n        // Combine with joint position data for balance estimate\n        double balance_score = 0.7 * abs(pitch) + 0.3 * abs(roll);\n\n        return balance_score;\n    }\n\n    bool detect_potential_fall()\n    {\n        // Simple fall detection based on IMU data\n        double linear_acceleration_magnitude =\n            sqrt(pow(imu_linear_acceleration_[0], 2) +\n                 pow(imu_linear_acceleration_[1], 2) +\n                 pow(imu_linear_acceleration_[2], 2));\n\n        // Check if acceleration is outside normal bounds (indicating impact)\n        if (linear_acceleration_magnitude > 20.0) { // 20 m/s^2 threshold\n            return true;\n        }\n\n        // Check if orientation is too extreme\n        double pitch = 2 * asin(imu_orientation_.y);\n        if (abs(pitch) > 1.0) { // 57 degrees threshold\n            return true;\n        }\n\n        return false;\n    }\n\n    // Publishers\n    rclcpp::Publisher<std_msgs::msg::String>::SharedPtr sensor_fusion_publisher_;\n\n    // Subscribers\n    rclcpp::Subscription<sensor_msgs::msg::Imu>::SharedPtr imu_subscriber_;\n    rclcpp::Subscription<sensor_msgs::msg::JointState>::SharedPtr joint_state_subscriber_;\n\n    // Timer\n    rclcpp::TimerBase::SharedPtr timer_;\n\n    // Sensor data storage\n    std::vector<double> joint_positions_;\n    std::vector<double> joint_velocities_;\n    std::vector<double> joint_efforts_;\n    geometry_msgs::msg::Quaternion imu_orientation_;\n    double imu_angular_velocity_[3];\n    double imu_linear_acceleration_[3];\n\n    // Timestamps\n    rclcpp::Time last_imu_time_;\n    rclcpp::Time last_joint_time_;\n};\n\nint main(int argc, char * argv[])\n{\n    rclcpp::init(argc, argv);\n    rclcpp::spin(std::make_shared<HumanoidSensorFusionNode>());\n    rclcpp::shutdown();\n    return 0;\n}\n'})}),"\n",(0,o.jsx)(n.h2,{id:"services-synchronous-communication-in-ros-2",children:"Services: Synchronous Communication in ROS 2"}),"\n",(0,o.jsx)(n.p,{children:"Services provide synchronous request-response communication in ROS 2, which is essential for humanoid robotics when immediate responses are required. Unlike topics which are asynchronous, services guarantee that a response will be received before the calling process continues."}),"\n",(0,o.jsx)(n.h3,{id:"service-definition-and-implementation",children:"Service Definition and Implementation"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# Example service definition (would be in srv/ directory)\n# HumanoidControl.srv\n# float64[] joint_positions\n# float64[] joint_velocities\n# float64[] joint_efforts\n# ---\n# bool success\n# string message\n# float64 execution_time\n\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.qos import QoSProfile\nfrom example_interfaces.srv import Trigger, SetBool\nfrom std_srvs.srv import Empty\nfrom builtin_interfaces.msg import Time\nimport time\nimport threading\nfrom collections import deque\n\nclass HumanoidServiceNode(Node):\n    \"\"\"\n    Humanoid Service Node demonstrating various service patterns for humanoid robotics.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('humanoid_service_node')\n\n        # Create services for different humanoid operations\n        self.calibrate_service = self.create_service(\n            Trigger,\n            'calibrate_humanoid',\n            self.calibrate_callback\n        )\n\n        self.emergency_stop_service = self.create_service(\n            Trigger,\n            'emergency_stop',\n            self.emergency_stop_callback\n        )\n\n        self.reset_position_service = self.create_service(\n            Empty,\n            'reset_position',\n            self.reset_position_callback\n        )\n\n        self.enable_motors_service = self.create_service(\n            SetBool,\n            'enable_motors',\n            self.enable_motors_callback\n        )\n\n        # Store service state\n        self.motors_enabled = False\n        self.calibration_state = False\n        self.emergency_stop_active = False\n\n        self.get_logger().info('Humanoid Service Node initialized with multiple services')\n\n    def calibrate_callback(self, request, response):\n        \"\"\"Calibrate all humanoid joints.\"\"\"\n        self.get_logger().info('Starting calibration procedure')\n\n        try:\n            # Simulate calibration process\n            self.emergency_stop_active = True  # Stop all movement during calibration\n\n            # Perform calibration steps\n            self.get_logger().info('Calibrating joint positions...')\n            time.sleep(2)  # Simulate calibration time\n\n            self.get_logger().info('Calibrating sensors...')\n            time.sleep(1)  # Simulate sensor calibration\n\n            # Update calibration state\n            self.calibration_state = True\n\n            # Re-enable movement after calibration\n            self.emergency_stop_active = False\n\n            response.success = True\n            response.message = 'Calibration completed successfully'\n\n            self.get_logger().info('Calibration completed successfully')\n\n        except Exception as e:\n            response.success = False\n            response.message = f'Calibration failed: {str(e)}'\n            self.get_logger().error(f'Calibration error: {str(e)}')\n\n        return response\n\n    def emergency_stop_callback(self, request, response):\n        \"\"\"Activate emergency stop.\"\"\"\n        self.get_logger().warn('EMERGENCY STOP ACTIVATED')\n\n        try:\n            # Stop all motor movements immediately\n            self.emergency_stop_active = True\n\n            # Log the emergency stop\n            self.get_logger().info('All motors stopped due to emergency stop')\n\n            response.success = True\n            response.message = 'Emergency stop activated'\n\n        except Exception as e:\n            response.success = False\n            response.message = f'Emergency stop failed: {str(e)}'\n            self.get_logger().error(f'Emergency stop error: {str(e)}')\n\n        return response\n\n    def reset_position_callback(self, request, response):\n        \"\"\"Reset humanoid to default position.\"\"\"\n        self.get_logger().info('Resetting humanoid to default position')\n\n        try:\n            # Check if motors are enabled\n            if not self.motors_enabled:\n                raise Exception('Motors not enabled - cannot reset position')\n\n            # Check if emergency stop is active\n            if self.emergency_stop_active:\n                raise Exception('Emergency stop active - cannot reset position')\n\n            # Move to default position (simplified example)\n            default_positions = [0.0] * 12  # 12 joints\n            self.move_to_position(default_positions)\n\n            response.success = True\n            response.message = 'Position reset completed'\n\n            self.get_logger().info('Position reset completed successfully')\n\n        except Exception as e:\n            response.success = False\n            response.message = f'Position reset failed: {str(e)}'\n            self.get_logger().error(f'Position reset error: {str(e)}')\n\n        return response\n\n    def enable_motors_callback(self, request, response):\n        \"\"\"Enable or disable motors.\"\"\"\n        enable = request.data\n        self.get_logger().info(f'{\"Enabling\" if enable else \"Disabling\"} motors')\n\n        try:\n            if enable:\n                # Perform safety checks before enabling\n                if self.emergency_stop_active:\n                    raise Exception('Cannot enable motors while emergency stop is active')\n\n                # Enable motors (simulated)\n                self.motors_enabled = True\n                response.success = True\n                response.message = 'Motors enabled successfully'\n\n                self.get_logger().info('Motors enabled')\n            else:\n                # Disable motors\n                self.motors_enabled = False\n                response.success = True\n                response.message = 'Motors disabled successfully'\n\n                self.get_logger().info('Motors disabled')\n\n        except Exception as e:\n            response.success = False\n            response.message = f'Motor control failed: {str(e)}'\n            self.get_logger().error(f'Motor control error: {str(e)}')\n\n        return response\n\n    def move_to_position(self, positions):\n        \"\"\"Move joints to specified positions (simplified implementation).\"\"\"\n        # This would interface with actual motor controllers in a real implementation\n        self.get_logger().debug(f'Moving to positions: {positions}')\n        time.sleep(0.1)  # Simulate movement time\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    node = HumanoidServiceNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info('Interrupted by user')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(n.h2,{id:"advanced-system-architecture-for-humanoid-robotics",children:"Advanced System Architecture for Humanoid Robotics"}),"\n",(0,o.jsx)(n.h3,{id:"ros-2-communication-architecture",children:"ROS 2 Communication Architecture"}),"\n",(0,o.jsx)(n.p,{children:"The following Mermaid.js diagram illustrates the comprehensive communication architecture for an autonomous humanoid robot using ROS 2:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-mermaid",children:'graph TB\n    subgraph "Humanoid Robot Control System"\n        Perception[Perception Stack<br/>Vision, LiDAR, IMU, Proprioception]\n        Planning[Planning Stack<br/>Motion, Path, Trajectory Planning]\n        Control[Control Stack<br/>Joint Control, Balance, Whole-Body Control]\n        Navigation[Navigation Stack<br/>SLAM, Localization, Path Following]\n        Sensing[Sensor Stack<br/>Joint Encoders, Force Sensors, Cameras]\n        Actuation[Actuator Stack<br/>Servo Drivers, Motor Controllers]\n        Safety[SAFETY SYSTEMS<br/>Emergency Stop, Collision Prevention]\n    end\n\n    subgraph "AI & Intelligence Layer"\n        Reasoning[Reasoning Engine<br/>Logic, Planning, Decision Making]\n        Learning[Learning Engine<br/>RL, Imitation, Online Adaptation]\n        PerceptionAI[AI Perception<br/>Object Detection, Scene Understanding]\n    end\n\n    subgraph "External Systems"\n        Remote[Remote Control<br/>Teleoperation, Commands]\n        Monitoring[Monitoring<br/>Logging, Diagnostics, Telemetry]\n        Cloud[Cloud Services<br/>AI Training, Data Analytics, OTA Updates]\n    end\n\n    subgraph "Communication Protocols"\n        DDS[(DDS/RTPS<br/>Data Distribution Service)]\n        TCP[TCP/IP<br/>Reliable Communication]\n        UDP[UDP<br/>Real-time Streaming]\n        SHM[Shared Memory<br/>Intra-process]\n    end\n\n    %% Core Data Flow\n    Sensing --\x3e Perception\n    Perception --\x3e PerceptionAI\n    Perception --\x3e Planning\n    Planning --\x3e Control\n    Control --\x3e Actuation\n    Navigation --\x3e Planning\n    Safety --\x3e Control\n\n    %% AI Integration\n    PerceptionAI --\x3e Reasoning\n    Learning --\x3e Control\n    Reasoning --\x3e Planning\n\n    %% External Interfaces\n    Remote --\x3e Planning\n    Remote --\x3e Control\n    Monitoring --\x3e All Stacks\n    Cloud --\x3e Learning\n    Cloud --\x3e Reasoning\n\n    %% Communication Protocols\n    DDS -.-> Perception\n    DDS -.-> Planning\n    TCP -.-> Monitoring\n    UDP -.-> Remote\n    SHM -.-> Control\n\n    %% Safety Critical Path\n    Safety ==> Control\n    Control ==> Safety\n\n    style Perception fill:#e1f5fe,stroke:#0277bd,stroke-width:2px\n    style Planning fill:#e8f5e8,stroke:#388e3c,stroke-width:2px\n    style Control fill:#fff3e0,stroke:#f57c00,stroke-width:2px\n    style Navigation fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    style Sensing fill:#e0f2f1,stroke:#00695c,stroke-width:2px\n    style Actuation fill:#ffebee,stroke:#d32f2f,stroke-width:2px\n    style Safety fill:#ffcdd2,stroke:#c62828,stroke-width:3px\n    style Reasoning fill:#e1bee7,stroke:#7b1fa2,stroke-width:2px\n    style Learning fill:#d1c4e9,stroke:#5e35b1,stroke-width:2px\n    style PerceptionAI fill:#c5e1a5,stroke:#558b2f,stroke-width:2px\n    style DDS fill:#b2ebf2,stroke:#006064,stroke-width:1px\n    style TCP fill:#b39ddb,stroke:#4527a0,stroke-width:1px\n    style UDP fill:#a5d6a7,stroke:#33691e,stroke-width:1px\n    style SHM fill:#ffcc80,stroke:#ef6c00,stroke-width:1px\n'})}),"\n",(0,o.jsx)(n.h3,{id:"advanced-ros-2-middleware-configuration",children:"Advanced ROS 2 Middleware Configuration"}),"\n",(0,o.jsx)(n.p,{children:"For humanoid robotics applications, the ROS 2 middleware configuration plays a critical role in ensuring real-time performance and reliable communication. Here's an example of a production-ready configuration:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-cpp",children:'#include <rclcpp/rclcpp.hpp>\n#include <rmw/qos_profiles.h>\n#include <rmw/types.h>\n#include <dds/dds.h>\n\nclass HumanoidMiddlewareConfig {\npublic:\n    static rclcpp::QoS getCriticalControlQoS() {\n        // Ultra-low latency, high-reliability profile for critical control\n        return rclcpp::QoS(\n            rclcpp::KeepLast(1))  // Minimal history to reduce latency\n            .reliability(RMW_QOS_POLICY_RELIABILITY_RELIABLE)\n            .durability(RMW_QOS_POLICY_DURABILITY_VOLATILE)\n            .deadline(rclcpp::Duration(10000000))  // 10ms deadline\n            .liveliness(RMW_QOS_POLICY_LIVELINESS_AUTOMATIC)\n            .avoid_ros_namespace_conventions(false);\n    }\n\n    static rclcpp::QoS getSensorDataQoS() {\n        // High-frequency sensor data with best-effort delivery\n        return rclcpp::QoS(\n            rclcpp::KeepLast(10))  // Keep recent samples\n            .reliability(RMW_QOS_POLICY_RELIABILITY_BEST_EFFORT)\n            .durability(RMW_QOS_POLICY_DURABILITY_VOLATILE)\n            .lifespan(rclcpp::Duration(50000000))  // 50ms lifespan\n            .avoid_ros_namespace_conventions(false);\n    }\n\n    static rclcpp::QoS getDiagnosticQoS() {\n        // Diagnostic data with transient-local durability\n        return rclcpp::QoS(\n            rclcpp::KeepLast(5))  // Keep last 5 samples\n            .reliability(RMW_QOS_POLICY_RELIABILITY_RELIABLE)\n            .durability(RMW_QOS_POLICY_DURABILITY_TRANSIENT_LOCAL)\n            .avoid_ros_namespace_conventions(false);\n    }\n\n    // Advanced DDS configuration for real-time performance\n    static dds::core::QosPolicy::Partition getPartitionConfig() {\n        dds::core::QosPolicy::Partition partition;\n\n        // Separate partitions for different subsystems\n        std::vector<std::string> partitions = {\n            "control_critical",      // Critical control commands\n            "sensing",              // Sensor data streams\n            "planning",             // Planning and trajectory data\n            "diagnostics",          // System health monitoring\n            "ai_intelligence"       // AI/ML inference results\n        };\n\n        partition = dds::core::QosPolicy::Partition(partitions);\n        return partition;\n    }\n\n    // Transport configuration for optimal performance\n    static dds::core::policy::TransportPriority getTransportPriority(uint8_t priority = 7) {\n        // Higher priority for critical control messages\n        return dds::core::policy::TransportPriority(priority);\n    }\n};\n\n// Example usage in a critical control node\nclass JointControllerNode : public rclcpp::Node {\npublic:\n    JointControllerNode() : Node("joint_controller_node") {\n        // Create publishers with appropriate QoS for different data types\n\n        // Critical joint commands with ultra-low latency\n        joint_cmd_publisher_ = this->create_publisher<sensor_msgs::msg::JointState>(\n            "/autonomous_humanoid/joint_commands",\n            HumanoidMiddlewareConfig::getCriticalControlQoS()\n        );\n\n        // Joint state feedback with sensor-appropriate QoS\n        joint_state_publisher_ = this->create_publisher<sensor_msgs::msg::JointState>(\n            "/autonomous_humanoid/joint_states",\n            HumanoidMiddlewareConfig::getSensorDataQoS()\n        );\n\n        // Diagnostic information\n        diagnostic_publisher_ = this->create_publisher<diagnostic_msgs::msg::DiagnosticArray>(\n            "/autonomous_humanoid/diagnostics",\n            HumanoidMiddlewareConfig::getDiagnosticQoS()\n        );\n\n        // Control timer for real-time control loop\n        control_timer_ = this->create_wall_timer(\n            std::chrono::microseconds(1000), // 1kHz control loop\n            std::bind(&JointControllerNode::controlLoop, this)\n        );\n    }\n\nprivate:\n    void controlLoop() {\n        // Real-time control logic with guaranteed timing\n        auto start_time = std::chrono::high_resolution_clock::now();\n\n        // Critical control computations\n        performCriticalControlCalculations();\n\n        // Publish joint commands\n        publishJointCommands();\n\n        // Check timing constraints\n        auto end_time = std::chrono::high_resolution_clock::now();\n        auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);\n\n        if (duration.count() > 1000) { // Exceeded 1ms budget\n            RCLCPP_WARN(this->get_logger(),\n                "Control loop exceeded timing budget: %ld microseconds",\n                duration.count());\n        }\n    }\n\n    rclcpp::Publisher<sensor_msgs::msg::JointState>::SharedPtr joint_cmd_publisher_;\n    rclcpp::Publisher<sensor_msgs::msg::JointState>::SharedPtr joint_state_publisher_;\n    rclcpp::Publisher<diagnostic_msgs::msg::DiagnosticArray>::SharedPtr diagnostic_publisher_;\n    rclcpp::TimerBase::SharedPtr control_timer_;\n};\n'})}),"\n",(0,o.jsx)(n.h3,{id:"real-time-performance-considerations",children:"Real-Time Performance Considerations"}),"\n",(0,o.jsx)(n.p,{children:"For humanoid robotics applications, real-time performance is critical. The following considerations ensure deterministic behavior:"}),"\n",(0,o.jsx)(n.h4,{id:"1-memory-management",children:"1. Memory Management"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-cpp",children:"// Custom allocator for real-time safety\ntemplate<typename T>\nclass RealTimeAllocator {\npublic:\n    using value_type = T;\n\n    RealTimeAllocator() noexcept {}\n    template<typename U> RealTimeAllocator(const RealTimeAllocator<U>&) noexcept {}\n\n    T* allocate(std::size_t n) {\n        // Pre-allocated memory pool to avoid dynamic allocation during control loops\n        static thread_local std::array<T, 1024> memory_pool;\n        static thread_local size_t offset = 0;\n\n        if (offset + n > memory_pool.size()) {\n            throw std::bad_alloc();\n        }\n\n        T* ptr = &memory_pool[offset];\n        offset += n;\n        return ptr;\n    }\n\n    void deallocate(T* p, std::size_t n) noexcept {\n        // No-op for memory pool - deallocation happens automatically\n    }\n};\n"})}),"\n",(0,o.jsx)(n.h4,{id:"2-thread-configuration-for-real-time-priority",children:"2. Thread Configuration for Real-Time Priority"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-cpp",children:'#include <pthread.h>\n#include <sched.h>\n\nclass RealTimeThreadManager {\npublic:\n    static bool configureThreadForRealTime(pthread_t thread, int priority = 80) {\n        struct sched_param param;\n        param.sched_priority = priority;  // RT priority (1-99)\n\n        int result = pthread_setschedparam(thread, SCHED_FIFO, &param);\n        if (result != 0) {\n            RCLCPP_ERROR(rclcpp::get_logger("realtime_manager"),\n                "Failed to set real-time priority: %d", result);\n            return false;\n        }\n\n        // Lock memory pages to prevent page faults during real-time execution\n        if (mlockall(MCL_CURRENT | MCL_FUTURE) == -1) {\n            RCLCPP_WARN(rclcpp::get_logger("realtime_manager"),\n                "Failed to lock memory pages for real-time execution");\n        }\n\n        return true;\n    }\n};\n'})}),"\n",(0,o.jsx)(n.h4,{id:"3-deterministic-message-processing",children:"3. Deterministic Message Processing"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom rclpy.qos import QoSProfile, DurabilityPolicy, ReliabilityPolicy\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import JointState\nimport time\nfrom collections import deque\nimport threading\n\nclass DeterministicMessageProcessor(Node):\n    \"\"\"\n    Implements deterministic message processing for humanoid robotics applications.\n    Ensures bounded execution time and predictable message handling.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('deterministic_message_processor')\n\n        # Configuration parameters\n        self.declare_parameter('max_queue_size', 10)\n        self.declare_parameter('max_processing_time_ms', 5)\n        self.declare_parameter('enable_statistics', True)\n\n        self.max_queue_size = self.get_parameter('max_queue_size').value\n        self.max_processing_time_ms = self.get_parameter('max_processing_time_ms').value\n        self.enable_statistics = self.get_parameter('enable_statistics').value\n\n        # Message queues with bounded size\n        self.joint_state_queue = deque(maxlen=self.max_queue_size)\n        self.command_queue = deque(maxlen=self.max_queue_size)\n\n        # Statistics\n        self.stats_lock = threading.Lock()\n        self.processing_times = deque(maxlen=100)\n        self.dropped_messages = 0\n        self.processed_messages = 0\n\n        # Subscribers\n        self.joint_state_sub = self.create_subscription(\n            JointState,\n            '/autonomous_humanoid/joint_states',\n            self.joint_state_callback,\n            self.create_qos_profile()\n        )\n\n        self.cmd_sub = self.create_subscription(\n            JointState,\n            '/autonomous_humanoid/joint_commands',\n            self.command_callback,\n            self.create_qos_profile()\n        )\n\n        # Processing timer\n        self.process_timer = self.create_timer(\n            0.001,  # 1kHz processing rate\n            self.process_messages\n        )\n\n        self.get_logger().info(\n            f'Initialized deterministic message processor with queue size {self.max_queue_size} '\n            f'and max processing time {self.max_processing_time_ms}ms'\n        )\n\n    def create_qos_profile(self):\n        \"\"\"Create appropriate QoS profile for deterministic processing.\"\"\"\n        return QoSProfile(\n            depth=1,\n            reliability=ReliabilityPolicy.RELIABLE,\n            durability=DurabilityPolicy.VOLATILE\n        )\n\n    def joint_state_callback(self, msg):\n        \"\"\"Non-blocking message callback that adds to processing queue.\"\"\"\n        try:\n            self.joint_state_queue.append({\n                'timestamp': time.time(),\n                'message': msg,\n                'seq_num': getattr(msg, 'header', {}).get('seq', 0) if hasattr(msg, 'header') else 0\n            })\n        except IndexError:\n            # Queue full, message dropped\n            with self.stats_lock:\n                self.dropped_messages += 1\n\n    def command_callback(self, msg):\n        \"\"\"Non-blocking command callback.\"\"\"\n        try:\n            self.command_queue.append({\n                'timestamp': time.time(),\n                'message': msg,\n                'seq_num': getattr(msg, 'header', {}).get('seq', 0) if hasattr(msg, 'header') else 0\n            })\n        except IndexError:\n            with self.stats_lock:\n                self.dropped_messages += 1\n\n    def process_messages(self):\n        \"\"\"Deterministic message processing with bounded execution time.\"\"\"\n        start_time = time.perf_counter()\n\n        # Process joint states\n        while self.joint_state_queue:\n            if self._exceeds_processing_budget(start_time):\n                break\n\n            try:\n                msg_data = self.joint_state_queue.popleft()\n                self._process_joint_state(msg_data['message'])\n\n                with self.stats_lock:\n                    self.processed_messages += 1\n            except IndexError:\n                break  # Queue became empty\n\n        # Process commands\n        while self.command_queue:\n            if self._exceeds_processing_budget(start_time):\n                break\n\n            try:\n                msg_data = self.command_queue.popleft()\n                self._process_command(msg_data['message'])\n\n                with self.stats_lock:\n                    self.processed_messages += 1\n            except IndexError:\n                break  # Queue became empty\n\n        # Record processing time statistics\n        if self.enable_statistics:\n            end_time = time.perf_counter()\n            processing_time_ms = (end_time - start_time) * 1000\n            with self.stats_lock:\n                self.processing_times.append(processing_time_ms)\n\n    def _exceeds_processing_budget(self, start_time):\n        \"\"\"Check if processing time exceeds budget.\"\"\"\n        current_time = time.perf_counter()\n        elapsed_ms = (current_time - start_time) * 1000\n        return elapsed_ms >= self.max_processing_time_ms\n\n    def _process_joint_state(self, msg):\n        \"\"\"Process joint state message with bounded execution time.\"\"\"\n        # Implement joint state processing logic here\n        # This should be a fast, deterministic operation\n        pass\n\n    def _process_command(self, msg):\n        \"\"\"Process command message with bounded execution time.\"\"\"\n        # Implement command processing logic here\n        # This should be a fast, deterministic operation\n        pass\n\n    def get_processing_statistics(self):\n        \"\"\"Get processing statistics for performance monitoring.\"\"\"\n        with self.stats_lock:\n            if self.processing_times:\n                avg_time = sum(self.processing_times) / len(self.processing_times)\n                max_time = max(self.processing_times)\n                min_time = min(self.processing_times)\n            else:\n                avg_time = max_time = min_time = 0.0\n\n            stats = {\n                'processed_messages': self.processed_messages,\n                'dropped_messages': self.dropped_messages,\n                'avg_processing_time_ms': avg_time,\n                'max_processing_time_ms': max_time,\n                'min_processing_time_ms': min_time,\n                'queue_utilization': len(self.joint_state_queue) / self.max_queue_size\n            }\n\n            return stats\n"})}),"\n",(0,o.jsx)(n.h3,{id:"advanced-communication-patterns-for-humanoid-robotics",children:"Advanced Communication Patterns for Humanoid Robotics"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robots require sophisticated communication patterns to coordinate their complex subsystems. Here's an example of a state machine implementation with real-time safety considerations:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from enum import Enum\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional, Callable\nimport time\nimport threading\nfrom collections import deque\nimport numpy as np\n\nclass HumanoidState(Enum):\n    """Enumeration of possible humanoid states with safety considerations."""\n    IDLE = "idle"\n    WALKING = "walking"\n    STANDING = "standing"\n    BALANCING = "balancing"\n    CALIBRATING = "calibrating"\n    EMERGENCY_STOP = "emergency_stop"\n    RECOVERY = "recovery"\n    SAFETY_LOCKOUT = "safety_lockout"\n\n@dataclass\nclass StateTransition:\n    """Represents a state transition with safety conditions."""\n    from_state: HumanoidState\n    to_state: HumanoidState\n    condition: str\n    action: str\n    safety_check: Callable[[], bool]  # Safety function that must return True\n\nclass HumanoidStateMachine:\n    """\n    Real-time safe state machine for managing humanoid robot behavior.\n    Implements safety checks and bounded execution time for all operations.\n    """\n\n    def __init__(self, node):\n        self.node = node\n        self.current_state = HumanoidState.IDLE\n        self.previous_state = HumanoidState.IDLE\n        self.state_lock = threading.RLock()  # Recursive lock for state operations\n        self.state_entry_time = time.time()\n\n        # Initialize transition rules with safety functions\n        self.transitions = [\n            StateTransition(\n                HumanoidState.IDLE, HumanoidState.WALKING,\n                "walking_command_received", "start_walking_sequence",\n                lambda: self._is_safe_to_walk()\n            ),\n            StateTransition(\n                HumanoidState.WALKING, HumanoidState.STANDING,\n                "stop_command_received", "execute_stop_sequence",\n                lambda: True  # Standing is always safe\n            ),\n            StateTransition(\n                HumanoidState.WALKING, HumanoidState.BALANCING,\n                "imbalance_detected", "activate_balance_control",\n                lambda: self._is_safe_to_balance()\n            ),\n            StateTransition(\n                HumanoidState.BALANCING, HumanoidState.STANDING,\n                "balance_restored", "return_to_standing",\n                lambda: self._is_safe_to_stand()\n            ),\n            StateTransition(\n                HumanoidState.IDLE, HumanoidState.CALIBRATING,\n                "calibrate_command", "execute_calibration",\n                lambda: self._is_safe_to_calibrate()\n            ),\n            StateTransition(\n                HumanoidState.WALKING, HumanoidState.EMERGENCY_STOP,\n                "emergency_stop_triggered", "execute_emergency_stop",\n                lambda: True  # Emergency stop is always allowed\n            ),\n            StateTransition(\n                HumanoidState.EMERGENCY_STOP, HumanoidState.SAFETY_LOCKOUT,\n                "manual_override_required", "activate_safety_lockout",\n                lambda: True  # Safety lockout is always safe\n            ),\n            StateTransition(\n                HumanoidState.SAFETY_LOCKOUT, HumanoidState.RECOVERY,\n                "safety_clear_manual", "execute_recovery_sequence",\n                lambda: self._is_safe_to_recover()\n            ),\n            StateTransition(\n                HumanoidState.RECOVERY, HumanoidState.STANDING,\n                "recovery_complete", "stand_up_sequence",\n                lambda: self._is_safe_to_stand()\n            )\n        ]\n\n        # Initialize sensor data with bounded buffers\n        self.sensor_data = {\n            \'imu_orientation\': deque(maxlen=10),\n            \'imu_angular_velocity\': deque(maxlen=10),\n            \'imu_linear_acceleration\': deque(maxlen=10),\n            \'joint_positions\': {},\n            \'joint_velocities\': {},\n            \'joint_efforts\': {},\n            \'force_sensors\': deque(maxlen=10),\n            \'contact_sensors\': deque(maxlen=10)\n        }\n\n        # Command buffers with bounded size\n        self.command_buffers = {\n            \'walking_commands\': deque(maxlen=5),\n            \'balance_commands\': deque(maxlen=5),\n            \'safety_commands\': deque(maxlen=10)\n        }\n\n        # Safety monitoring\n        self.safety_monitoring_active = True\n        self.emergency_stop_active = False\n        self.safety_violations = 0\n\n        # Performance monitoring\n        self.state_transition_times = deque(maxlen=50)\n\n        self.node.get_logger().info(\n            f\'Humanoid State Machine initialized in {self.current_state.value} state with safety monitoring\'\n        )\n\n    def update_sensor_data(self, sensor_msg):\n        """Update internal sensor data with bounded execution time."""\n        start_time = time.time()\n\n        with self.state_lock:\n            # Add timestamped sensor data to appropriate buffers\n            timestamp = time.time()\n\n            if hasattr(sensor_msg, \'orientation\'):\n                # IMU data\n                self.sensor_data[\'imu_orientation\'].append({\n                    \'data\': [\n                        sensor_msg.orientation.x,\n                        sensor_msg.orientation.y,\n                        sensor_msg.orientation.z,\n                        sensor_msg.orientation.w\n                    ],\n                    \'timestamp\': timestamp\n                })\n\n                self.sensor_data[\'imu_angular_velocity\'].append({\n                    \'data\': [\n                        sensor_msg.angular_velocity.x,\n                        sensor_msg.angular_velocity.y,\n                        sensor_msg.angular_velocity.z\n                    ],\n                    \'timestamp\': timestamp\n                })\n\n                self.sensor_data[\'imu_linear_acceleration\'].append({\n                    \'data\': [\n                        sensor_msg.linear_acceleration.x,\n                        sensor_msg.linear_acceleration.y,\n                        sensor_msg.linear_acceleration.z\n                    ],\n                    \'timestamp\': timestamp\n                })\n\n            # Bounded execution time check\n            if time.time() - start_time > 0.001:  # 1ms budget\n                self.node.get_logger().warn(\'Sensor data update exceeded time budget\')\n\n    def update_commands(self, cmd_type: str, value, max_age_seconds: float = 1.0):\n        """Update command buffers with age-based filtering."""\n        with self.state_lock:\n            timestamp = time.time()\n\n            # Clean old commands based on age\n            if cmd_type in self.command_buffers:\n                # Remove commands older than max_age_seconds\n                current_buffer = self.command_buffers[cmd_type]\n                filtered_buffer = deque(maxlen=current_buffer.maxlen)\n\n                for cmd in current_buffer:\n                    if timestamp - cmd[\'timestamp\'] <= max_age_seconds:\n                        filtered_buffer.append(cmd)\n\n                self.command_buffers[cmd_type] = filtered_buffer\n\n                # Add new command\n                self.command_buffers[cmd_type].append({\n                    \'data\': value,\n                    \'timestamp\': timestamp\n                })\n\n    def evaluate_conditions(self) -> Dict[str, bool]:\n        """Evaluate all transition conditions with bounded execution time."""\n        start_time = time.time()\n        conditions = {}\n\n        # Check balance condition (bounded execution)\n        pitch, roll = self._get_balance_state()\n        conditions[\'imbalance_detected\'] = abs(pitch) > 0.5 or abs(roll) > 0.5\n        conditions[\'balance_restored\'] = abs(pitch) < 0.2 and abs(roll) < 0.2\n\n        # Check command conditions (bounded execution)\n        conditions[\'walking_command_received\'] = self._has_recent_command(\'walking_commands\')\n        conditions[\'stop_command_received\'] = self._has_recent_command(\'walking_commands\', check_stop=True)\n        conditions[\'calibrate_command\'] = self._has_recent_command(\'safety_commands\', check_calibrate=True)\n        conditions[\'emergency_stop_triggered\'] = self.emergency_stop_active\n        conditions[\'manual_override_required\'] = self._needs_manual_override()\n        conditions[\'safety_clear_manual\'] = self._is_safety_cleared_manually()\n        conditions[\'recovery_complete\'] = self._is_recovery_complete()\n\n        # Time budget check\n        if time.time() - start_time > 0.002:  # 2ms budget\n            self.node.get_logger().warn(\'Condition evaluation exceeded time budget\')\n\n        return conditions\n\n    def _get_balance_state(self) -> tuple:\n        """Get current balance state (pitch, roll) with bounded execution."""\n        # Extract latest IMU data\n        if self.sensor_data[\'imu_orientation\']:\n            latest_orientation = self.sensor_data[\'imu_orientation\'][-1][\'data\']\n            # Convert quaternion to Euler angles (simplified for performance)\n            x, y, z, w = latest_orientation\n\n            # Calculate pitch and roll (simplified approximation)\n            pitch = 2 * np.arcsin(y) if abs(y) < 0.999 else np.sign(y) * np.pi/2\n            roll = 2 * np.arcsin(x) if abs(x) < 0.999 else np.sign(x) * np.pi/2\n\n            return pitch, roll\n        else:\n            return 0.0, 0.0\n\n    def _has_recent_command(self, buffer_name: str, check_stop: bool = False, check_calibrate: bool = False) -> bool:\n        """Check if there are recent commands in the specified buffer."""\n        if buffer_name not in self.command_buffers:\n            return False\n\n        buffer = self.command_buffers[buffer_name]\n        if not buffer:\n            return False\n\n        # Check latest command timestamp (within 100ms)\n        latest_cmd = buffer[-1]\n        return time.time() - latest_cmd[\'timestamp\'] <= 0.1\n\n    def _needs_manual_override(self) -> bool:\n        """Check if manual override is needed."""\n        return self.safety_violations > 3  # Require manual intervention after 3 violations\n\n    def _is_safety_cleared_manually(self) -> bool:\n        """Check if safety has been cleared manually."""\n        # In real implementation, this would check for manual safety clear command\n        return False  # Placeholder\n\n    def _is_recovery_complete(self) -> bool:\n        """Check if recovery sequence is complete."""\n        # In real implementation, this would check for recovery completion\n        return True  # Placeholder\n\n    def transition_to_state(self, new_state: HumanoidState) -> bool:\n        """Safely transition to a new state with safety checks."""\n        with self.state_lock:\n            # Find transition rule\n            transition_rule = None\n            for transition in self.transitions:\n                if (transition.from_state == self.current_state and\n                    transition.to_state == new_state):\n                    transition_rule = transition\n                    break\n\n            if not transition_rule:\n                self.node.get_logger().warn(\n                    f\'Invalid transition from {self.current_state.value} to {new_state.value}\'\n                )\n                return False\n\n            # Check safety condition\n            if not transition_rule.safety_check():\n                self.node.get_logger().error(\n                    f\'Safety check failed for transition to {new_state.value}: {transition_rule.condition}\'\n                )\n                self.safety_violations += 1\n                return False\n\n            # Perform transition\n            old_state = self.current_state\n            start_time = time.time()\n\n            self.previous_state = old_state\n            self.current_state = new_state\n            self.state_entry_time = time.time()\n\n            # Execute state-specific action\n            self._execute_state_action(new_state)\n\n            # Record transition time\n            transition_time = time.time() - start_time\n            self.state_transition_times.append(transition_time)\n\n            self.node.get_logger().info(\n                f\'Safe state transition: {old_state.value} -> {new_state.value} \'\n                f\'(time: {transition_time*1000:.2f}ms)\'\n            )\n\n            return True\n\n    def _execute_state_action(self, state: HumanoidState):\n        """Execute actions specific to the current state."""\n        start_time = time.time()\n\n        if state == HumanoidState.WALKING:\n            self.node.get_logger().info(\'Executing walking sequence with safety monitoring\')\n            # Implement walking control logic with safety checks\n        elif state == HumanoidState.STANDING:\n            self.node.get_logger().info(\'Executing standing sequence with balance maintenance\')\n            # Implement standing control logic\n        elif state == HumanoidState.BALANCING:\n            self.node.get_logger().info(\'Executing balance control with active stabilization\')\n            # Implement balance control logic\n        elif state == HumanoidState.CALIBRATING:\n            self.node.get_logger().info(\'Executing calibration sequence with motion freeze\')\n            # Implement calibration logic\n        elif state == HumanoidState.EMERGENCY_STOP:\n            self.node.get_logger().warn(\'Executing emergency stop - all motion frozen\')\n            # Implement emergency stop logic\n        elif state == HumanoidState.RECOVERY:\n            self.node.get_logger().info(\'Executing recovery sequence with gradual activation\')\n            # Implement recovery logic\n        elif state == HumanoidState.SAFETY_LOCKOUT:\n            self.node.get_logger().warn(\'Entering safety lockout - manual intervention required\')\n            # Implement safety lockout logic\n\n        # Check execution time\n        execution_time = time.time() - start_time\n        if execution_time > 0.005:  # 5ms budget\n            self.node.get_logger().warn(\n                f\'State action for {state.value} exceeded time budget: {execution_time*1000:.2f}ms\'\n            )\n\n    def update_state_machine(self) -> bool:\n        """Update the state machine based on current conditions with safety monitoring."""\n        start_time = time.time()\n\n        # Evaluate conditions\n        conditions = self.evaluate_conditions()\n\n        # Check for valid transitions\n        for transition in self.transitions:\n            if (transition.from_state == self.current_state and\n                conditions.get(transition.condition, False)):\n\n                # Attempt to transition (includes safety checks)\n                if self.transition_to_state(transition.to_state):\n                    # Successfully transitioned\n                    break\n                else:\n                    # Transition failed due to safety violation\n                    self.node.get_logger().error(\n                        f\'Transition from {self.current_state.value} to {transition.to_state.value} \'\n                        f\'failed due to safety violation: {transition.condition}\'\n                    )\n\n        # Safety monitoring\n        if self.safety_monitoring_active:\n            self._perform_safety_checks()\n\n        # Time budget check\n        total_time = time.time() - start_time\n        if total_time > 0.01:  # 10ms budget for entire update\n            self.node.get_logger().warn(\n                f\'State machine update exceeded time budget: {total_time*1000:.2f}ms\'\n            )\n\n        return True\n\n    def _perform_safety_checks(self):\n        """Perform continuous safety monitoring."""\n        # Check for dangerous conditions that require immediate action\n        pitch, roll = self._get_balance_state()\n\n        # Extreme imbalance - trigger emergency stop\n        if abs(pitch) > 1.0 or abs(roll) > 1.0:  # 57 degrees\n            self.node.get_logger().error(\'Extreme imbalance detected - triggering emergency stop\')\n            self.emergency_stop_active = True\n            self.transition_to_state(HumanoidState.EMERGENCY_STOP)\n\n        # Check for joint limit violations\n        self._check_joint_limits()\n\n    def _check_joint_limits(self):\n        """Check for joint limit violations."""\n        # In real implementation, this would check joint position/velocity/effort limits\n        pass\n\n    def _is_safe_to_walk(self) -> bool:\n        """Safety check for walking transition."""\n        pitch, roll = self._get_balance_state()\n        return abs(pitch) < 0.3 and abs(roll) < 0.3  # Less than 17 degrees tilt\n\n    def _is_safe_to_balance(self) -> bool:\n        """Safety check for balancing transition."""\n        return True  # Balancing is always safer than falling\n\n    def _is_safe_to_stand(self) -> bool:\n        """Safety check for standing transition."""\n        pitch, roll = self._get_balance_state()\n        return abs(pitch) < 0.5 and abs(roll) < 0.5  # Less than 29 degrees tilt\n\n    def _is_safe_to_calibrate(self) -> bool:\n        """Safety check for calibration transition."""\n        return self.current_state in [HumanoidState.IDLE, HumanoidState.STANDING]\n\n    def _is_safe_to_recover(self) -> bool:\n        """Safety check for recovery transition."""\n        return self.safety_violations <= 5  # Don\'t recover if too many violations\n\n    def get_current_state(self) -> HumanoidState:\n        """Get the current state with thread safety."""\n        with self.state_lock:\n            return self.current_state\n\n    def is_in_state(self, state: HumanoidState) -> bool:\n        """Check if the robot is in a specific state with thread safety."""\n        with self.state_lock:\n            return self.current_state == state\n\n    def get_state_duration(self) -> float:\n        """Get the duration since entering the current state."""\n        with self.state_lock:\n            return time.time() - self.state_entry_time\n\n    def get_performance_metrics(self) -> Dict:\n        """Get performance and safety metrics."""\n        with self.state_lock:\n            if self.state_transition_times:\n                avg_transition_time = sum(self.state_transition_times) / len(self.state_transition_times)\n                max_transition_time = max(self.state_transition_times)\n            else:\n                avg_transition_time = max_transition_time = 0.0\n\n            return {\n                \'current_state\': self.current_state.value,\n                \'state_duration\': self.get_state_duration(),\n                \'safety_violations\': self.safety_violations,\n                \'avg_transition_time_ms\': avg_transition_time * 1000,\n                \'max_transition_time_ms\': max_transition_time * 1000,\n                \'emergency_stop_active\': self.emergency_stop_active,\n                \'safety_monitoring_active\': self.safety_monitoring_active\n            }\n\n# Integration with ROS 2 node\nclass HumanoidStateNode(Node):\n    def __init__(self):\n        super().__init__(\'humanoid_state_node\')\n\n        # Declare parameters\n        self.declare_parameter(\'control_frequency\', 100)  # Hz\n        self.declare_parameter(\'enable_safety_monitoring\', True)\n        self.declare_parameter(\'max_safety_violations_before_lockout\', 5)\n\n        # Get parameter values\n        self.control_frequency = self.get_parameter(\'control_frequency\').value\n        self.enable_safety_monitoring = self.get_parameter(\'enable_safety_monitoring\').value\n        self.max_safety_violations = self.get_parameter(\'max_safety_violations_before_lockout\').value\n\n        # Initialize state machine\n        self.state_machine = HumanoidStateMachine(self)\n\n        # Create timer for state machine updates\n        self.state_timer = self.create_timer(\n            1.0 / self.control_frequency,\n            self.state_machine.update_state_machine\n        )\n\n        # Safety monitoring timer\n        if self.enable_safety_monitoring:\n            self.safety_timer = self.create_timer(\n                0.1,  # 10Hz safety checks\n                self.perform_additional_safety_checks\n            )\n\n        self.get_logger().info(\n            f\'Humanoid State Node initialized with {self.control_frequency}Hz control frequency\'\n        )\n\n    def perform_additional_safety_checks(self):\n        """Perform additional safety checks outside the main control loop."""\n        metrics = self.state_machine.get_performance_metrics()\n\n        # Check safety violation count\n        if metrics[\'safety_violations\'] >= self.max_safety_violations:\n            self.get_logger().critical(\n                f\'Maximum safety violations reached ({metrics["safety_violations"]}). \'\n                \'Activating safety lockout.\'\n            )\n            self.state_machine.transition_to_state(HumanoidState.SAFETY_LOCKOUT)\n\n        # Log safety metrics periodically\n        if self.get_clock().now().nanoseconds % 1000000000 < 10000000:  # Every ~1 second\n            self.get_logger().info(\n                f\'Safety metrics - Violations: {metrics["safety_violations"]}, \'\n                f\'State: {metrics["current_state"]}, \'\n                f\'Transition time: {metrics["avg_transition_time_ms"]:.2f}ms\'\n            )\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    node = HumanoidStateNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info(\'State node interrupted by user\')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"nvidia-isaac-sim-integration-for-humanoid-robotics",children:"NVIDIA Isaac Sim Integration for Humanoid Robotics"}),"\n",(0,o.jsx)(n.p,{children:"When developing humanoid robots, simulation is crucial for testing and validation. NVIDIA Isaac Sim provides advanced physics simulation capabilities that are essential for humanoid robotics development. Here are the key parameters and configurations for Isaac Sim setup:"}),"\n",(0,o.jsx)(n.h3,{id:"isaac-sim-configuration-parameters",children:"Isaac Sim Configuration Parameters"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",children:'{\n  "simulation_settings": {\n    "physics_engine": "PhysX",\n    "gravity": [0.0, 0.0, -9.81],\n    "timestep": 0.001,\n    "substeps": 1,\n    "solver_type": "TGS",\n    "solver_iterations": 4,\n    "collision_margin": 0.001,\n    "contact_offset": 0.02\n  },\n  "robot_settings": {\n    "robot_name": "autonomous_humanoid",\n    "urdf_path": "/assets/robots/humanoid.urdf",\n    "scale": [1.0, 1.0, 1.0],\n    "initial_position": [0.0, 0.0, 1.0],\n    "initial_orientation": [0.0, 0.0, 0.0, 1.0],\n    "joints": {\n      "left_hip_joint": {\n        "type": "revolute",\n        "limits": {"lower": -1.57, "upper": 1.57, "effort": 100.0, "velocity": 5.0},\n        "damping": 0.1,\n        "friction": 0.0\n      },\n      "left_knee_joint": {\n        "type": "revolute",\n        "limits": {"lower": 0.0, "upper": 2.36, "effort": 100.0, "velocity": 5.0},\n        "damping": 0.1,\n        "friction": 0.0\n      },\n      "right_hip_joint": {\n        "type": "revolute",\n        "limits": {"lower": -1.57, "upper": 1.57, "effort": 100.0, "velocity": 5.0},\n        "damping": 0.1,\n        "friction": 0.0\n      },\n      "right_knee_joint": {\n        "type": "revolute",\n        "limits": {"lower": 0.0, "upper": 2.36, "effort": 100.0, "velocity": 5.0},\n        "damping": 0.1,\n        "friction": 0.0\n      }\n    }\n  },\n  "sensor_settings": {\n    "camera": {\n      "resolution": [640, 480],\n      "fov": 60.0,\n      "near_plane": 0.1,\n      "far_plane": 100.0,\n      "position": [0.5, 0.0, 1.5]\n    },\n    "lidar": {\n      "rotation_frequency": 10.0,\n      "channels": 16,\n      "points_per_channel": 1000,\n      "range": 25.0,\n      "position": [0.3, 0.0, 1.2]\n    },\n    "imu": {\n      "linear_acceleration_noise_density": 0.017,\n      "angular_velocity_noise_density": 0.001,\n      "linear_acceleration_random_walk": 0.00017,\n      "angular_velocity_random_walk": 0.00001\n    }\n  },\n  "environment_settings": {\n    "ground_plane": {\n      "size": [10.0, 10.0],\n      "static_friction": 0.5,\n      "dynamic_friction": 0.5,\n      "restitution": 0.0\n    },\n    "lighting": {\n      "ambient_light": [0.3, 0.3, 0.3],\n      "directional_light": {\n        "direction": [-0.5, -0.5, -1.0],\n        "color": [1.0, 1.0, 1.0],\n        "intensity": 500.0\n      }\n    }\n  },\n  "ros_bridge_settings": {\n    "enabled": true,\n    "topics": {\n      "joint_states": "/autonomous_humanoid/joint_states",\n      "cmd_vel": "/autonomous_humanoid/cmd_vel",\n      "imu_data": "/autonomous_humanoid/imu/data",\n      "camera_image": "/autonomous_humanoid/camera/image_raw",\n      "lidar_scan": "/autonomous_humanoid/lidar/scan"\n    }\n  }\n}\n'})}),"\n",(0,o.jsx)(n.h2,{id:"advanced-communication-patterns-for-humanoid-robotics-1",children:"Advanced Communication Patterns for Humanoid Robotics"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robots require sophisticated communication patterns to coordinate their complex subsystems. Here's an example of a state machine implementation for humanoid behavior:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from enum import Enum\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional\nimport time\nfrom threading import Lock\n\nclass HumanoidState(Enum):\n    """Enumeration of possible humanoid states."""\n    IDLE = "idle"\n    WALKING = "walking"\n    STANDING = "standing"\n    BALANCING = "balancing"\n    CALIBRATING = "calibrating"\n    EMERGENCY_STOP = "emergency_stop"\n    RECOVERY = "recovery"\n\n@dataclass\nclass HumanoidStateTransition:\n    """Represents a state transition with conditions."""\n    from_state: HumanoidState\n    to_state: HumanoidState\n    condition: str\n    action: str\n\nclass HumanoidStateMachine:\n    """\n    State machine for managing humanoid robot behavior.\n    This implementation demonstrates advanced ROS 2 usage patterns.\n    """\n\n    def __init__(self, node):\n        self.node = node\n        self.current_state = HumanoidState.IDLE\n        self.previous_state = HumanoidState.IDLE\n        self.state_lock = Lock()\n\n        # Initialize state transition rules\n        self.transitions = [\n            HumanoidStateTransition(\n                HumanoidState.IDLE, HumanoidState.WALKING,\n                "walking_command_received", "start_walking_sequence"\n            ),\n            HumanoidStateTransition(\n                HumanoidState.WALKING, HumanoidState.STANDING,\n                "stop_command_received", "execute_stop_sequence"\n            ),\n            HumanoidStateTransition(\n                HumanoidState.WALKING, HumanoidState.BALANCING,\n                "imbalance_detected", "activate_balance_control"\n            ),\n            HumanoidStateTransition(\n                HumanoidState.BALANCING, HumanoidState.STANDING,\n                "balance_restored", "return_to_standing"\n            ),\n            HumanoidStateTransition(\n                HumanoidState.IDLE, HumanoidState.CALIBRATING,\n                "calibrate_command", "execute_calibration"\n            ),\n            HumanoidStateTransition(\n                HumanoidState.WALKING, HumanoidState.EMERGENCY_STOP,\n                "emergency_stop", "execute_emergency_stop"\n            ),\n            HumanoidStateTransition(\n                HumanoidState.EMERGENCY_STOP, HumanoidState.RECOVERY,\n                "manual_recovery", "execute_recovery_sequence"\n            ),\n            HumanoidStateTransition(\n                HumanoidState.RECOVERY, HumanoidState.STANDING,\n                "recovery_complete", "stand_up_sequence"\n            )\n        ]\n\n        # Initialize sensor data\n        self.sensor_data = {\n            \'imu_orientation\': [0.0, 0.0, 0.0, 1.0],\n            \'imu_angular_velocity\': [0.0, 0.0, 0.0],\n            \'imu_linear_acceleration\': [0.0, 0.0, -9.81],\n            \'joint_positions\': {},\n            \'joint_velocities\': {},\n            \'joint_efforts\': {},\n            \'force_sensors\': {}\n        }\n\n        # Initialize command flags\n        self.commands = {\n            \'walking_requested\': False,\n            \'stop_requested\': False,\n            \'calibrate_requested\': False,\n            \'emergency_stop\': False,\n            \'manual_recovery\': False\n        }\n\n        self.node.get_logger().info(f\'Humanoid State Machine initialized in {self.current_state.value} state\')\n\n    def update_sensor_data(self, sensor_msg):\n        """Update internal sensor data from ROS messages."""\n        with self.state_lock:\n            # Update sensor data based on message type\n            if hasattr(sensor_msg, \'orientation\'):\n                # IMU data\n                self.sensor_data[\'imu_orientation\'] = [\n                    sensor_msg.orientation.x,\n                    sensor_msg.orientation.y,\n                    sensor_msg.orientation.z,\n                    sensor_msg.orientation.w\n                ]\n                self.sensor_data[\'imu_angular_velocity\'] = [\n                    sensor_msg.angular_velocity.x,\n                    sensor_msg.angular_velocity.y,\n                    sensor_msg.angular_velocity.z\n                ]\n                self.sensor_data[\'imu_linear_acceleration\'] = [\n                    sensor_msg.linear_acceleration.x,\n                    sensor_msg.linear_acceleration.y,\n                    sensor_msg.linear_acceleration.z\n                ]\n\n    def update_commands(self, cmd_type, value=True):\n        """Update command flags."""\n        with self.state_lock:\n            if cmd_type in self.commands:\n                self.commands[cmd_type] = value\n\n    def evaluate_conditions(self):\n        """Evaluate all transition conditions."""\n        conditions = {}\n\n        # Check balance condition\n        pitch = 2 * self.node.get_parameter(\'balance_threshold\').value\n        roll = 2 * self.node.get_parameter(\'balance_threshold\').value\n        conditions[\'imbalance_detected\'] = abs(pitch) > 0.5 or abs(roll) > 0.5\n        conditions[\'balance_restored\'] = abs(pitch) < 0.2 and abs(roll) < 0.2\n\n        # Check command conditions\n        conditions[\'walking_command_received\'] = self.commands[\'walking_requested\']\n        conditions[\'stop_command_received\'] = self.commands[\'stop_requested\']\n        conditions[\'calibrate_command\'] = self.commands[\'calibrate_requested\']\n        conditions[\'emergency_stop\'] = self.commands[\'emergency_stop\']\n        conditions[\'manual_recovery\'] = self.commands[\'manual_recovery\']\n\n        # Check recovery conditions\n        conditions[\'recovery_complete\'] = True  # Simplified for example\n\n        return conditions\n\n    def transition_to_state(self, new_state: HumanoidState):\n        """Transition to a new state with proper cleanup."""\n        with self.state_lock:\n            if new_state != self.current_state:\n                self.previous_state = self.current_state\n                old_state = self.current_state\n                self.current_state = new_state\n\n                self.node.get_logger().info(\n                    f\'State transition: {old_state.value} -> {new_state.value}\'\n                )\n\n                # Execute state-specific actions\n                self.execute_state_action(new_state)\n\n    def execute_state_action(self, state: HumanoidState):\n        """Execute actions specific to the current state."""\n        if state == HumanoidState.WALKING:\n            self.node.get_logger().info(\'Executing walking sequence\')\n            # Implement walking control logic\n        elif state == HumanoidState.STANDING:\n            self.node.get_logger().info(\'Executing standing sequence\')\n            # Implement standing control logic\n        elif state == HumanoidState.BALANCING:\n            self.node.get_logger().info(\'Executing balance control\')\n            # Implement balance control logic\n        elif state == HumanoidState.CALIBRATING:\n            self.node.get_logger().info(\'Executing calibration sequence\')\n            # Implement calibration logic\n        elif state == HumanoidState.EMERGENCY_STOP:\n            self.node.get_logger().info(\'Executing emergency stop\')\n            # Implement emergency stop logic\n        elif state == HumanoidState.RECOVERY:\n            self.node.get_logger().info(\'Executing recovery sequence\')\n            # Implement recovery logic\n\n    def update_state_machine(self):\n        """Update the state machine based on current conditions."""\n        conditions = self.evaluate_conditions()\n\n        # Check for valid transitions\n        for transition in self.transitions:\n            if (transition.from_state == self.current_state and\n                conditions.get(transition.condition, False)):\n\n                self.transition_to_state(transition.to_state)\n                break  # Only one transition per update\n\n    def get_current_state(self) -> HumanoidState:\n        """Get the current state."""\n        with self.state_lock:\n            return self.current_state\n\n    def is_in_state(self, state: HumanoidState) -> bool:\n        """Check if the robot is in a specific state."""\n        with self.state_lock:\n            return self.current_state == state\n\n# Integration with ROS 2 node\nclass HumanoidStateNode(Node):\n    def __init__(self):\n        super().__init__(\'humanoid_state_node\')\n\n        # Declare parameters\n        self.declare_parameter(\'balance_threshold\', 0.1)\n        self.declare_parameter(\'control_frequency\', 100)\n\n        # Initialize state machine\n        self.state_machine = HumanoidStateMachine(self)\n\n        # Create timer for state machine updates\n        self.state_timer = self.create_timer(\n            1.0 / self.get_parameter(\'control_frequency\').value,\n            self.state_machine.update_state_machine\n        )\n\n        self.get_logger().info(\'Humanoid State Node initialized\')\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    node = HumanoidStateNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info(\'Interrupted by user\')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(n.p,{children:"Understanding nodes, topics, and services is crucial for building distributed robotic systems, particularly for autonomous humanoid robots. These communication patterns enable the development of complex, modular systems where different components can operate independently while maintaining coordinated behavior. The advanced examples provided demonstrate how these basic concepts can be extended to create sophisticated humanoid control systems with proper error handling, safety mechanisms, and state management."}),"\n",(0,o.jsx)(n.p,{children:"The integration with NVIDIA Isaac Sim provides realistic physics simulation capabilities that are essential for testing humanoid robot algorithms before deployment on physical hardware. The configuration parameters ensure that the simulation accurately represents the real-world dynamics of the humanoid robot, enabling safe and efficient development and testing of complex behaviors."}),"\n",(0,o.jsx)(n.p,{children:"Proper use of QoS policies, state machines, and service-based communication patterns enables the development of robust, real-time capable humanoid robot systems that can handle the complex requirements of autonomous operation."})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(m,{...e})}):m(e)}},8453(e,n,t){t.d(n,{R:()=>a,x:()=>r});var i=t(6540);const o={},s=i.createContext(o);function a(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);