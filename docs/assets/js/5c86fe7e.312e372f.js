"use strict";(globalThis.webpackChunkclassic=globalThis.webpackChunkclassic||[]).push([[6642],{3103(n,e,i){i.r(e),i.d(e,{assets:()=>s,contentTitle:()=>l,default:()=>c,frontMatter:()=>o,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"module-2/unity-rendering","title":"Unity Rendering","description":"Visual Rendering in Digital Twins","source":"@site/docs/module-2/unity-rendering.md","sourceDirName":"module-2","slug":"/module-2/unity-rendering","permalink":"/ebsite/docs/docs/module-2/unity-rendering","draft":false,"unlisted":false,"editUrl":"https://github.com/sherazi-412002/ai-native-sdd-books/tree/main/docs/module-2/unity-rendering.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"curriculumSidebar","previous":{"title":"Physics and Collisions: Advanced Simulation for Digital Twins of Humanoid Robots","permalink":"/ebsite/docs/docs/module-2/physics-collisions"},"next":{"title":"Sensor Simulation: Advanced Perceptual Systems for Humanoid Robot Digital Twins","permalink":"/ebsite/docs/docs/module-2/sensor-simulation"}}');var a=i(4848),r=i(8453);const o={sidebar_position:2},l="Unity Rendering",s={},d=[{value:"Visual Rendering in Digital Twins",id:"visual-rendering-in-digital-twins",level:2},{value:"Unity Graphics Pipeline",id:"unity-graphics-pipeline",level:2},{value:"Materials and Shaders",id:"materials-and-shaders",level:2},{value:"PBR Shader Implementation",id:"pbr-shader-implementation",level:3},{value:"Material System for Robot Components",id:"material-system-for-robot-components",level:3},{value:"Shader Graph Implementation",id:"shader-graph-implementation",level:3},{value:"Lighting Systems",id:"lighting-systems",level:2},{value:"Realistic Lighting Setup",id:"realistic-lighting-setup",level:3},{value:"Lighting Diagram",id:"lighting-diagram",level:3},{value:"Post-Processing Effects",id:"post-processing-effects",level:2},{value:"Post-Processing Implementation",id:"post-processing-implementation",level:3},{value:"Custom Post-Processing Effect for Robot Vision",id:"custom-post-processing-effect-for-robot-vision",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Rendering Optimization Techniques",id:"rendering-optimization-techniques",level:3},{value:"Performance Monitoring System",id:"performance-monitoring-system",level:3},{value:"Summary",id:"summary",level:2}];function m(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"unity-rendering",children:"Unity Rendering"})}),"\n",(0,a.jsx)(e.h2,{id:"visual-rendering-in-digital-twins",children:"Visual Rendering in Digital Twins"}),"\n",(0,a.jsx)(e.p,{children:"This chapter covers rendering techniques in Unity for creating realistic digital twins of humanoid robots. Unity's rendering pipeline provides advanced capabilities for simulating real-world lighting, materials, and visual effects that are crucial for accurate digital twin representation. In humanoid robotics applications, realistic rendering enables better simulation-to-reality transfer, allowing developers to visualize robot behavior, sensor data, and environmental interactions with high fidelity."}),"\n",(0,a.jsx)(e.p,{children:"Digital twins require precise visual representation to serve as effective tools for robot development, testing, and validation. Unity's flexible rendering system supports Physically-Based Rendering (PBR), advanced lighting models, and real-time performance optimization techniques that are essential for creating believable digital environments. This chapter explores Unity's rendering capabilities with a focus on humanoid robot digital twins, covering graphics pipeline optimization, material systems, lighting techniques, and performance considerations."}),"\n",(0,a.jsx)(e.h2,{id:"unity-graphics-pipeline",children:"Unity Graphics Pipeline"}),"\n",(0,a.jsx)(e.p,{children:"Unity's Scriptable Render Pipeline (SRP) provides developers with extensive control over the rendering process, allowing customization of how objects are drawn, lit, and processed. For humanoid robot digital twins, understanding the graphics pipeline is crucial for achieving both visual quality and performance."}),"\n",(0,a.jsx)(e.p,{children:"The rendering pipeline consists of several key stages:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Culling"}),": Determines which objects are visible to the camera and should be rendered"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Setup"}),": Configures rendering states and shader properties"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Geometry Processing"}),": Transforms vertices and applies vertex shaders"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Rasterization"}),": Converts geometry into fragments/pixels"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Fragment Processing"}),": Applies pixel shaders and calculates final colors"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Output Merging"}),": Combines results with depth, stencil, and color buffers"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"For humanoid robots, the pipeline must handle complex articulated models with multiple materials, realistic skin and metal surfaces, and dynamic lighting conditions. Unity's SRP allows developers to customize these stages for specific use cases."}),"\n",(0,a.jsx)(e.p,{children:"Here's an example of a custom render pass in Unity's Universal Render Pipeline (URP):"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing UnityEngine.Rendering;\nusing UnityEngine.Rendering.Universal;\n\npublic class HumanoidRobotRenderPass : ScriptableRenderPass\n{\n    private static readonly string k_RenderTag = "Humanoid Robot Render Pass";\n    private static readonly int k_SourceId = Shader.PropertyToID("_SourceTexture");\n    private static readonly int k_DestinationId = Shader.PropertyToID("_DestinationTexture");\n\n    private Material m_Material;\n    private RenderTargetIdentifier m_Source;\n    private RenderTargetIdentifier m_Destination;\n    private RenderTextureDescriptor m_Descriptor;\n\n    public HumanoidRobotRenderPass(RenderTextureDescriptor descriptor)\n    {\n        m_Descriptor = descriptor;\n        renderPassEvent = RenderPassEvent.AfterRenderingOpaques;\n    }\n\n    public void Setup(RenderTargetIdentifier source, RenderTargetIdentifier destination, Material material)\n    {\n        m_Source = source;\n        m_Destination = destination;\n        m_Material = material;\n    }\n\n    public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData)\n    {\n        if (m_Material == null) return;\n\n        CommandBuffer cmd = CommandBufferPool.Get(k_RenderTag);\n\n        RenderTextureDescriptor opaqueDesc = m_Descriptor;\n        opaqueDesc.depthBufferBits = 0;\n\n        // Blit source texture to destination texture with custom material\n        cmd.SetGlobalTexture(k_SourceId, m_Source);\n        cmd.Blit(m_Source, m_Destination, m_Material, 0);\n\n        context.ExecuteCommandBuffer(cmd);\n        CommandBufferPool.Release(cmd);\n    }\n}\n\npublic class HumanoidRobotRendererFeature : ScriptableRendererFeature\n{\n    public Material material;\n    private HumanoidRobotRenderPass m_RenderPass;\n\n    public override void Create()\n    {\n        m_RenderPass = new HumanoidRobotRenderPass(base.renderTextureDescriptor);\n        m_RenderPass.renderPassEvent = RenderPassEvent.AfterRenderingOpaques;\n    }\n\n    public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData)\n    {\n        if (material == null) return;\n        m_RenderPass.Setup(renderer.cameraColorTarget, RenderTargetHandle.CameraTarget.Identifier(), material);\n        renderer.EnqueuePass(m_RenderPass);\n    }\n}\n'})}),"\n",(0,a.jsx)(e.p,{children:"The graphics pipeline optimization for humanoid robots involves several considerations:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"LOD (Level of Detail) Systems"}),": Implementing multiple versions of robot models with varying polygon counts based on camera distance"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Occlusion Culling"}),": Using Unity's occlusion culling to avoid rendering parts of the robot that are not visible"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Dynamic Batching"}),": Combining multiple small robot components for efficient rendering"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Shader Variants"}),": Managing shader permutations to minimize draw calls"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"materials-and-shaders",children:"Materials and Shaders"}),"\n",(0,a.jsx)(e.p,{children:"Unity's material system is based on Physically-Based Rendering (PBR), which simulates real-world light interaction with surfaces. For humanoid robots, materials must accurately represent different surface types like metal, plastic, rubber, and composite materials."}),"\n",(0,a.jsx)(e.h3,{id:"pbr-shader-implementation",children:"PBR Shader Implementation"}),"\n",(0,a.jsx)(e.p,{children:"Here's a comprehensive PBR shader implementation suitable for humanoid robot materials:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-csharp",children:'Shader "Custom/HumanoidRobotPBR"\n{\n    Properties\n    {\n        _Color ("Color", Color) = (1,1,1,1)\n        _MainTex ("Albedo (RGB)", 2D) = "white" {}\n        _Metallic ("Metallic", Range(0,1)) = 0.0\n        _Smoothness ("Smoothness", Range(0,1)) = 0.5\n        _BumpMap ("Normal Map", 2D) = "bump" {}\n        _BumpScale ("Normal Scale", Float) = 1.0\n        _OcclusionMap ("Occlusion", 2D) = "white" {}\n        _OcclusionStrength ("Occlusion Strength", Range(0,1)) = 1.0\n        _EmissionMap ("Emission", 2D) = "black" {}\n        _EmissionColor ("Emission Color", Color) = (0,0,0,1)\n        _DetailMask ("Detail Mask", 2D) = "white" {}\n        _DetailAlbedoMap ("Detail Albedo", 2D) = "grey" {}\n        _DetailNormalMap ("Detail Normal", 2D) = "bump" {}\n        _DetailNormalScale ("Detail Normal Scale", Float) = 1.0\n        _DetailAlbedoScale ("Detail Albedo Scale", Range(0,1)) = 1.0\n        _RoughnessMap ("Roughness Map", 2D) = "white" {}\n        _MetallicMap ("Metallic Map", 2D) = "black" {}\n    }\n    SubShader\n    {\n        Tags { "RenderType"="Opaque" "RenderPipeline" = "UniversalPipeline"}\n        LOD 300\n\n        Pass\n        {\n            Name "PBR Forward Pass"\n            Tags { "LightMode" = "UniversalForward" }\n\n            HLSLPROGRAM\n            #pragma vertex vert\n            #pragma fragment frag\n\n            #pragma multi_compile _ _MAIN_LIGHT_SHADOWS\n            #pragma multi_compile _ _MAIN_LIGHT_SHADOWS_CASCADE\n            #pragma multi_compile _ _SHADOWS_SOFT\n            #pragma multi_compile_fog\n\n            #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"\n            #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl"\n            #include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"\n            #include "Packages/com.unity.render-pipelines.core/ShaderLibrary/UnityInstancing.hlsl"\n\n            struct Attributes\n            {\n                float4 positionOS : POSITION;\n                float3 normalOS : NORMAL;\n                float4 tangentOS : TANGENT;\n                float2 uv : TEXCOORD0;\n                float2 uv2 : TEXCOORD1;\n                float2 lightmapUV : TEXCOORD2;\n                UNITY_VERTEX_INPUT_INSTANCE_ID\n            };\n\n            struct Varyings\n            {\n                float4 positionCS : SV_POSITION;\n                float3 positionWS : TEXCOORD0;\n                float3 normalWS : TEXCOORD1;\n                float4 tangentWS : TEXCOORD2;\n                float3 bitangentWS : TEXCOORD3;\n                float2 uv : TEXCOORD4;\n                float2 lightmapUV : TEXCOORD5;\n                float4 shadowCoord : TEXCOORD6;\n                float4 fogFactorAndVertexLight : TEXCOORD7;\n                UNITY_VERTEX_INPUT_INSTANCE_ID\n                UNITY_VERTEX_OUTPUT_STEREO\n            };\n\n            TEXTURE2D(_MainTex);           SAMPLER(sampler_MainTex);\n            TEXTURE2D(_BumpMap);          SAMPLER(sampler_BumpMap);\n            TEXTURE2D(_OcclusionMap);     SAMPLER(sampler_OcclusionMap);\n            TEXTURE2D(_EmissionMap);      SAMPLER(sampler_EmissionMap);\n            TEXTURE2D(_DetailAlbedoMap);  SAMPLER(sampler_DetailAlbedoMap);\n            TEXTURE2D(_DetailNormalMap);  SAMPLER(sampler_DetailNormalMap);\n            TEXTURE2D(_RoughnessMap);     SAMPLER(sampler_RoughnessMap);\n            TEXTURE2D(_MetallicMap);      SAMPLER(sampler_MetallicMap);\n\n            CBUFFER_START(UnityPerMaterial)\n                float4 _MainTex_ST;\n                float4 _Color;\n                float _Metallic;\n                float _Smoothness;\n                float _BumpScale;\n                float _OcclusionStrength;\n                float _EmissionColor;\n                float _DetailNormalScale;\n                float _DetailAlbedoScale;\n            CBUFFER_END\n\n            Varyings vert(Attributes input)\n            {\n                Varyings output = (Varyings)0;\n                UNITY_SETUP_INSTANCE_ID(input);\n                UNITY_TRANSFER_INSTANCE_ID(input, output);\n                UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(output);\n\n                VertexPositionInputs vertexInput = GetVertexPositionInputs(input.positionOS.xyz);\n                VertexNormalInputs normalInput = GetVertexNormalInputs(input.normalOS, input.tangentOS);\n\n                output.positionCS = vertexInput.positionCS;\n                output.positionWS = vertexInput.positionWS;\n                output.normalWS = normalInput.normalWS;\n                output.tangentWS = float4(normalInput.tangentWS, input.tangentOS.w);\n                output.bitangentWS = normalInput.bitangentWS;\n\n                output.uv = TRANSFORM_TEX(input.uv, _MainTex);\n                output.lightmapUV = input.lightmapUV;\n\n                output.shadowCoord = TransformWorldToShadowCoord(output.positionWS);\n\n                output.fogFactorAndVertexLight = 0;\n                output.fogFactorAndVertexLight.x = ComputeFogFactor(output.positionCS.z);\n\n                return output;\n            }\n\n            half4 frag(Varyings input) : SV_Target\n            {\n                UNITY_SETUP_INSTANCE_ID(input);\n                UNITY_SETUP_STEREO_EYE_INDEX_POST_VERTEX(input);\n\n                float3 positionWS = input.positionWS;\n                half3 normalWS = NormalizeNormalPerPixel(input.normalWS);\n                float2 uv = input.uv;\n\n                // Sample textures\n                half4 albedoAlpha = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, uv) * _Color;\n                half3 albedo = albedoAlpha.rgb;\n                half alpha = albedoAlpha.a;\n\n                // Sample and unpack normal map\n                half4 normalMapSample = SAMPLE_TEXTURE2D(_BumpMap, sampler_BumpMap, uv);\n                half3 normalTS = UnpackNormal(normalMapSample);\n                normalTS.xy *= _BumpScale;\n                normalTS.z = sqrt(1.0 - saturate(dot(normalTS.xy, normalTS.xy)));\n                half3 worldNormal = TransformTangentToWorld(normalTS, half3x3(input.tangentWS.xyz, input.bitangentWS.xyz, input.normalWS));\n\n                // Sample material maps\n                half metallic = _Metallic;\n                half smoothness = _Smoothness;\n\n                if (_MetallicMap)\n                    metallic *= SAMPLE_TEXTURE2D(_MetallicMap, sampler_MetallicMap, uv).r;\n\n                if (_RoughnessMap)\n                    smoothness *= 1.0 - SAMPLE_TEXTURE2D(_RoughnessMap, sampler_RoughnessMap, uv).r;\n\n                // Occlusion\n                half occlusion = SAMPLE_TEXTURE2D(_OcclusionMap, sampler_OcclusionMap, uv).r;\n                occlusion = lerp(1.0, occlusion, _OcclusionStrength);\n\n                // Emission\n                half3 emission = SAMPLE_TEXTURE2D(_EmissionMap, sampler_EmissionMap, uv).rgb * _EmissionColor.rgb;\n\n                // Detail maps\n                float2 detailUV = uv * 4.0; // Scale for detail tiling\n                half3 detailAlbedo = SAMPLE_TEXTURE2D(_DetailAlbedoMap, sampler_DetailAlbedoMap, detailUV).rgb;\n                detailAlbedo = lerp(half3(1.0, 1.0, 1.0), detailAlbedo, _DetailAlbedoScale);\n                albedo *= detailAlbedo;\n\n                half4 detailNormalSample = SAMPLE_TEXTURE2D(_DetailNormalMap, sampler_DetailNormalMap, detailUV);\n                half3 detailNormalTS = UnpackNormal(detailNormalSample);\n                detailNormalTS.xy *= _DetailNormalScale;\n                detailNormalTS.z = sqrt(1.0 - saturate(dot(detailNormalTS.xy, detailNormalTS.xy)));\n\n                // Blend normals\n                worldNormal = BlendNormal(worldNormal, TransformTangentToWorld(detailNormalTS, half3x3(input.tangentWS.xyz, input.bitangentWS.xyz, input.normalWS)));\n\n                // Lighting calculations\n                Light mainLight = GetMainLight(input.shadowCoord);\n                half3 viewDir = GetWorldSpaceNormalizeViewDir(positionWS);\n\n                BRDFData brdfData;\n                InitializeBRDFData(albedo, metallic, smoothness, alpha, brdfData);\n\n                half3 diffuse = LightingLambert(mainLight.color, mainLight.direction, worldNormal);\n                half3 specular = LightingSpecular(mainLight.color, mainLight.direction, worldNormal, viewDir, brdfData.reflectivity, brdfData.perceptualRoughness);\n\n                half3 color = brdfData.diffuse + brdfData.specular + emission;\n                color *= occlusion;\n\n                // Apply fog\n                color = MixFog(color, input.fogFactorAndVertexLight.x);\n\n                return half4(color, alpha);\n            }\n            ENDHLSL\n        }\n\n        Pass\n        {\n            Name "ShadowCaster"\n            Tags { "LightMode" = "ShadowCaster" }\n\n            ZWrite On\n            ZTest LEqual\n            ColorMask 0\n\n            HLSLPROGRAM\n            #pragma vertex ShadowPassVertex\n            #pragma fragment ShadowPassFragment\n            #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl"\n\n            float3 _LightDirection;\n\n            struct Attributes\n            {\n                float4 positionOS : POSITION;\n                float3 normalOS : NORMAL;\n                float2 uv : TEXCOORD0;\n                UNITY_VERTEX_INPUT_INSTANCE_ID\n            };\n\n            struct Varyings\n            {\n                float2 uv : TEXCOORD0;\n                float4 positionCS : SV_POSITION;\n                UNITY_VERTEX_INPUT_INSTANCE_ID\n                UNITY_VERTEX_OUTPUT_STEREO\n            };\n\n            Varyings ShadowPassVertex(Attributes input)\n            {\n                Varyings output;\n                UNITY_SETUP_INSTANCE_ID(input);\n                UNITY_TRANSFER_INSTANCE_ID(input, output);\n                UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(output);\n\n                float3 positionWS = TransformObjectToWorld(input.positionOS.xyz);\n                float3 normalWS = TransformObjectToWorldNormal(input.normalOS);\n\n                float4 positionCS = TransformWorldToHClip(ApplyShadowBias(positionWS, normalWS, _LightDirection));\n\n                output.positionCS = positionCS;\n                output.uv = TRANSFORM_TEX(input.uv, _MainTex);\n                return output;\n            }\n\n            half4 ShadowPassFragment(Varyings input) : SV_TARGET\n            {\n                UNITY_SETUP_INSTANCE_ID(input);\n                float4 albedoAlpha = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, input.uv) * _Color;\n                clip(albedoAlpha.a - 0.001);\n                return 0;\n            }\n            ENDHLSL\n        }\n    }\n    Fallback "Universal Render Pipeline/Lit"\n    CustomEditor "HumanoidRobotPBRGUI"\n}\n'})}),"\n",(0,a.jsx)(e.h3,{id:"material-system-for-robot-components",children:"Material System for Robot Components"}),"\n",(0,a.jsx)(e.p,{children:"For humanoid robots, different components require specialized materials:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Metallic Surfaces"}),": High metallic values with low roughness for realistic metal reflections"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Plastic Components"}),": Low metallic values with variable roughness for different plastic types"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"LED Indicators"}),": Emissive materials for status lights and indicators"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Sensor Covers"}),": Transparent materials with specific transmission properties"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Joint Mechanisms"}),": Materials that show mechanical details and wear patterns"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"shader-graph-implementation",children:"Shader Graph Implementation"}),"\n",(0,a.jsx)(e.p,{children:"Unity's Shader Graph provides a visual approach to creating custom shaders for humanoid robot materials. Here's an example implementation for creating a robot-specific material:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing UnityEngine.Rendering;\nusing UnityEngine.Rendering.Universal;\n\n[CreateAssetMenu(fileName = "RobotMaterialData", menuName = "Robot Rendering/Material Data")]\npublic class RobotMaterialData : ScriptableObject\n{\n    [Header("Surface Properties")]\n    public Color baseColor = Color.gray;\n    public float metallic = 0.8f;\n    public float smoothness = 0.4f;\n    public Texture2D albedoMap;\n    public Texture2D normalMap;\n    public Texture2D metallicMap;\n    public Texture2D roughnessMap;\n\n    [Header("Detail Properties")]\n    public Texture2D detailAlbedo;\n    public Texture2D detailNormal;\n    public float detailAlbedoScale = 1.0f;\n    public float detailNormalScale = 1.0f;\n\n    [Header("Emission Properties")]\n    public bool hasEmission = false;\n    public Color emissionColor = Color.black;\n    public Texture2D emissionMap;\n\n    [Header("Robot-Specific Properties")]\n    public bool isWornSurface = false;\n    public float wearIntensity = 0.0f;\n    public Color wearColor = Color.red;\n    public Texture2D wearMask;\n\n    public Material CreateRobotMaterial()\n    {\n        Material material = new Material(Shader.Find("Custom/HumanoidRobotPBR"));\n\n        material.SetColor("_Color", baseColor);\n        material.SetFloat("_Metallic", metallic);\n        material.SetFloat("_Smoothness", smoothness);\n\n        if (albedoMap != null) material.SetTexture("_MainTex", albedoMap);\n        if (normalMap != null) material.SetTexture("_BumpMap", normalMap);\n        if (metallicMap != null) material.SetTexture("_MetallicMap", metallicMap);\n        if (roughnessMap != null) material.SetTexture("_RoughnessMap", roughnessMap);\n        if (detailAlbedo != null) material.SetTexture("_DetailAlbedoMap", detailAlbedo);\n        if (detailNormal != null) material.SetTexture("_DetailNormalMap", detailNormal);\n\n        material.SetFloat("_DetailAlbedoScale", detailAlbedoScale);\n        material.SetFloat("_DetailNormalScale", detailNormalScale);\n\n        if (hasEmission)\n        {\n            material.EnableKeyword("_EMISSION");\n            material.SetColor("_EmissionColor", emissionColor);\n            if (emissionMap != null) material.SetTexture("_EmissionMap", emissionMap);\n        }\n        else\n        {\n            material.DisableKeyword("_EMISSION");\n        }\n\n        return material;\n    }\n}\n'})}),"\n",(0,a.jsx)(e.h2,{id:"lighting-systems",children:"Lighting Systems"}),"\n",(0,a.jsx)(e.p,{children:"Lighting is crucial for creating realistic digital twins that accurately represent real-world conditions. Unity supports multiple lighting systems that can be configured for humanoid robot environments."}),"\n",(0,a.jsx)(e.h3,{id:"realistic-lighting-setup",children:"Realistic Lighting Setup"}),"\n",(0,a.jsx)(e.p,{children:"For humanoid robot digital twins, lighting must simulate various real-world conditions:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing UnityEngine.Rendering;\nusing UnityEngine.Rendering.Universal;\n\npublic class HumanoidRobotLightingSystem : MonoBehaviour\n{\n    [Header("Lighting Configuration")]\n    public Light mainDirectionalLight;\n    public Light[] additionalLights;\n    public bool useRealisticShadows = true;\n    public float shadowDistance = 50.0f;\n    public float shadowResolution = 2048.0f;\n\n    [Header("Environment Lighting")]\n    public Cubemap reflectionCubemap;\n    public float reflectionIntensity = 1.0f;\n    public Color ambientColor = Color.gray;\n\n    [Header("Dynamic Lighting")]\n    public bool enableDynamicLighting = true;\n    public float lightingUpdateRate = 0.1f;\n\n    private float m_LastUpdate;\n\n    void Start()\n    {\n        SetupLighting();\n        m_LastUpdate = Time.time;\n    }\n\n    void Update()\n    {\n        if (enableDynamicLighting && Time.time - m_LastUpdate > lightingUpdateRate)\n        {\n            UpdateDynamicLighting();\n            m_LastUpdate = Time.time;\n        }\n    }\n\n    private void SetupLighting()\n    {\n        // Configure main directional light\n        if (mainDirectionalLight != null)\n        {\n            mainDirectionalLight.type = LightType.Directional;\n            mainDirectionalLight.shadows = LightShadows.Soft;\n            mainDirectionalLight.shadowStrength = 0.8f;\n            mainDirectionalLight.shadowBias = 0.05f;\n            mainDirectionalLight.shadowNormalBias = 0.4f;\n            mainDirectionalLight.shadowNearPlane = 0.2f;\n        }\n\n        // Configure additional lights\n        if (additionalLights != null)\n        {\n            foreach (Light light in additionalLights)\n            {\n                ConfigureAdditionalLight(light);\n            }\n        }\n\n        // Set up environment lighting\n        RenderSettings.ambientMode = UnityEngine.Rendering.AmbientMode.Trilight;\n        RenderSettings.ambientSkyColor = ambientColor * 0.7f;\n        RenderSettings.ambientEquatorColor = ambientColor * 0.5f;\n        RenderSettings.ambientGroundColor = ambientColor * 0.3f;\n\n        // Configure reflection probes\n        SetupReflectionProbes();\n    }\n\n    private void ConfigureAdditionalLight(Light light)\n    {\n        // Configure based on light type\n        switch (light.type)\n        {\n            case LightType.Point:\n                light.shadows = LightShadows.Soft;\n                light.range = Mathf.Max(light.range, 10.0f);\n                break;\n            case LightType.Spot:\n                light.shadows = LightShadows.Soft;\n                light.spotAngle = Mathf.Clamp(light.spotAngle, 30.0f, 120.0f);\n                break;\n            case LightType.Directional:\n                light.shadows = LightShadows.Soft;\n                break;\n        }\n\n        // Set realistic intensity based on light type\n        if (light.type == LightType.Point || light.type == LightType.Spot)\n        {\n            light.intensity = Mathf.Clamp(light.intensity, 0.5f, 3.0f);\n        }\n        else if (light.type == LightType.Directional)\n        {\n            light.intensity = Mathf.Clamp(light.intensity, 0.5f, 2.0f);\n        }\n    }\n\n    private void SetupReflectionProbes()\n    {\n        // Create and configure reflection probes for the humanoid robot\n        GameObject[] robotParts = GameObject.FindGameObjectsWithTag("RobotPart");\n\n        foreach (GameObject part in robotParts)\n        {\n            // Add reflection probe to important robot parts\n            if (part.GetComponent<Renderer>() != null)\n            {\n                ReflectionProbe probe = part.AddComponent<ReflectionProbe>();\n                probe.mode = ReflectionProbeMode.Realtime;\n                probe.size = new Vector3(5.0f, 5.0f, 5.0f);\n                probe.center = Vector3.zero;\n                probe.resolution = 512;\n                probe.refreshMode = ReflectionProbeRefreshMode.EveryFrame;\n                probe.timeSlicingMode = ReflectionProbeTimeSlicingMode.IndividualFaces;\n            }\n        }\n    }\n\n    private void UpdateDynamicLighting()\n    {\n        // Update lighting based on time of day or other dynamic factors\n        float timeOfDay = (Mathf.Sin(Time.time * 0.1f) + 1.0f) * 0.5f; // 0-1 cycle\n\n        // Adjust main light direction and intensity based on time\n        if (mainDirectionalLight != null)\n        {\n            Vector3 lightDirection = new Vector3(\n                Mathf.Sin(timeOfDay * Mathf.PI * 2) * 0.7f,\n                -Mathf.Cos(timeOfDay * Mathf.PI * 2) * 0.8f - 0.2f,\n                Mathf.Cos(timeOfDay * Mathf.PI * 2) * 0.5f\n            );\n\n            mainDirectionalLight.transform.rotation = Quaternion.LookRotation(lightDirection);\n            mainDirectionalLight.intensity = Mathf.Lerp(0.8f, 1.2f, timeOfDay);\n        }\n\n        // Update ambient lighting\n        Color ambient = Color.Lerp(\n            new Color(0.2f, 0.2f, 0.3f),  // Cool ambient\n            new Color(0.3f, 0.25f, 0.2f), // Warm ambient\n            timeOfDay\n        );\n\n        RenderSettings.ambientSkyColor = ambient * 0.7f;\n        RenderSettings.ambientEquatorColor = ambient * 0.5f;\n        RenderSettings.ambientGroundColor = ambient * 0.3f;\n    }\n\n    // Method to set up lighting for specific scenarios\n    public void SetupScenarioLighting(string scenario)\n    {\n        switch (scenario)\n        {\n            case "indoor_daylight":\n                SetupIndoorDaylight();\n                break;\n            case "indoor_night":\n                SetupIndoorNight();\n                break;\n            case "outdoor_day":\n                SetupOutdoorDay();\n                break;\n            case "outdoor_night":\n                SetupOutdoorNight();\n                break;\n            case "factory_floor":\n                SetupFactoryFloor();\n                break;\n            default:\n                SetupDefaultLighting();\n                break;\n        }\n    }\n\n    private void SetupIndoorDaylight()\n    {\n        if (mainDirectionalLight != null)\n        {\n            mainDirectionalLight.color = Color.white;\n            mainDirectionalLight.intensity = 1.0f;\n            mainDirectionalLight.transform.rotation = Quaternion.Euler(50, -30, 0);\n        }\n\n        RenderSettings.ambientMode = UnityEngine.Rendering.AmbientMode.Trilight;\n        RenderSettings.ambientSkyColor = new Color(0.212f, 0.227f, 0.259f);\n        RenderSettings.ambientEquatorColor = new Color(0.114f, 0.125f, 0.133f);\n        RenderSettings.ambientGroundColor = new Color(0.047f, 0.043f, 0.035f);\n    }\n\n    private void SetupIndoorNight()\n    {\n        if (mainDirectionalLight != null)\n        {\n            mainDirectionalLight.color = new Color(0.8f, 0.9f, 1.0f);\n            mainDirectionalLight.intensity = 0.5f;\n            mainDirectionalLight.transform.rotation = Quaternion.Euler(45, -120, 0);\n        }\n\n        // Add artificial lights for indoor night scenario\n        AddArtificialIndoorLights();\n    }\n\n    private void AddArtificialIndoorLights()\n    {\n        // Create artificial lights for indoor environment\n        GameObject[] lightPositions = GameObject.FindGameObjectsWithTag("LightPosition");\n\n        foreach (GameObject pos in lightPositions)\n        {\n            GameObject lightObj = new GameObject("Artificial Light");\n            lightObj.transform.SetParent(pos.transform);\n            lightObj.transform.localPosition = Vector3.zero;\n\n            Light light = lightObj.AddComponent<Light>();\n            light.type = LightType.Point;\n            light.color = new Color(0.9f, 0.8f, 0.6f); // Warm white\n            light.range = 15.0f;\n            light.intensity = 1.5f;\n            light.shadows = LightShadows.Soft;\n        }\n    }\n\n    private void SetupOutdoorDay()\n    {\n        if (mainDirectionalLight != null)\n        {\n            mainDirectionalLight.color = Color.white;\n            mainDirectionalLight.intensity = 1.5f;\n            mainDirectionalLight.transform.rotation = Quaternion.Euler(50, 150, 0);\n        }\n\n        RenderSettings.ambientMode = UnityEngine.Rendering.AmbientMode.Trilight;\n        RenderSettings.ambientSkyColor = new Color(0.5f, 0.55f, 0.8f);\n        RenderSettings.ambientEquatorColor = new Color(0.7f, 0.6f, 0.5f);\n        RenderSettings.ambientGroundColor = new Color(0.2f, 0.2f, 0.2f);\n    }\n\n    private void SetupOutdoorNight()\n    {\n        if (mainDirectionalLight != null)\n        {\n            mainDirectionalLight.color = new Color(0.2f, 0.2f, 0.4f); // Moonlight\n            mainDirectionalLight.intensity = 0.2f;\n            mainDirectionalLight.transform.rotation = Quaternion.Euler(130, 45, 0);\n        }\n\n        RenderSettings.ambientMode = UnityEngine.Rendering.AmbientMode.Trilight;\n        RenderSettings.ambientSkyColor = new Color(0.05f, 0.05f, 0.1f);\n        RenderSettings.ambientEquatorColor = new Color(0.02f, 0.02f, 0.05f);\n        RenderSettings.ambientGroundColor = new Color(0.01f, 0.01f, 0.02f);\n    }\n\n    private void SetupFactoryFloor()\n    {\n        if (mainDirectionalLight != null)\n        {\n            mainDirectionalLight.color = new Color(0.9f, 0.9f, 0.95f); // Industrial lighting\n            mainDirectionalLight.intensity = 1.2f;\n            mainDirectionalLight.transform.rotation = Quaternion.Euler(60, -45, 0);\n        }\n\n        // Add industrial-style artificial lights\n        AddIndustrialLights();\n    }\n\n    private void AddIndustrialLights()\n    {\n        // Create industrial lighting setup\n        for (int i = 0; i < 8; i++)\n        {\n            GameObject lightObj = new GameObject($"Industrial Light {i}");\n            lightObj.transform.position = new Vector3(i * 5.0f, 8.0f, 0);\n\n            Light light = lightObj.AddComponent<Light>();\n            light.type = LightType.Spot;\n            light.color = new Color(0.95f, 0.95f, 0.9f);\n            light.range = 20.0f;\n            light.spotAngle = 60.0f;\n            light.intensity = 2.0f;\n            light.shadows = LightShadows.Soft;\n        }\n    }\n\n    private void SetupDefaultLighting()\n    {\n        if (mainDirectionalLight != null)\n        {\n            mainDirectionalLight.color = Color.white;\n            mainDirectionalLight.intensity = 1.0f;\n            mainDirectionalLight.transform.rotation = Quaternion.Euler(50, -30, 0);\n        }\n    }\n}\n'})}),"\n",(0,a.jsx)(e.h3,{id:"lighting-diagram",children:"Lighting Diagram"}),"\n",(0,a.jsx)(e.p,{children:"Here's a Mermaid.js diagram showing the lighting architecture for humanoid robot digital twins:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-mermaid",children:"graph TB\n    A[Humanoid Robot Digital Twin] --\x3e B[Main Directional Light]\n    A --\x3e C[Point Lights]\n    A --\x3e D[Spot Lights]\n    A --\x3e E[Reflection Probes]\n\n    B --\x3e F[Shadow Mapping]\n    C --\x3e G[Local Illumination]\n    D --\x3e H[Task Lighting]\n    E --\x3e I[Environment Reflections]\n\n    F --\x3e J[Real-time Shadows]\n    G --\x3e K[Robot Component Lighting]\n    H --\x3e L[Sensor Area Lighting]\n    I --\x3e M[Dynamic Reflections]\n\n    J --\x3e N[Shadow Distance: 50m]\n    K --\x3e O[Material-based Response]\n    L --\x3e P[Interactive Lighting]\n    M --\x3e Q[Cubemap Updates]\n\n    style A fill:#e1f5fe\n    style B fill:#f3e5f5\n    style C fill:#e8f5e8\n    style D fill:#fff3e0\n    style E fill:#fce4ec\n"})}),"\n",(0,a.jsx)(e.h2,{id:"post-processing-effects",children:"Post-Processing Effects"}),"\n",(0,a.jsx)(e.p,{children:"Post-processing effects enhance the visual quality of humanoid robot digital twins by adding realistic camera effects, color grading, and atmospheric effects."}),"\n",(0,a.jsx)(e.h3,{id:"post-processing-implementation",children:"Post-Processing Implementation"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing UnityEngine.Rendering;\nusing UnityEngine.Rendering.Universal;\n\n[RequireComponent(typeof(Volume))]\npublic class HumanoidRobotPostProcessing : MonoBehaviour\n{\n    [Header("Depth of Field")]\n    public bool enableDepthOfField = true;\n    public float dofFocusDistance = 10.0f;\n    public float dofAperture = 5.6f;\n    public float dofFocalLength = 50.0f;\n\n    [Header("Color Grading")]\n    public bool enableColorGrading = true;\n    public Color temperatureShift = Color.white;\n    public float saturation = 1.0f;\n    public float contrast = 1.0f;\n\n    [Header("Bloom")]\n    public bool enableBloom = true;\n    public float bloomIntensity = 0.5f;\n    public float bloomThreshold = 1.0f;\n    public float bloomScatter = 0.7f;\n\n    [Header("Motion Blur")]\n    public bool enableMotionBlur = true;\n    public float motionBlurIntensity = 0.5f;\n\n    [Header("Chromatic Aberration")]\n    public bool enableChromaticAberration = true;\n    public float chromaticAberrationIntensity = 0.1f;\n\n    private Volume m_Volume;\n    private DepthOfField m_DepthOfField;\n    private ColorAdjustments m_ColorAdjustments;\n    private Bloom m_Bloom;\n    private MotionBlur m_MotionBlur;\n    private ChromaticAberration m_ChromaticAberration;\n\n    void Start()\n    {\n        SetupPostProcessing();\n    }\n\n    void Update()\n    {\n        UpdatePostProcessing();\n    }\n\n    private void SetupPostProcessing()\n    {\n        m_Volume = GetComponent<Volume>();\n\n        // Get or create post-processing effects\n        m_Volume.profile.TryGet(out m_DepthOfField);\n        if (m_DepthOfField == null)\n        {\n            m_Volume.profile.Add<DepthOfField>(true);\n            m_Volume.profile.TryGet(out m_DepthOfField);\n        }\n\n        m_Volume.profile.TryGet(out m_ColorAdjustments);\n        if (m_ColorAdjustments == null)\n        {\n            m_Volume.profile.Add<ColorAdjustments>(true);\n            m_Volume.profile.TryGet(out m_ColorAdjustments);\n        }\n\n        m_Volume.profile.TryGet(out m_Bloom);\n        if (m_Bloom == null)\n        {\n            m_Volume.profile.Add<Bloom>(true);\n            m_Volume.profile.TryGet(out m_Bloom);\n        }\n\n        m_Volume.profile.TryGet(out m_MotionBlur);\n        if (m_MotionBlur == null)\n        {\n            m_Volume.profile.Add<MotionBlur>(true);\n            m_Volume.profile.TryGet(out m_MotionBlur);\n        }\n\n        m_Volume.profile.TryGet(out m_ChromaticAberration);\n        if (m_ChromaticAberration == null)\n        {\n            m_Volume.profile.Add<ChromaticAberration>(true);\n            m_Volume.profile.TryGet(out m_ChromaticAberration);\n        }\n\n        UpdatePostProcessing();\n    }\n\n    private void UpdatePostProcessing()\n    {\n        if (m_DepthOfField != null)\n        {\n            m_DepthOfField.active = enableDepthOfField;\n            if (enableDepthOfField)\n            {\n                m_DepthOfField.focusDistance.value = dofFocusDistance;\n                m_DepthOfField.aperture.value = dofAperture;\n                m_DepthOfField.focalLength.value = dofFocalLength;\n            }\n        }\n\n        if (m_ColorAdjustments != null)\n        {\n            m_ColorAdjustments.active = enableColorGrading;\n            if (enableColorGrading)\n            {\n                m_ColorAdjustments.temperature.value = GetTemperatureValue(temperatureShift);\n                m_ColorAdjustments.saturation.value = (saturation - 1.0f) * 20.0f; // Convert to -20 to 20 range\n                m_ColorAdjustments.contrast.value = (contrast - 1.0f) * 20.0f; // Convert to -20 to 20 range\n            }\n        }\n\n        if (m_Bloom != null)\n        {\n            m_Bloom.active = enableBloom;\n            if (enableBloom)\n            {\n                m_Bloom.intensity.value = bloomIntensity;\n                m_Bloom.threshold.value = bloomThreshold;\n                m_Bloom.scatter.value = bloomScatter;\n            }\n        }\n\n        if (m_MotionBlur != null)\n        {\n            m_MotionBlur.active = enableMotionBlur;\n            if (enableMotionBlur)\n            {\n                m_MotionBlur.intensity.value = motionBlurIntensity;\n            }\n        }\n\n        if (m_ChromaticAberration != null)\n        {\n            m_ChromaticAberration.active = enableChromaticAberration;\n            if (enableChromaticAberration)\n            {\n                m_ChromaticAberration.intensity.value = chromaticAberrationIntensity;\n            }\n        }\n    }\n\n    private float GetTemperatureValue(Color color)\n    {\n        // Convert color temperature to Unity\'s temperature adjustment value\n        float avg = (color.r + color.g + color.b) / 3.0f;\n        return (avg - 0.5f) * 100.0f; // Convert to -50 to 50 range\n    }\n\n    // Method to adjust post-processing for different viewing scenarios\n    public void SetViewingScenario(string scenario)\n    {\n        switch (scenario)\n        {\n            case "close_up":\n                SetCloseUpViewing();\n                break;\n            case "wide_shot":\n                SetWideShotViewing();\n                break;\n            case "detailed_inspection":\n                SetDetailedInspectionViewing();\n                break;\n            case "environment_overview":\n                SetEnvironmentOverviewViewing();\n                break;\n            default:\n                SetDefaultViewing();\n                break;\n        }\n    }\n\n    private void SetCloseUpViewing()\n    {\n        enableDepthOfField = true;\n        dofFocusDistance = 2.0f; // Close focus\n        dofAperture = 2.8f;      // Shallow depth of field\n        dofFocalLength = 85.0f;  // Telephoto effect\n\n        enableBloom = false;     // Reduce bloom for close inspection\n        bloomIntensity = 0.1f;\n\n        enableMotionBlur = false; // Disable motion blur for detailed view\n        motionBlurIntensity = 0.0f;\n    }\n\n    private void SetWideShotViewing()\n    {\n        enableDepthOfField = true;\n        dofFocusDistance = 15.0f; // Medium distance focus\n        dofAperture = 8.0f;       // Deeper depth of field\n        dofFocalLength = 35.0f;   // Wide angle effect\n\n        enableBloom = true;       // Enhance overall scene\n        bloomIntensity = 0.3f;\n\n        enableMotionBlur = true;  // Add subtle motion blur\n        motionBlurIntensity = 0.2f;\n    }\n\n    private void SetDetailedInspectionViewing()\n    {\n        enableDepthOfField = true;\n        dofFocusDistance = 0.5f;  // Very close focus\n        dofAperture = 1.4f;       // Very shallow depth of field\n        dofFocalLength = 100.0f;  // Macro lens effect\n\n        enableColorGrading = true;\n        saturation = 1.2f;        // Enhance material details\n        contrast = 1.1f;          // Increase contrast for details\n\n        enableBloom = false;      // Reduce bloom for clarity\n        enableMotionBlur = false; // Disable motion blur for clarity\n    }\n\n    private void SetEnvironmentOverviewViewing()\n    {\n        enableDepthOfField = false; // No depth of field for overview\n        enableBloom = true;\n        bloomIntensity = 0.4f;      // Enhance environment\n        bloomThreshold = 0.8f;\n\n        enableColorGrading = true;\n        saturation = 0.9f;          // Slightly desaturated for overview\n        contrast = 1.0f;\n\n        enableMotionBlur = true;    // Add motion blur for dynamic scenes\n        motionBlurIntensity = 0.3f;\n    }\n\n    private void SetDefaultViewing()\n    {\n        enableDepthOfField = true;\n        dofFocusDistance = 10.0f;\n        dofAperture = 5.6f;\n        dofFocalLength = 50.0f;\n\n        enableColorGrading = true;\n        saturation = 1.0f;\n        contrast = 1.0f;\n\n        enableBloom = true;\n        bloomIntensity = 0.5f;\n        bloomThreshold = 1.0f;\n\n        enableMotionBlur = true;\n        motionBlurIntensity = 0.5f;\n\n        enableChromaticAberration = true;\n        chromaticAberrationIntensity = 0.1f;\n    }\n}\n'})}),"\n",(0,a.jsx)(e.h3,{id:"custom-post-processing-effect-for-robot-vision",children:"Custom Post-Processing Effect for Robot Vision"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-hlsl",children:'// Robot Vision Post-Processing Shader\nShader "Custom/RobotVisionEffect"\n{\n    Properties\n    {\n        _MainTex ("Texture", 2D) = "white" {}\n        _EdgeColor ("Edge Color", Color) = (1, 1, 1, 1)\n        _EdgeThreshold ("Edge Threshold", Range(0.0, 1.0)) = 0.1\n        _RobotVisionIntensity ("Robot Vision Intensity", Range(0.0, 1.0)) = 0.5\n        _GridSize ("Grid Size", Float) = 64\n        _GridColor ("Grid Color", Color) = (0, 1, 0, 0.2)\n    }\n    SubShader\n    {\n        Cull Off ZWrite Off ZTest Always\n\n        Pass\n        {\n            HLSLPROGRAM\n            #pragma vertex vert\n            #pragma fragment frag\n\n            #include "UnityCG.cginc"\n\n            struct appdata\n            {\n                float4 vertex : POSITION;\n                float2 uv : TEXCOORD0;\n            };\n\n            struct v2f\n            {\n                float2 uv : TEXCOORD0;\n                float4 vertex : SV_POSITION;\n            };\n\n            v2f vert (appdata v)\n            {\n                v2f o;\n                o.vertex = UnityObjectToClipPos(v.vertex);\n                o.uv = v.uv;\n                return o;\n            }\n\n            sampler2D _MainTex;\n            float4 _MainTex_TexelSize;\n            float4 _EdgeColor;\n            float _EdgeThreshold;\n            float _RobotVisionIntensity;\n            float _GridSize;\n            float4 _GridColor;\n\n            fixed4 frag (v2f i) : SV_Target\n            {\n                // Sample the main texture\n                fixed4 col = tex2D(_MainTex, i.uv);\n\n                // Edge detection\n                float2 dx = float2(_MainTex_TexelSize.x, 0.0);\n                float2 dy = float2(0.0, _MainTex_TexelSize.y);\n\n                float3 center = tex2D(_MainTex, i.uv).rgb;\n                float3 left = tex2D(_MainTex, i.uv - dx).rgb;\n                float3 right = tex2D(_MainTex, i.uv + dx).rgb;\n                float3 up = tex2D(_MainTex, i.uv - dy).rgb;\n                float3 down = tex2D(_MainTex, i.uv + dy).rgb;\n\n                float3 gradientX = (right - left);\n                float3 gradientY = (up - down);\n                float gradientMagnitude = length(gradientX) + length(gradientY);\n\n                // Create edge effect\n                float edge = step(_EdgeThreshold, gradientMagnitude);\n                fixed3 edgeEffect = lerp(col.rgb, _EdgeColor.rgb, edge * _RobotVisionIntensity);\n\n                // Add grid overlay\n                float2 gridUV = i.uv * _GridSize;\n                float2 grid = abs(frac(gridUV) - 0.5);\n                float gridLine = min(grid.x, grid.y);\n                gridLine = step(0.45, gridLine);\n\n                // Combine effects\n                fixed3 finalColor = lerp(edgeEffect, _GridColor.rgb, gridLine * _GridColor.a * _RobotVisionIntensity);\n\n                return fixed4(finalColor, col.a);\n            }\n            ENDHLSL\n        }\n    }\n}\n'})}),"\n",(0,a.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,a.jsx)(e.p,{children:"Performance optimization is critical for real-time humanoid robot digital twins, especially when running complex simulations with multiple robots and detailed environments."}),"\n",(0,a.jsx)(e.h3,{id:"rendering-optimization-techniques",children:"Rendering Optimization Techniques"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing System.Collections.Generic;\n\npublic class HumanoidRobotRenderingOptimizer : MonoBehaviour\n{\n    [Header("LOD Configuration")]\n    public int lodCount = 4;\n    public float[] lodDistances = { 10.0f, 25.0f, 50.0f, 100.0f };\n    public bool enableLOD = true;\n\n    [Header("Occlusion Culling")]\n    public bool enableOcclusionCulling = true;\n    public float occlusionCheckInterval = 0.5f;\n\n    [Header("Dynamic Batching")]\n    public bool enableDynamicBatching = true;\n    public int maxBatchSize = 300;\n\n    [Header("Texture Streaming")]\n    public bool enableTextureStreaming = true;\n    public float textureQuality = 1.0f;\n\n    [Header("Shader Optimization")]\n    public bool enableShaderLOD = true;\n    public int shaderLODLevel = 300;\n\n    private Dictionary<Renderer, LODGroup> m_LODGroups = new Dictionary<Renderer, LODGroup>();\n    private Dictionary<Renderer, Material[]> m_OriginalMaterials = new Dictionary<Renderer, Material[]>();\n    private float m_LastOcclusionCheck = 0.0f;\n\n    void Start()\n    {\n        SetupOptimization();\n    }\n\n    void Update()\n    {\n        if (enableOcclusionCulling && Time.time - m_LastOcclusionCheck > occlusionCheckInterval)\n        {\n            CheckOcclusion();\n            m_LastOcclusionCheck = Time.time;\n        }\n\n        OptimizeRendering();\n    }\n\n    private void SetupOptimization()\n    {\n        // Set up global rendering settings\n        QualitySettings.anisotropicFiltering = AnisotropicFiltering.Enable;\n        QualitySettings.vSyncCount = 0; // Disable VSync for better performance\n        QualitySettings.maxQueuedFrames = 2;\n\n        if (enableTextureStreaming)\n        {\n            QualitySettings.streamingMipmapsActive = true;\n            QualitySettings.streamingMipmapsMemoryBudget = 512.0f; // 512 MB budget\n            QualitySettings.streamingMipmapsRenderersPerFrame = 512;\n            QualitySettings.streamingMipmapsMaxLevelReduction = 2;\n        }\n\n        // Create LOD groups for robot parts\n        if (enableLOD)\n        {\n            SetupLODGroups();\n        }\n\n        // Configure shader LOD\n        if (enableShaderLOD)\n        {\n            Shader.globalMaximumLOD = shaderLODLevel;\n        }\n    }\n\n    private void SetupLODGroups()\n    {\n        // Find all robot parts and set up LOD\n        GameObject[] robotParts = GameObject.FindGameObjectsWithTag("RobotPart");\n\n        foreach (GameObject part in robotParts)\n        {\n            Renderer renderer = part.GetComponent<Renderer>();\n            if (renderer != null)\n            {\n                // Store original materials for LOD switching\n                m_OriginalMaterials[renderer] = renderer.sharedMaterials;\n\n                // Create LOD group if needed\n                LODGroup lodGroup = part.GetComponent<LODGroup>();\n                if (lodGroup == null)\n                {\n                    lodGroup = part.AddComponent<LODGroup>();\n                    m_LODGroups[renderer] = lodGroup;\n\n                    // Create LOD levels\n                    LOD[] lods = new LOD[lodCount];\n                    for (int i = 0; i < lodCount; i++)\n                    {\n                        // Calculate screen relative transition height\n                        float screenRelativeTransitionHeight = (lodDistances[i] / 100.0f) * 0.5f;\n\n                        // Create renderer array for this LOD\n                        Renderer[] renderers = { renderer };\n\n                        lods[i] = new LOD(screenRelativeTransitionHeight, renderers);\n\n                        // Create simplified materials for lower LODs\n                        if (i > 0)\n                        {\n                            Material[] simplifiedMaterials = new Material[renderer.sharedMaterials.Length];\n                            for (int j = 0; j < renderer.sharedMaterials.Length; j++)\n                            {\n                                simplifiedMaterials[j] = CreateSimplifiedMaterial(renderer.sharedMaterials[j], i);\n                            }\n                            lods[i].renderers[0].sharedMaterials = simplifiedMaterials;\n                        }\n                    }\n\n                    lodGroup.SetLODs(lods);\n                    lodGroup.RecalculateBounds();\n                }\n            }\n        }\n    }\n\n    private Material CreateSimplifiedMaterial(Material original, int lodLevel)\n    {\n        // Create a simplified version of the material based on LOD level\n        Material simplified = new Material(original.shader);\n\n        // Copy essential properties\n        simplified.color = original.color;\n        simplified.mainTexture = original.mainTexture;\n\n        // Reduce complexity for lower LODs\n        if (lodLevel >= 2)\n        {\n            // Remove expensive properties for very low LOD\n            simplified.EnableKeyword("_NORMALMAP_OFF");\n            simplified.EnableKeyword("_EMISSION_OFF");\n            simplified.EnableKeyword("_DETAIL_OFF");\n        }\n\n        if (lodLevel >= 3)\n        {\n            // Further simplify for lowest LOD\n            simplified.SetFloat("_Metallic", 0.0f); // Remove metallic effect\n            simplified.SetFloat("_Smoothness", 0.5f); // Use default smoothness\n        }\n\n        return simplified;\n    }\n\n    private void CheckOcclusion()\n    {\n        // Perform occlusion queries for robot parts\n        foreach (Renderer renderer in m_OriginalMaterials.Keys)\n        {\n            if (renderer != null)\n            {\n                // Check if renderer is visible\n                bool isVisible = IsRendererVisible(renderer);\n\n                // Adjust rendering based on visibility\n                renderer.enabled = isVisible;\n            }\n        }\n    }\n\n    private bool IsRendererVisible(Renderer renderer)\n    {\n        // Check if renderer is in camera frustum\n        Plane[] planes = GeometryUtility.CalculateFrustumPlanes(Camera.main);\n        return GeometryUtility.TestPlanesAABB(planes, renderer.bounds);\n    }\n\n    private void OptimizeRendering()\n    {\n        // Update LOD groups based on camera distance\n        if (enableLOD)\n        {\n            UpdateLODGroups();\n        }\n\n        // Optimize shader properties based on distance\n        OptimizeShaderProperties();\n\n        // Manage texture streaming\n        if (enableTextureStreaming)\n        {\n            OptimizeTextureStreaming();\n        }\n    }\n\n    private void UpdateLODGroups()\n    {\n        Camera mainCamera = Camera.main;\n        if (mainCamera == null) return;\n\n        foreach (var kvp in m_LODGroups)\n        {\n            Renderer renderer = kvp.Key;\n            LODGroup lodGroup = kvp.Value;\n\n            if (renderer != null && lodGroup != null)\n            {\n                // Calculate distance from camera\n                float distance = Vector3.Distance(mainCamera.transform.position, renderer.bounds.center);\n\n                // Update LOD based on distance\n                int lodLevel = 0;\n                for (int i = 0; i < lodDistances.Length; i++)\n                {\n                    if (distance > lodDistances[i])\n                    {\n                        lodLevel = i + 1;\n                    }\n                    else\n                    {\n                        break;\n                    }\n                }\n\n                // Clamp to valid range\n                lodLevel = Mathf.Min(lodLevel, lodCount - 1);\n\n                // Set the current LOD\n                lodGroup.ForceLOD(lodLevel);\n            }\n        }\n    }\n\n    private void OptimizeShaderProperties()\n    {\n        // Optimize shader properties based on current quality settings\n        Shader.SetGlobalFloat("_OptimizationLevel", textureQuality);\n\n        // Adjust various shader parameters based on performance needs\n        if (QualitySettings.GetQualityLevel() <= 1) // Low quality\n        {\n            Shader.SetGlobalFloat("_ShadowQuality", 0.5f);\n            Shader.SetGlobalFloat("_ReflectionQuality", 0.3f);\n            Shader.SetGlobalFloat("_PostProcessingQuality", 0.5f);\n        }\n        else if (QualitySettings.GetQualityLevel() >= 4) // High quality\n        {\n            Shader.SetGlobalFloat("_ShadowQuality", 1.0f);\n            Shader.SetGlobalFloat("_ReflectionQuality", 1.0f);\n            Shader.SetGlobalFloat("_PostProcessingQuality", 1.0f);\n        }\n        else // Medium quality\n        {\n            Shader.SetGlobalFloat("_ShadowQuality", 0.7f);\n            Shader.SetGlobalFloat("_ReflectionQuality", 0.7f);\n            Shader.SetGlobalFloat("_PostProcessingQuality", 0.7f);\n        }\n    }\n\n    private void OptimizeTextureStreaming()\n    {\n        // Adjust texture streaming based on available memory\n        float availableMemory = SystemInfo.graphicsMemorySize / 1024.0f; // MB\n\n        if (availableMemory < 2048.0f) // Less than 2GB\n        {\n            QualitySettings.streamingMipmapsMemoryBudget = 256.0f; // Reduce budget\n            textureQuality = 0.7f;\n        }\n        else if (availableMemory > 8192.0f) // More than 8GB\n        {\n            QualitySettings.streamingMipmapsMemoryBudget = 1024.0f; // Increase budget\n            textureQuality = 1.0f;\n        }\n        else\n        {\n            QualitySettings.streamingMipmapsMemoryBudget = 512.0f;\n            textureQuality = 0.8f;\n        }\n    }\n\n    // Method to get rendering performance metrics\n    public RenderingPerformanceMetrics GetPerformanceMetrics()\n    {\n        RenderingPerformanceMetrics metrics = new RenderingPerformanceMetrics();\n\n        metrics.triangleCount = 0;\n        metrics.drawCallCount = UnityEngine.Rendering.UnityStats.drawCalls;\n        metrics.renderingTime = UnityEngine.Rendering.UnityStats.renderTime;\n        metrics.shadowCasters = UnityEngine.Rendering.UnityStats.shadowCasters;\n\n        // Calculate triangle count for robot parts\n        GameObject[] robotParts = GameObject.FindGameObjectsWithTag("RobotPart");\n        foreach (GameObject part in robotParts)\n        {\n            MeshFilter meshFilter = part.GetComponent<MeshFilter>();\n            if (meshFilter != null && meshFilter.sharedMesh != null)\n            {\n                metrics.triangleCount += meshFilter.sharedMesh.triangles.Length / 3;\n            }\n        }\n\n        return metrics;\n    }\n}\n\n[System.Serializable]\npublic class RenderingPerformanceMetrics\n{\n    public int triangleCount;\n    public int drawCallCount;\n    public float renderingTime;\n    public int shadowCasters;\n    public float averageFrameTime;\n    public float peakMemoryUsage;\n}\n'})}),"\n",(0,a.jsx)(e.h3,{id:"performance-monitoring-system",children:"Performance Monitoring System"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing UnityEngine.UI;\nusing System.Collections.Generic;\n\npublic class PerformanceMonitor : MonoBehaviour\n{\n    [Header("Performance UI")]\n    public Text performanceText;\n    public Slider qualitySlider;\n\n    [Header("Performance Thresholds")]\n    public float targetFrameRate = 60.0f;\n    public float warningFrameRate = 30.0f;\n    public float criticalFrameRate = 15.0f;\n\n    private List<float> frameTimes = new List<float>();\n    private const int frameHistoryCount = 60; // Last 60 frames\n\n    void Start()\n    {\n        if (qualitySlider != null)\n        {\n            qualitySlider.onValueChanged.AddListener(OnQualityChanged);\n        }\n    }\n\n    void Update()\n    {\n        UpdatePerformanceMetrics();\n        UpdatePerformanceUI();\n    }\n\n    private void UpdatePerformanceMetrics()\n    {\n        // Add current frame time to history\n        float currentFrameTime = Time.unscaledDeltaTime;\n        frameTimes.Add(currentFrameTime);\n\n        // Keep only the last N frame times\n        if (frameTimes.Count > frameHistoryCount)\n        {\n            frameTimes.RemoveAt(0);\n        }\n    }\n\n    private void UpdatePerformanceUI()\n    {\n        if (performanceText != null)\n        {\n            float avgFrameTime = GetAverageFrameTime();\n            float avgFrameRate = avgFrameTime > 0 ? 1.0f / avgFrameTime : 0;\n\n            float minFrameTime = GetMinFrameTime();\n            float maxFrameTime = GetMaxFrameTime();\n            float minFrameRate = minFrameTime > 0 ? 1.0f / minFrameTime : 0;\n            float maxFrameRate = maxFrameTime > 0 ? 1.0f / maxFrameTime : 0;\n\n            string performanceInfo = $"Frame Rate: {avgFrameRate:F1} FPS\\n" +\n                                   $"Avg Frame Time: {avgFrameTime * 1000:F1} ms\\n" +\n                                   $"Min/Max: {minFrameRate:F1}/{maxFrameRate:F1} FPS\\n" +\n                                   $"Draw Calls: {UnityEngine.Rendering.UnityStats.drawCalls}\\n" +\n                                   $"Triangles: {UnityEngine.Rendering.UnityStats.triangles}\\n" +\n                                   $"Shadow Casters: {UnityEngine.Rendering.UnityStats.shadowCasters}\\n" +\n                                   $"Memory: {UnityEngine.Profiling.Profiler.GetTotalAllocatedMemoryLong() / (1024 * 1024)} MB";\n\n            performanceText.text = performanceInfo;\n\n            // Color code based on performance\n            if (avgFrameRate < criticalFrameRate)\n            {\n                performanceText.color = Color.red;\n            }\n            else if (avgFrameRate < warningFrameRate)\n            {\n                performanceText.color = Color.yellow;\n            }\n            else\n            {\n                performanceText.color = Color.green;\n            }\n        }\n    }\n\n    private float GetAverageFrameTime()\n    {\n        if (frameTimes.Count == 0) return 0;\n\n        float sum = 0;\n        foreach (float time in frameTimes)\n        {\n            sum += time;\n        }\n        return sum / frameTimes.Count;\n    }\n\n    private float GetMinFrameTime()\n    {\n        if (frameTimes.Count == 0) return 0;\n\n        float min = float.MaxValue;\n        foreach (float time in frameTimes)\n        {\n            if (time < min) min = time;\n        }\n        return min;\n    }\n\n    private float GetMaxFrameTime()\n    {\n        if (frameTimes.Count == 0) return 0;\n\n        float max = 0;\n        foreach (float time in frameTimes)\n        {\n            if (time > max) max = time;\n        }\n        return max;\n    }\n\n    private void OnQualityChanged(float quality)\n    {\n        // Adjust quality settings based on slider value\n        int qualityLevel = Mathf.RoundToInt(quality * (QualitySettings.names.Length - 1));\n        QualitySettings.SetQualityLevel(qualityLevel);\n\n        // Adjust rendering optimization parameters\n        HumanoidRobotRenderingOptimizer optimizer = FindObjectOfType<HumanoidRobotRenderingOptimizer>();\n        if (optimizer != null)\n        {\n            optimizer.textureQuality = quality;\n        }\n    }\n}\n'})}),"\n",(0,a.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(e.p,{children:"Unity rendering techniques for humanoid robot digital twins require a comprehensive approach that balances visual quality with performance. The implementation involves several key components:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Graphics Pipeline"}),": Custom render passes and SRP configuration for specialized robot rendering needs"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Materials and Shaders"}),": PBR implementation with robot-specific surface properties and detailed material systems"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Lighting Systems"}),": Realistic lighting setups with scenario-based configurations for different environments"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Post-Processing Effects"}),": Advanced visual effects for enhanced realism and specialized robot vision modes"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Performance Optimization"}),": LOD systems, occlusion culling, and real-time performance monitoring"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"The technical implementation includes C# scripts for managing complex rendering systems, HLSL shaders for custom visual effects, and comprehensive optimization techniques. These systems work together to create realistic digital twins that accurately represent humanoid robots in various environments while maintaining real-time performance."}),"\n",(0,a.jsx)(e.p,{children:"The modular architecture allows for easy customization based on specific robot designs and simulation requirements. The system supports multiple viewing scenarios, dynamic lighting conditions, and real-time performance adjustments to ensure optimal visual quality across different hardware configurations."})]})}function c(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(m,{...n})}):m(n)}},8453(n,e,i){i.d(e,{R:()=>o,x:()=>l});var t=i(6540);const a={},r=t.createContext(a);function o(n){const e=t.useContext(r);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),t.createElement(r.Provider,{value:e},n.children)}}}]);