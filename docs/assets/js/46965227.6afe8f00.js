"use strict";(globalThis.webpackChunkclassic=globalThis.webpackChunkclassic||[]).push([[5276],{2639(n,e,i){i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-2/physics-collisions","title":"Physics and Collisions: Advanced Simulation for Digital Twins of Humanoid Robots","description":"Introduction to Physics Simulation for Digital Twins","source":"@site/docs/module-2/physics-collisions.md","sourceDirName":"module-2","slug":"/module-2/physics-collisions","permalink":"/ebsite/docs/docs/module-2/physics-collisions","draft":false,"unlisted":false,"editUrl":"https://github.com/sherazi-412002/ai-native-sdd-books/tree/main/docs/module-2/physics-collisions.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"curriculumSidebar","previous":{"title":"Module 2: The Digital Twin (Gazebo & Unity)","permalink":"/ebsite/docs/docs/category/module-2-the-digital-twin-gazebo--unity"},"next":{"title":"Unity Rendering","permalink":"/ebsite/docs/docs/module-2/unity-rendering"}}');var o=i(4848),s=i(8453);const a={sidebar_position:1},r="Physics and Collisions: Advanced Simulation for Digital Twins of Humanoid Robots",l={},c=[{value:"Introduction to Physics Simulation for Digital Twins",id:"introduction-to-physics-simulation-for-digital-twins",level:2},{value:"Theoretical Foundation of Physics Simulation",id:"theoretical-foundation-of-physics-simulation",level:2},{value:"Physics Engine Fundamentals",id:"physics-engine-fundamentals",level:3},{value:"Rigid Body Dynamics",id:"rigid-body-dynamics",level:4},{value:"Constraint Solving",id:"constraint-solving",level:4},{value:"Time Integration",id:"time-integration",level:4},{value:"Collision Detection Theory",id:"collision-detection-theory",level:3},{value:"Broad Phase",id:"broad-phase",level:4},{value:"Narrow Phase",id:"narrow-phase",level:4},{value:"Continuous Collision Detection (CCD)",id:"continuous-collision-detection-ccd",level:4},{value:"Advanced Physics Engine Implementation",id:"advanced-physics-engine-implementation",level:2},{value:"NVIDIA PhysX Configuration for Humanoid Simulation",id:"nvidia-physx-configuration-for-humanoid-simulation",level:3},{value:"Collision Detection Algorithms and Implementation",id:"collision-detection-algorithms-and-implementation",level:2},{value:"Advanced Collision Detection for Humanoid Robots",id:"advanced-collision-detection-for-humanoid-robots",level:3},{value:"Contact Simulation and Friction Modeling",id:"contact-simulation-and-friction-modeling",level:2},{value:"Contact Models for Humanoid Robots",id:"contact-models-for-humanoid-robots",level:3},{value:"Performance Optimization for Real-time Simulation",id:"performance-optimization-for-real-time-simulation",level:2},{value:"Integration with NVIDIA Isaac Sim",id:"integration-with-nvidia-isaac-sim",level:2},{value:"Summary",id:"summary",level:2},{value:"Advanced Topics in Humanoid Physics Simulation",id:"advanced-topics-in-humanoid-physics-simulation",level:2},{value:"Multi-Body Dynamics for Humanoid Robots",id:"multi-body-dynamics-for-humanoid-robots",level:3},{value:"Real-time Physics Simulation Considerations",id:"real-time-physics-simulation-considerations",level:3},{value:"Isaac Sim Performance Tuning",id:"isaac-sim-performance-tuning",level:3},{value:"Advanced Contact Modeling for Humanoid Locomotion",id:"advanced-contact-modeling-for-humanoid-locomotion",level:3},{value:"Conclusion",id:"conclusion",level:2}];function _(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"physics-and-collisions-advanced-simulation-for-digital-twins-of-humanoid-robots",children:"Physics and Collisions: Advanced Simulation for Digital Twins of Humanoid Robots"})}),"\n",(0,o.jsx)(e.h2,{id:"introduction-to-physics-simulation-for-digital-twins",children:"Introduction to Physics Simulation for Digital Twins"}),"\n",(0,o.jsx)(e.p,{children:"Physics simulation in digital twin environments is fundamental for creating realistic representations of humanoid robots. The digital twin must accurately reflect the physical behavior of the real robot, including its interactions with the environment, to enable effective testing, validation, and development of control algorithms. For humanoid robots, which have complex multi-link structures with numerous degrees of freedom, physics simulation becomes particularly challenging due to the need to accurately model contacts, collisions, and dynamic interactions."}),"\n",(0,o.jsx)(e.p,{children:"Digital twin physics simulation serves multiple purposes:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Validation"}),": Testing control algorithms in a realistic simulated environment before deployment"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Safety"}),": Identifying potential issues without risking physical hardware"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Optimization"}),": Tuning parameters and improving performance in a controlled environment"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Training"}),": Developing AI models and machine learning algorithms"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"theoretical-foundation-of-physics-simulation",children:"Theoretical Foundation of Physics Simulation"}),"\n",(0,o.jsx)(e.h3,{id:"physics-engine-fundamentals",children:"Physics Engine Fundamentals"}),"\n",(0,o.jsx)(e.p,{children:"Physics engines for robotics simulation typically implement the following core components:"}),"\n",(0,o.jsx)(e.h4,{id:"rigid-body-dynamics",children:"Rigid Body Dynamics"}),"\n",(0,o.jsx)(e.p,{children:"The simulation of rigid bodies is governed by Newton-Euler equations of motion. For each link in a humanoid robot, the physics engine calculates:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Translational motion: F = ma"}),"\n",(0,o.jsx)(e.li,{children:"Rotational motion: \u03c4 = I\u03b1 + \u03c9 \xd7 (I\u03c9)"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"Where F is force, m is mass, a is acceleration, \u03c4 is torque, I is the inertia tensor, \u03b1 is angular acceleration, and \u03c9 is angular velocity."}),"\n",(0,o.jsx)(e.h4,{id:"constraint-solving",children:"Constraint Solving"}),"\n",(0,o.jsx)(e.p,{children:"Joints in humanoid robots impose constraints between links. The physics engine must solve these constraints while maintaining:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Joint limits"}),"\n",(0,o.jsx)(e.li,{children:"Closed-loop kinematic chains"}),"\n",(0,o.jsx)(e.li,{children:"Contact constraints"}),"\n",(0,o.jsx)(e.li,{children:"Actuator forces and torques"}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"time-integration",children:"Time Integration"}),"\n",(0,o.jsx)(e.p,{children:"Physics engines use numerical integration methods to advance the simulation through time. Common approaches include:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Explicit Euler (fast but unstable)"}),"\n",(0,o.jsx)(e.li,{children:"Implicit Euler (stable but computationally expensive)"}),"\n",(0,o.jsx)(e.li,{children:"Runge-Kutta methods (balanced accuracy and stability)"}),"\n",(0,o.jsx)(e.li,{children:"Symplectic integrators (energy-conserving)"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"collision-detection-theory",children:"Collision Detection Theory"}),"\n",(0,o.jsx)(e.p,{children:"Collision detection in physics engines typically involves a multi-stage process:"}),"\n",(0,o.jsx)(e.h4,{id:"broad-phase",children:"Broad Phase"}),"\n",(0,o.jsx)(e.p,{children:"Quickly identifies pairs of objects that might be colliding using spatial partitioning techniques:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Axis-Aligned Bounding Box (AABB) trees"}),"\n",(0,o.jsx)(e.li,{children:"Spatial hashing"}),"\n",(0,o.jsx)(e.li,{children:"Grid-based partitioning"}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"narrow-phase",children:"Narrow Phase"}),"\n",(0,o.jsx)(e.p,{children:"Precisely determines if and where collisions occur between potential pairs:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"GJK algorithm for convex shapes"}),"\n",(0,o.jsx)(e.li,{children:"SAT (Separating Axis Theorem) for polyhedra"}),"\n",(0,o.jsx)(e.li,{children:"Ray casting for specific intersection tests"}),"\n"]}),"\n",(0,o.jsx)(e.h4,{id:"continuous-collision-detection-ccd",children:"Continuous Collision Detection (CCD)"}),"\n",(0,o.jsx)(e.p,{children:"Prevents tunneling effects by detecting collisions that might occur between discrete time steps:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Conservative advancement"}),"\n",(0,o.jsx)(e.li,{children:"Speculative advancement"}),"\n",(0,o.jsx)(e.li,{children:"Posteriori collision detection"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"advanced-physics-engine-implementation",children:"Advanced Physics Engine Implementation"}),"\n",(0,o.jsx)(e.h3,{id:"nvidia-physx-configuration-for-humanoid-simulation",children:"NVIDIA PhysX Configuration for Humanoid Simulation"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-cpp",children:'#include <PxPhysicsAPI.h>\n#include <extensions/PxExtensions.h>\n#include <vehicle/PxVehicleAPI.h>\n#include <iostream>\n\nusing namespace physx;\n\nclass HumanoidPhysicsSimulator {\nprivate:\n    PxFoundation* foundation;\n    PxPhysics* physics;\n    PxScene* scene;\n    PxMaterial* material;\n\n    // Humanoid robot actors\n    std::vector<PxRigidDynamic*> humanoid_links;\n    std::vector<PxJoint*> humanoid_joints;\n\n    // Simulation parameters\n    PxReal timestep;\n    PxU32 substeps;\n    PxVec3 gravity;\n\npublic:\n    HumanoidPhysicsSimulator() : timestep(0.001f), substeps(1), gravity(PxVec3(0.0f, -9.81f, 0.0f)) {\n        // Foundation setup\n        foundation = PxCreateFoundation(PX_PHYSICS_VERSION, allocator, error_callback);\n\n        // Physics creation\n        physics = PxCreatePhysics(PX_PHYSICS_VERSION, *foundation, PxTolerancesScale(), true, nullptr);\n\n        // Extensions initialization\n        PxInitExtensions(*physics);\n\n        // Material for contacts\n        material = physics->createMaterial(0.5f, 0.5f, 0.1f); // static, dynamic, restitution\n\n        // Scene creation with advanced parameters\n        PxSceneDesc scene_desc(physics->getTolerancesScale());\n        scene_desc.gravity = gravity;\n\n        // Advanced solver settings for humanoid simulation\n        scene_desc.solverType = PxSolverType::eTGS;  // Temporal Gauss-Seidel solver\n        scene_desc.broadPhaseType = PxBroadPhaseType::eABP;  // Accelerated Broad Phase\n        scene_desc.simulationEventCallback = nullptr;  // Event callbacks for contacts\n        scene_desc.flags |= PxSceneFlag::eENABLE_CCD;  // Enable Continuous Collision Detection\n        scene_desc.flags |= PxSceneFlag::eENABLE_PCM;  // Enable Projection Contact Model\n\n        // Solver parameters optimized for humanoid robots\n        scene_desc.solverIterationCounts.minPositionIters = 4;   // Position iterations\n        scene_desc.solverIterationCounts.minVelocityIters = 1;   // Velocity iterations\n        scene_desc.solverOffsetSlop = 0.001f;                   // Contact offset slop\n\n        scene = physics->createScene(scene_desc);\n\n        // CPU dispatcher for multithreading\n        cpu_dispatcher = PxDefaultCpuDispatcherCreate(4); // 4 threads\n        scene->setCpuDispatcher(cpu_dispatcher);\n\n        std::cout << "Humanoid Physics Simulator initialized with advanced parameters" << std::endl;\n    }\n\n    ~HumanoidPhysicsSimulator() {\n        if (scene) scene->release();\n        if (cpu_dispatcher) cpu_dispatcher->release();\n        if (material) material->release();\n        if (physics) PxCloseExtensions();\n        if (physics) physics->release();\n        if (foundation) foundation->release();\n    }\n\n    void createHumanoidRobot() {\n        // Create base/torso link\n        PxTransform base_transform(PxVec3(0.0f, 1.0f, 0.0f)); // Start slightly above ground\n        PxRigidDynamic* base_link = createCapsuleActor(base_transform, 0.15f, 0.4f, 10.0f); // Torso\n        humanoid_links.push_back(base_link);\n\n        // Create head link\n        PxTransform head_transform(PxVec3(0.0f, 0.0f, 0.5f)); // Relative to torso\n        PxRigidDynamic* head_link = createSphereActor(head_transform.transform(base_transform), 0.12f, 2.0f);\n        humanoid_links.push_back(head_link);\n\n        // Create left arm\n        createArmChain(true, base_transform);\n\n        // Create right arm (mirrored)\n        createArmChain(false, base_transform);\n\n        // Create left leg\n        createLegChain(true, base_transform);\n\n        // Create right leg (mirrored)\n        createLegChain(false, base_transform);\n\n        // Add all actors to scene\n        for (auto& link : humanoid_links) {\n            scene->addActor(*link);\n        }\n\n        std::cout << "Humanoid robot model created with " << humanoid_links.size() << " links" << std::endl;\n    }\n\n    PxRigidDynamic* createCapsuleActor(const PxTransform& transform, PxReal radius, PxReal half_height, PxReal mass) {\n        PxRigidDynamic* actor = PxCreateDynamic(*physics, transform, PxSphereGeometry(radius), *material, 1.0f);\n\n        // Set capsule geometry (approximate with sphere for now, in real implementation would use proper capsule)\n        PxShape* shape;\n        PxU32 nb_shapes = actor->getNbShapes();\n        actor->getShapes(&shape, nb_shapes);\n\n        // Create proper capsule geometry\n        PxTransform local_transform(PxIdentity);\n        PxReal density = mass / (PxPi * radius * radius * 2.0f * half_height + 4.0f/3.0f * PxPi * radius * radius * radius); // Approximate density\n\n        // Recreate with proper mass and geometry\n        actor->setMass(mass);\n        actor->setCMassLocalPose(PxTransform(PxVec3(0.0f, 0.0f, 0.0f)));\n\n        // Set appropriate moment of inertia for capsule\n        PxVec3 moi(0.25f * mass * (radius*radius + half_height*half_height/3.0f),\n                   0.25f * mass * (radius*radius + half_height*half_height/3.0f),\n                   0.5f * mass * radius * radius);\n        actor->setMassSpaceInertiaTensor(moi);\n\n        return actor;\n    }\n\n    PxRigidDynamic* createSphereActor(const PxTransform& transform, PxReal radius, PxReal mass) {\n        PxRigidDynamic* actor = PxCreateDynamic(*physics, transform, PxSphereGeometry(radius), *material, 1.0f);\n        actor->setMass(mass);\n\n        // Moment of inertia for sphere: (2/5) * m * r\xb2\n        PxReal moi_value = 0.4f * mass * radius * radius;\n        actor->setMassSpaceInertiaTensor(PxVec3(moi_value, moi_value, moi_value));\n\n        return actor;\n    }\n\n    void createArmChain(bool is_left, const PxTransform& base_transform) {\n        PxReal sign = is_left ? 1.0f : -1.0f;\n        PxVec3 offset(0.0f, 0.15f * sign, 0.7f); // Shoulder position relative to base\n\n        // Create shoulder joints and links\n        PxTransform shoulder_transform = base_transform.transform(offset);\n        PxRigidDynamic* shoulder_link = createCapsuleActor(shoulder_transform, 0.06f, 0.15f, 1.5f);\n        humanoid_links.push_back(shoulder_link);\n\n        // Upper arm\n        PxTransform upper_arm_transform = shoulder_transform.transform(PxVec3(0.0f, 0.0f, -0.3f));\n        PxRigidDynamic* upper_arm_link = createCapsuleActor(upper_arm_transform, 0.06f, 0.15f, 1.5f);\n        humanoid_links.push_back(upper_arm_link);\n\n        // Lower arm\n        PxTransform lower_arm_transform = upper_arm_transform.transform(PxVec3(0.0f, 0.0f, -0.3f));\n        PxRigidDynamic* lower_arm_link = createCapsuleActor(lower_arm_transform, 0.05f, 0.15f, 1.0f);\n        humanoid_links.push_back(lower_arm_link);\n\n        // Hand\n        PxTransform hand_transform = lower_arm_transform.transform(PxVec3(0.0f, 0.0f, -0.3f));\n        PxRigidDynamic* hand_link = createSphereActor(hand_transform, 0.05f, 0.3f);\n        humanoid_links.push_back(hand_link);\n\n        // Create joints between arm segments (in real implementation would use proper joint constraints)\n        // This is a simplified representation\n    }\n\n    void createLegChain(bool is_left, const PxTransform& base_transform) {\n        PxReal sign = is_left ? 1.0f : -1.0f;\n        PxVec3 offset(0.0f, 0.08f * sign, 0.0f); // Hip position relative to base\n\n        // Create hip joints and links\n        PxTransform hip_transform = base_transform.transform(offset);\n        PxRigidDynamic* hip_link = createCapsuleActor(hip_transform, 0.08f, 0.05f, 0.5f);\n        humanoid_links.push_back(hip_link);\n\n        // Thigh\n        PxTransform thigh_transform = hip_transform.transform(PxVec3(0.0f, 0.0f, -0.4f));\n        PxRigidDynamic* thigh_link = createCapsuleActor(thigh_transform, 0.08f, 0.2f, 3.0f);\n        humanoid_links.push_back(thigh_link);\n\n        // Shin\n        PxTransform shin_transform = thigh_transform.transform(PxVec3(0.0f, 0.0f, -0.4f));\n        PxRigidDynamic* shin_link = createCapsuleActor(shin_transform, 0.07f, 0.2f, 2.5f);\n        humanoid_links.push_back(shin_link);\n\n        // Foot\n        PxTransform foot_transform = shin_transform.transform(PxVec3(0.05f, 0.0f, -0.4f));\n        PxRigidDynamic* foot_link = createBoxActor(foot_transform, PxVec3(0.09f, 0.05f, 0.02f), 1.0f);\n        humanoid_links.push_back(foot_link);\n    }\n\n    PxRigidDynamic* createBoxActor(const PxTransform& transform, const PxVec3& dimensions, PxReal mass) {\n        PxRigidDynamic* actor = PxCreateDynamic(*physics, transform, PxBoxGeometry(dimensions), *material, 1.0f);\n        actor->setMass(mass);\n\n        // Moment of inertia for box\n        PxReal dx = 2.0f * dimensions.x, dy = 2.0f * dimensions.y, dz = 2.0f * dimensions.z;\n        PxVec3 moi(mass/12.0f * (dy*dy + dz*dz),\n                   mass/12.0f * (dx*dx + dz*dz),\n                   mass/12.0f * (dx*dx + dy*dy));\n        actor->setMassSpaceInertiaTensor(moi);\n\n        return actor;\n    }\n\n    void simulateStep() {\n        scene->simulate(timestep / substeps);\n        scene->fetchResults(true); // Block until simulation completes\n    }\n\n    void setRobotConfiguration(const std::vector<PxReal>& joint_angles) {\n        // In a real implementation, this would update joint positions\n        // For now, this is a placeholder for setting robot pose\n    }\n\n    void applyControlInputs(const std::vector<PxVec3>& forces, const std::vector<PxVec3>& torques) {\n        // Apply control forces and torques to the robot links\n        for (size_t i = 0; i < humanoid_links.size() && i < forces.size(); ++i) {\n            humanoid_links[i]->addForce(forces[i], PxForceMode::eFORCE);\n            humanoid_links[i]->addTorque(torques[i]);\n        }\n    }\n\n    std::vector<PxTransform> getRobotStates() {\n        std::vector<PxTransform> states;\n        for (auto& link : humanoid_links) {\n            states.push_back(link->getGlobalPose());\n        }\n        return states;\n    }\n\n    void printSimulationInfo() {\n        std::cout << "=== Physics Simulation Info ===" << std::endl;\n        std::cout << "Timestep: " << timestep << "s" << std::endl;\n        std::cout << "Substeps: " << substeps << std::endl;\n        std::cout << "Gravity: [" << gravity.x << ", " << gravity.y << ", " << gravity.z << "]" << std::endl;\n        std::cout << "Number of actors in scene: " << scene->getNbActors(PxActorTypeFlag::eRIGID_DYNAMIC | PxActorTypeFlag::eRIGID_STATIC) << std::endl;\n        std::cout << "Number of humanoid links: " << humanoid_links.size() << std::endl;\n        std::cout << "=============================" << std::endl;\n    }\n\nprivate:\n    PxDefaultAllocator allocator;\n    PxDefaultErrorCallback error_callback;\n    PxCpuDispatcher* cpu_dispatcher;\n};\n\n// Example usage\nint main() {\n    HumanoidPhysicsSimulator simulator;\n    simulator.createHumanoidRobot();\n    simulator.printSimulationInfo();\n\n    // Main simulation loop\n    for (int i = 0; i < 1000; ++i) {\n        simulator.simulateStep();\n\n        if (i % 100 == 0) {\n            std::cout << "Simulation step: " << i << std::endl;\n        }\n    }\n\n    return 0;\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"collision-detection-algorithms-and-implementation",children:"Collision Detection Algorithms and Implementation"}),"\n",(0,o.jsx)(e.h3,{id:"advanced-collision-detection-for-humanoid-robots",children:"Advanced Collision Detection for Humanoid Robots"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"import numpy as np\nfrom typing import List, Tuple, Optional\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass CollisionType(Enum):\n    \"\"\"Types of collisions that can occur in humanoid simulation.\"\"\"\n    SELF_COLLISION = \"self_collision\"\n    ENVIRONMENT_COLLISION = \"environment_collision\"\n    GROUND_COLLISION = \"ground_collision\"\n    CONTACT_POINT = \"contact_point\"\n\n@dataclass\nclass CollisionInfo:\n    \"\"\"Information about a detected collision.\"\"\"\n    link_a: str\n    link_b: str\n    position: np.ndarray  # Collision point in world coordinates\n    normal: np.ndarray    # Normal vector pointing from A to B\n    depth: float          # Penetration depth\n    collision_type: CollisionType\n\nclass CollisionDetector:\n    \"\"\"Advanced collision detection system for humanoid robots.\"\"\"\n\n    def __init__(self, robot_links: List[str]):\n        self.robot_links = robot_links\n        self.collision_pairs = self._generate_collision_pairs()\n        self.contact_points = []\n\n        # Spatial partitioning for broad phase collision detection\n        self.spatial_grid = {}\n        self.grid_cell_size = 0.5  # meters\n\n        # Collision detection parameters\n        self.collision_margin = 0.001  # meters\n        self.contact_distance = 0.02   # Distance to consider contact\n\n        print(f\"Initialized collision detector for {len(robot_links)} links\")\n        print(f\"Generated {len(self.collision_pairs)} collision pairs\")\n\n    def _generate_collision_pairs(self) -> List[Tuple[str, str]]:\n        \"\"\"Generate all possible collision pairs, excluding impossible ones.\"\"\"\n        pairs = []\n\n        # Generate all combinations of links\n        for i, link_a in enumerate(self.robot_links):\n            for j, link_b in enumerate(self.robot_links):\n                if i >= j:  # Avoid duplicates and self-collisions\n                    continue\n\n                # Skip adjacent joints that are physically connected\n                # This is a simplified check - in reality, you'd have a kinematic tree\n                if self._are_adjacent_links(link_a, link_b):\n                    continue\n\n                pairs.append((link_a, link_b))\n\n        return pairs\n\n    def _are_adjacent_links(self, link_a: str, link_b: str) -> bool:\n        \"\"\"Check if two links are directly connected by a joint.\"\"\"\n        # Simplified adjacency check based on naming convention\n        # In a real implementation, this would use the kinematic tree\n        adjacent_pairs = [\n            ('base_link', 'head_link'),\n            ('base_link', 'left_shoulder_link'), ('base_link', 'right_shoulder_link'),\n            ('left_shoulder_link', 'left_upper_arm_link'), ('right_shoulder_link', 'right_upper_arm_link'),\n            ('left_upper_arm_link', 'left_lower_arm_link'), ('right_upper_arm_link', 'right_lower_arm_link'),\n            ('left_lower_arm_link', 'left_hand_link'), ('right_lower_arm_link', 'right_hand_link'),\n            ('base_link', 'left_hip_link'), ('base_link', 'right_hip_link'),\n            ('left_hip_link', 'left_thigh_link'), ('right_hip_link', 'right_thigh_link'),\n            ('left_thigh_link', 'left_shin_link'), ('right_thigh_link', 'right_shin_link'),\n            ('left_shin_link', 'left_foot_link'), ('right_shin_link', 'right_foot_link')\n        ]\n\n        return (link_a, link_b) in adjacent_pairs or (link_b, link_a) in adjacent_pairs\n\n    def update_robot_pose(self, link_poses: dict, link_geometries: dict):\n        \"\"\"Update the collision detection system with current robot pose.\"\"\"\n        # Update spatial grid with current link positions\n        self._update_spatial_grid(link_poses)\n\n        # Detect collisions\n        collisions = self._detect_collisions(link_poses, link_geometries)\n\n        return collisions\n\n    def _update_spatial_grid(self, link_poses: dict):\n        \"\"\"Update the spatial partitioning grid.\"\"\"\n        self.spatial_grid.clear()\n\n        for link_name, pose in link_poses.items():\n            # Calculate which grid cells this link occupies\n            position = pose['position']\n            bounding_radius = self._estimate_bounding_radius(link_poses[link_name]['geometry'])\n\n            min_cell = self._world_to_grid(position - bounding_radius)\n            max_cell = self._world_to_grid(position + bounding_radius)\n\n            # Add link to all occupied cells\n            for x in range(min_cell[0], max_cell[0] + 1):\n                for y in range(min_cell[1], max_cell[1] + 1):\n                    for z in range(min_cell[2], max_cell[2] + 1):\n                        cell_key = (x, y, z)\n                        if cell_key not in self.spatial_grid:\n                            self.spatial_grid[cell_key] = []\n                        self.spatial_grid[cell_key].append(link_name)\n\n    def _world_to_grid(self, world_pos: np.ndarray) -> Tuple[int, int, int]:\n        \"\"\"Convert world coordinates to grid cell coordinates.\"\"\"\n        x = int(world_pos[0] / self.grid_cell_size)\n        y = int(world_pos[1] / self.grid_cell_size)\n        z = int(world_pos[2] / self.grid_cell_size)\n        return (x, y, z)\n\n    def _estimate_bounding_radius(self, geometry: dict) -> float:\n        \"\"\"Estimate bounding radius for a geometry.\"\"\"\n        if geometry['type'] == 'sphere':\n            return geometry['radius']\n        elif geometry['type'] == 'capsule':\n            return max(geometry['radius'], geometry['length'] / 2.0)\n        elif geometry['type'] == 'box':\n            return np.linalg.norm(geometry['dimensions']) / 2.0\n        else:\n            return 0.1  # Default radius\n\n    def _detect_collisions(self, link_poses: dict, link_geometries: dict) -> List[CollisionInfo]:\n        \"\"\"Detect collisions between links using broad and narrow phase.\"\"\"\n        potential_collisions = self._broad_phase_collision_detection()\n        confirmed_collisions = []\n\n        for link_a, link_b in potential_collisions:\n            collision_info = self._narrow_phase_collision_detection(\n                link_a, link_b, link_poses, link_geometries\n            )\n\n            if collision_info:\n                confirmed_collisions.append(collision_info)\n\n        return confirmed_collisions\n\n    def _broad_phase_collision_detection(self) -> List[Tuple[str, str]]:\n        \"\"\"Broad phase collision detection using spatial partitioning.\"\"\"\n        overlapping_pairs = []\n\n        # Check each cell for potential overlaps\n        for cell_key, cell_links in self.spatial_grid.items():\n            if len(cell_links) < 2:\n                continue\n\n            # Check all combinations within this cell\n            for i, link_a in enumerate(cell_links):\n                for j, link_b in enumerate(cell_links):\n                    if i >= j:\n                        continue\n\n                    # Verify this pair should be checked\n                    if (link_a, link_b) in self.collision_pairs or (link_b, link_a) in self.collision_pairs:\n                        overlapping_pairs.append((link_a, link_b))\n\n        return overlapping_pairs\n\n    def _narrow_phase_collision_detection(\n        self,\n        link_a: str,\n        link_b: str,\n        link_poses: dict,\n        link_geometries: dict\n    ) -> Optional[CollisionInfo]:\n        \"\"\"Narrow phase collision detection between two specific links.\"\"\"\n        pose_a = link_poses[link_a]\n        pose_b = link_poses[link_b]\n        geom_a = link_geometries[link_a]\n        geom_b = link_geometries[link_b]\n\n        # Perform collision detection based on geometry types\n        if geom_a['type'] == 'sphere' and geom_b['type'] == 'sphere':\n            return self._sphere_sphere_collision(pose_a, geom_a, pose_b, geom_b, link_a, link_b)\n        elif geom_a['type'] == 'capsule' and geom_b['type'] == 'capsule':\n            return self._capsule_capsule_collision(pose_a, geom_a, pose_b, geom_b, link_a, link_b)\n        elif geom_a['type'] == 'box' and geom_b['type'] == 'box':\n            return self._box_box_collision(pose_a, geom_a, pose_b, geom_b, link_a, link_b)\n        elif (geom_a['type'] == 'capsule' and geom_b['type'] == 'sphere') or \\\n             (geom_a['type'] == 'sphere' and geom_b['type'] == 'capsule'):\n            return self._capsule_sphere_collision(pose_a, geom_a, pose_b, geom_b, link_a, link_b)\n        else:\n            # For mixed types, approximate with spheres\n            return self._sphere_sphere_collision(pose_a, geom_a, pose_b, geom_b, link_a, link_b)\n\n    def _sphere_sphere_collision(\n        self,\n        pose_a: dict,\n        geom_a: dict,\n        pose_b: dict,\n        geom_b: dict,\n        link_a: str,\n        link_b: str\n    ) -> Optional[CollisionInfo]:\n        \"\"\"Detect collision between two spheres.\"\"\"\n        pos_a = pose_a['position']\n        pos_b = pose_b['position']\n        radius_a = geom_a['radius']\n        radius_b = geom_b['radius']\n\n        distance = np.linalg.norm(pos_b - pos_a)\n        min_distance = radius_a + radius_b + self.collision_margin\n\n        if distance < min_distance:\n            # Calculate collision point and normal\n            normal = (pos_b - pos_a) / distance if distance > 0 else np.array([0, 0, 1])\n            penetration_depth = min_distance - distance\n\n            # Collision point is along the line connecting centers\n            collision_point = pos_a + normal * radius_a\n\n            return CollisionInfo(\n                link_a=link_a,\n                link_b=link_b,\n                position=collision_point,\n                normal=normal,\n                depth=penetration_depth,\n                collision_type=CollisionType.SELF_COLLISION\n            )\n\n        return None\n\n    def _capsule_capsule_collision(\n        self,\n        pose_a: dict,\n        geom_a: dict,\n        pose_b: dict,\n        geom_b: dict,\n        link_a: str,\n        link_b: str\n    ) -> Optional[CollisionInfo]:\n        \"\"\"Detect collision between two capsules.\"\"\"\n        # Get capsule parameters\n        pos_a = pose_a['position']\n        rot_a = pose_a['orientation']  # As quaternion [w, x, y, z]\n        radius_a = geom_a['radius']\n        length_a = geom_a['length']\n\n        pos_b = pose_b['position']\n        rot_b = pose_b['orientation']\n        radius_b = geom_b['radius']\n        length_b = geom_b['length']\n\n        # Convert quaternions to rotation matrices\n        rot_mat_a = self._quaternion_to_matrix(rot_a)\n        rot_mat_b = self._quaternion_to_matrix(rot_b)\n\n        # Calculate capsule axis directions\n        axis_a = rot_mat_a @ np.array([0, 0, 1])  # Capsule oriented along Z-axis in local frame\n        axis_b = rot_mat_b @ np.array([0, 0, 1])\n\n        # Calculate capsule endpoints\n        half_len_a = length_a / 2.0\n        half_len_b = length_b / 2.0\n\n        a_start = pos_a - axis_a * half_len_a\n        a_end = pos_a + axis_a * half_len_a\n\n        b_start = pos_b - axis_b * half_len_b\n        b_end = pos_b + axis_b * half_len_b\n\n        # Find closest points on both line segments\n        closest_a, closest_b = self._closest_points_on_segments(\n            a_start, a_end, b_start, b_end\n        )\n\n        # Calculate distance between closest points\n        distance = np.linalg.norm(closest_b - closest_a)\n        min_distance = radius_a + radius_b + self.collision_margin\n\n        if distance < min_distance:\n            normal = (closest_b - closest_a) / distance if distance > 0 else np.array([0, 0, 1])\n            penetration_depth = min_distance - distance\n\n            # Collision point is the midpoint between closest points\n            collision_point = (closest_a + closest_b) / 2.0\n\n            return CollisionInfo(\n                link_a=link_a,\n                link_b=link_b,\n                position=collision_point,\n                normal=normal,\n                depth=penetration_depth,\n                collision_type=CollisionType.SELF_COLLISION\n            )\n\n        return None\n\n    def _closest_points_on_segments(\n        self,\n        a_start: np.ndarray,\n        a_end: np.ndarray,\n        b_start: np.ndarray,\n        b_end: np.ndarray\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Find closest points between two line segments.\"\"\"\n        # Vector representations of segments\n        d1 = a_end - a_start\n        d2 = b_end - b_start\n        r = a_start - b_start\n\n        # Calculate dot products\n        a = np.dot(d1, d1)\n        e = np.dot(d2, d2)\n        f = np.dot(d2, r)\n\n        # Check if segments are parallel\n        if a <= 1e-10 and e <= 1e-10:\n            return a_start, b_start\n\n        if a <= 1e-10:\n            t = np.clip(f / e, 0, 1)\n            s = 0\n        elif e <= 1e-10:\n            s = 0\n            t = np.clip(f / e, 0, 1)\n        else:\n            c = np.dot(d1, r)\n\n            # Calculate parameters\n            b = np.dot(d1, d2)\n            denom = a * e - b * b\n\n            if abs(denom) > 1e-10:\n                s = np.clip((b * f - c * e) / denom, 0, 1)\n                t = np.clip((a * f - b * c) / denom, 0, 1)\n            else:\n                s = 0\n                t = np.clip(f / e, 0, 1)\n\n        # Calculate closest points\n        closest_a = a_start + s * d1\n        closest_b = b_start + t * d2\n\n        return closest_a, closest_b\n\n    def _quaternion_to_matrix(self, q: np.ndarray) -> np.ndarray:\n        \"\"\"Convert quaternion to rotation matrix.\"\"\"\n        w, x, y, z = q\n\n        # Normalize quaternion\n        norm = np.sqrt(w*w + x*x + y*y + z*z)\n        if norm > 0:\n            w, x, y, z = w/norm, x/norm, y/norm, z/norm\n\n        return np.array([\n            [1 - 2*(y*y + z*z), 2*(x*y - w*z), 2*(x*z + w*y)],\n            [2*(x*y + w*z), 1 - 2*(x*x + z*z), 2*(y*z - w*x)],\n            [2*(x*z - w*y), 2*(y*z + w*x), 1 - 2*(x*x + y*y)]\n        ])\n\n    def _capsule_sphere_collision(\n        self,\n        pose_capsule: dict,\n        geom_capsule: dict,\n        pose_sphere: dict,\n        geom_sphere: dict,\n        link_capsule: str,\n        link_sphere: str\n    ) -> Optional[CollisionInfo]:\n        \"\"\"Detect collision between a capsule and a sphere.\"\"\"\n        # Get parameters\n        pos_capsule = pose_capsule['position']\n        rot_capsule = pose_capsule['orientation']\n        radius_capsule = geom_capsule['radius']\n        length_capsule = geom_capsule['length']\n\n        pos_sphere = pose_sphere['position']\n        radius_sphere = geom_sphere['radius']\n\n        # Calculate capsule axis\n        rot_mat = self._quaternion_to_matrix(rot_capsule)\n        axis = rot_mat @ np.array([0, 0, 1])\n        half_len = length_capsule / 2.0\n\n        # Capsule endpoints\n        start = pos_capsule - axis * half_len\n        end = pos_capsule + axis * half_len\n\n        # Find closest point on capsule segment to sphere center\n        closest_point = self._closest_point_on_segment(start, end, pos_sphere)\n\n        # Calculate distance\n        distance = np.linalg.norm(pos_sphere - closest_point)\n        min_distance = radius_capsule + radius_sphere + self.collision_margin\n\n        if distance < min_distance:\n            normal = (pos_sphere - closest_point) / distance if distance > 0 else np.array([0, 0, 1])\n            penetration_depth = min_distance - distance\n\n            # Collision point is along the surface\n            collision_point = closest_point + normal * radius_capsule\n\n            return CollisionInfo(\n                link_a=link_capsule,\n                link_b=link_sphere,\n                position=collision_point,\n                normal=normal,\n                depth=penetration_depth,\n                collision_type=CollisionType.SELF_COLLISION\n            )\n\n        return None\n\n    def _closest_point_on_segment(self, start: np.ndarray, end: np.ndarray, point: np.ndarray) -> np.ndarray:\n        \"\"\"Find the closest point on a line segment to a given point.\"\"\"\n        segment_vec = end - start\n        point_vec = point - start\n\n        segment_len_sq = np.dot(segment_vec, segment_vec)\n\n        if segment_len_sq < 1e-10:\n            return start  # Degenerate segment\n\n        t = np.dot(point_vec, segment_vec) / segment_len_sq\n        t = np.clip(t, 0, 1)  # Clamp to segment\n\n        return start + t * segment_vec\n\n    def check_ground_collision(self, link_poses: dict, link_geometries: dict) -> List[CollisionInfo]:\n        \"\"\"Check for collisions with the ground plane.\"\"\"\n        ground_collisions = []\n        ground_level = 0.0  # Ground at z = 0\n\n        for link_name, pose in link_poses.items():\n            geometry = link_geometries[link_name]\n\n            # Calculate minimum Z extent of the link\n            pos_z = pose['position'][2]\n\n            if geometry['type'] == 'sphere':\n                min_extent = pos_z - geometry['radius']\n            elif geometry['type'] == 'capsule':\n                # Account for orientation\n                rot_mat = self._quaternion_to_matrix(pose['orientation'])\n                axis = rot_mat @ np.array([0, 0, 1])\n                half_len = geometry['length'] / 2.0\n\n                # Project capsule extent along world Z\n                extent_projection = abs(axis[2]) * half_len\n                min_extent = pos_z - extent_projection - geometry['radius']\n            elif geometry['type'] == 'box':\n                # Calculate minimum Z extent considering orientation\n                rot_mat = self._quaternion_to_matrix(pose['orientation'])\n                dimensions = geometry['dimensions']\n\n                # Find minimum Z extent of oriented box\n                corners = self._get_box_corners(dimensions)\n                transformed_corners = [pose['position'] + rot_mat @ corner for corner in corners]\n                min_extent = min(corner[2] for corner in transformed_corners)\n            else:\n                min_extent = pos_z  # Default case\n\n            # Check if link is below or penetrating ground\n            if min_extent < ground_level + self.collision_margin:\n                penetration_depth = (ground_level + self.collision_margin) - min_extent\n\n                # Collision point is at ground level directly below the link\n                collision_point = np.array([pose['position'][0], pose['position'][1], ground_level])\n                normal = np.array([0, 0, 1])  # Normal pointing up\n\n                ground_collisions.append(CollisionInfo(\n                    link_a=link_name,\n                    link_b='ground',\n                    position=collision_point,\n                    normal=normal,\n                    depth=penetration_depth,\n                    collision_type=CollisionType.GROUND_COLLISION\n                ))\n\n        return ground_collisions\n\n    def _get_box_corners(self, dimensions: np.ndarray) -> List[np.ndarray]:\n        \"\"\"Get all 8 corners of an axis-aligned box.\"\"\"\n        dx, dy, dz = dimensions\n\n        return [\n            np.array([-dx, -dy, -dz]) / 2,\n            np.array([dx, -dy, -dz]) / 2,\n            np.array([-dx, dy, -dz]) / 2,\n            np.array([dx, dy, -dz]) / 2,\n            np.array([-dx, -dy, dz]) / 2,\n            np.array([dx, -dy, dz]) / 2,\n            np.array([-dx, dy, dz]) / 2,\n            np.array([dx, dy, dz]) / 2\n        ]\n\n# Example usage\ndef example_usage():\n    \"\"\"Example of using the collision detection system.\"\"\"\n    # Define humanoid robot links\n    robot_links = [\n        'base_link', 'head_link',\n        'left_shoulder_link', 'left_upper_arm_link', 'left_lower_arm_link', 'left_hand_link',\n        'right_shoulder_link', 'right_upper_arm_link', 'right_lower_arm_link', 'right_hand_link',\n        'left_hip_link', 'left_thigh_link', 'left_shin_link', 'left_foot_link',\n        'right_hip_link', 'right_thigh_link', 'right_shin_link', 'right_foot_link'\n    ]\n\n    # Initialize collision detector\n    collision_detector = CollisionDetector(robot_links)\n\n    # Example robot pose (simplified)\n    link_poses = {\n        'base_link': {'position': np.array([0.0, 0.0, 1.0]), 'orientation': np.array([1.0, 0.0, 0.0, 0.0])},\n        'head_link': {'position': np.array([0.0, 0.0, 1.5]), 'orientation': np.array([1.0, 0.0, 0.0, 0.0])},\n        'left_foot_link': {'position': np.array([-0.1, 0.1, 0.05]), 'orientation': np.array([1.0, 0.0, 0.0, 0.0])},\n        'right_foot_link': {'position': np.array([0.1, -0.1, 0.05]), 'orientation': np.array([1.0, 0.0, 0.0, 0.0])}\n    }\n\n    # Example link geometries\n    link_geometries = {\n        'base_link': {'type': 'capsule', 'radius': 0.15, 'length': 0.8},\n        'head_link': {'type': 'sphere', 'radius': 0.12},\n        'left_foot_link': {'type': 'box', 'dimensions': np.array([0.18, 0.1, 0.04])},\n        'right_foot_link': {'type': 'box', 'dimensions': np.array([0.18, 0.1, 0.04])}\n    }\n\n    # Update collision detector with current pose\n    self_collisions = collision_detector.update_robot_pose(link_poses, link_geometries)\n    ground_collisions = collision_detector.check_ground_collision(link_poses, link_geometries)\n\n    print(f\"Detected {len(self_collisions)} self-collisions\")\n    print(f\"Detected {len(ground_collisions)} ground collisions\")\n\n    for collision in ground_collisions:\n        print(f\"Ground collision: {collision.link_a} at {collision.position}\")\n\nif __name__ == \"__main__\":\n    example_usage()\n"})}),"\n",(0,o.jsx)(e.h2,{id:"contact-simulation-and-friction-modeling",children:"Contact Simulation and Friction Modeling"}),"\n",(0,o.jsx)(e.p,{children:"Contact simulation is critical for realistic humanoid robot behavior, especially for locomotion and manipulation tasks. The contact model determines how forces are transmitted between the robot and its environment."}),"\n",(0,o.jsx)(e.h3,{id:"contact-models-for-humanoid-robots",children:"Contact Models for Humanoid Robots"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"import numpy as np\nfrom typing import List, Tuple\nfrom dataclasses import dataclass\n\n@dataclass\nclass ContactPoint:\n    \"\"\"Represents a single contact point between two bodies.\"\"\"\n    position: np.ndarray      # Contact position in world coordinates\n    normal: np.ndarray        # Contact normal (points from first body to second)\n    penetration_depth: float  # Depth of penetration\n    body_indices: Tuple[int, int]  # Indices of contacting bodies\n    force: np.ndarray = None  # Accumulated contact force\n\nclass ContactSolver:\n    \"\"\"Advanced contact solver for humanoid robot simulation.\"\"\"\n\n    def __init__(self, num_bodies: int, dt: float = 0.001):\n        self.num_bodies = num_bodies\n        self.dt = dt  # Time step\n\n        # Physical parameters\n        self.restitution = 0.2  # Coefficient of restitution\n        self.static_friction = 0.5  # Static friction coefficient\n        self.dynamic_friction = 0.3  # Dynamic friction coefficient\n        self.safety_factor = 0.9    # For constraint stability\n\n        # Cache for performance\n        self.mass_inv_cache = np.zeros(num_bodies)\n        self.inertia_inv_cache = np.zeros((num_bodies, 3, 3))\n\n        print(f\"Initialized contact solver for {num_bodies} bodies with dt={dt}\")\n\n    def solve_contacts(self, bodies_state: List[dict], contact_points: List[ContactPoint]) -> List[np.ndarray]:\n        \"\"\"Solve contact constraints and return corrective forces.\"\"\"\n        if not contact_points:\n            return [np.zeros(6) for _ in range(self.num_bodies)]  # No contacts, no forces\n\n        # Prepare system matrices\n        num_contacts = len(contact_points)\n        forces = np.zeros((num_contacts, 3))  # Normal and tangential forces\n\n        # Solve each contact individually (simplified approach)\n        # In practice, you'd solve the full LCP (Linear Complementarity Problem)\n        for i, contact in enumerate(contact_points):\n            body1_idx, body2_idx = contact.body_indices\n\n            # Get body properties\n            body1 = bodies_state[body1_idx]\n            body2 = bodies_state[body2_idx]\n\n            # Calculate relative velocity at contact point\n            rel_vel = self._calculate_relative_velocity(\n                body1, body2, contact.position, contact.normal\n            )\n\n            # Solve normal contact constraint\n            normal_impulse = self._solve_normal_contact(\n                body1, body2, contact, rel_vel\n            )\n\n            # Solve friction constraints\n            tangent1, tangent2 = self._compute_tangent_vectors(contact.normal)\n            friction_impulses = self._solve_friction_contacts(\n                body1, body2, contact, rel_vel, tangent1, tangent2\n            )\n\n            # Combine impulses into force\n            total_impulse = normal_impulse * contact.normal + friction_impulses[0] * tangent1 + friction_impulses[1] * tangent2\n            forces[i] = total_impulse / self.dt  # Convert impulse to force\n\n        # Distribute forces to bodies\n        body_forces = [np.zeros(6) for _ in range(self.num_bodies)]  # [Fx, Fy, Fz, Tx, Ty, Tz]\n\n        for i, contact in enumerate(contact_points):\n            body1_idx, body2_idx = contact.body_indices\n            force = forces[i]\n\n            # Apply equal and opposite forces\n            body_forces[body1_idx][:3] -= force[:3]  # Linear forces\n            body_forces[body2_idx][:3] += force[:3]\n\n            # Calculate torques (r \xd7 F)\n            r1 = contact.position - bodies_state[body1_idx]['position']\n            r2 = contact.position - bodies_state[body2_idx]['position']\n\n            torque1 = np.cross(r1, force[:3])\n            torque2 = np.cross(r2, force[:3])\n\n            body_forces[body1_idx][3:] -= torque1  # Torque components\n            body_forces[body2_idx][3:] -= torque2\n\n        return body_forces\n\n    def _calculate_relative_velocity(self, body1: dict, body2: dict, contact_pos: np.ndarray, normal: np.ndarray) -> np.ndarray:\n        \"\"\"Calculate relative velocity of contact points.\"\"\"\n        # Velocity of contact point on body 1\n        r1 = contact_pos - body1['position']\n        vel1 = body1['linear_velocity'] + np.cross(body1['angular_velocity'], r1)\n\n        # Velocity of contact point on body 2\n        r2 = contact_pos - body2['position']\n        vel2 = body2['linear_velocity'] + np.cross(body2['angular_velocity'], r2)\n\n        # Relative velocity\n        rel_vel = vel1 - vel2\n\n        return rel_vel\n\n    def _solve_normal_contact(self, body1: dict, body2: dict, contact: ContactPoint, rel_vel: np.ndarray) -> float:\n        \"\"\"Solve normal contact constraint.\"\"\"\n        # Normal velocity component\n        vn = np.dot(rel_vel, contact.normal)\n\n        # Calculate effective mass\n        r1 = contact.position - body1['position']\n        r2 = contact.position - body2['position']\n\n        # Effective inverse mass for normal direction\n        eff_mass_inv = (\n            body1['inv_mass'] + body2['inv_mass'] +\n            np.dot(contact.normal, np.cross(body1['inv_inertia'] @ np.cross(r1, contact.normal), r1)) +\n            np.dot(contact.normal, np.cross(body2['inv_inertia'] @ np.cross(r2, contact.normal), r2))\n        )\n\n        if eff_mass_inv <= 0:\n            return 0.0\n\n        eff_mass = 1.0 / eff_mass_inv\n\n        # Calculate impulse to stop penetration velocity\n        impulse_mag = -(1.0 + self.restitution) * vn\n        impulse_mag /= eff_mass_inv\n\n        # Apply penetration correction\n        penetration_correction = max(0.0, contact.penetration_depth) * self.safety_factor / (self.dt * self.dt)\n        impulse_mag += penetration_correction * eff_mass\n\n        # Clamp impulse to prevent pulling apart\n        impulse_mag = max(0.0, impulse_mag)\n\n        return impulse_mag\n\n    def _compute_tangent_vectors(self, normal: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Compute two tangent vectors perpendicular to the normal.\"\"\"\n        # Find a vector not parallel to normal\n        if abs(normal[2]) < 0.9:\n            tangent1 = np.cross(normal, np.array([0, 0, 1]))\n        else:\n            tangent1 = np.cross(normal, np.array([1, 0, 0]))\n\n        tangent1 = tangent1 / np.linalg.norm(tangent1)\n        tangent2 = np.cross(normal, tangent1)\n        tangent2 = tangent2 / np.linalg.norm(tangent2)\n\n        return tangent1, tangent2\n\n    def _solve_friction_contacts(self, body1: dict, body2: dict, contact: ContactPoint,\n                                rel_vel: np.ndarray, tangent1: np.ndarray, tangent2: np.ndarray) -> Tuple[float, float]:\n        \"\"\"Solve friction constraints using the Coulomb friction model.\"\"\"\n        # Normal force magnitude (from normal contact)\n        normal_vel = np.dot(rel_vel, contact.normal)\n        normal_impulse = max(0.0, -(1.0 + self.restitution) * normal_vel)  # Approximate normal impulse\n\n        # Tangential velocity components\n        vt1 = np.dot(rel_vel, tangent1)\n        vt2 = np.dot(rel_vel, tangent2)\n\n        # Effective masses for tangential directions\n        r1 = contact.position - body1['position']\n        r2 = contact.position - body2['position']\n\n        eff_mass_inv_t1 = (\n            body1['inv_mass'] + body2['inv_mass'] +\n            np.dot(tangent1, np.cross(body1['inv_inertia'] @ np.cross(r1, tangent1), r1)) +\n            np.dot(tangent1, np.cross(body2['inv_inertia'] @ np.cross(r2, tangent1), r2))\n        )\n\n        eff_mass_inv_t2 = (\n            body1['inv_mass'] + body2['inv_mass'] +\n            np.dot(tangent2, np.cross(body1['inv_inertia'] @ np.cross(r1, tangent2), r1)) +\n            np.dot(tangent2, np.cross(body2['inv_inertia'] @ np.cross(r2, tangent2), r2))\n        )\n\n        if eff_mass_inv_t1 <= 0 or eff_mass_inv_t2 <= 0:\n            return 0.0, 0.0\n\n        # Calculate tangential impulses\n        impulse_t1 = -vt1 / eff_mass_inv_t1\n        impulse_t2 = -vt2 / eff_mass_inv_t2\n\n        # Apply friction cone constraint (Coulomb friction)\n        max_friction_impulse = self.static_friction * normal_impulse\n\n        # Magnitude of tangential impulse\n        impulse_mag = np.sqrt(impulse_t1**2 + impulse_t2**2)\n\n        if impulse_mag > max_friction_impulse:\n            # Sliding friction\n            scale = max_friction_impulse / impulse_mag\n            impulse_t1 *= scale\n            impulse_t2 *= scale\n\n        return impulse_t1, impulse_t2\n\n# Integration with physics simulation\nclass HumanoidPhysicsEngine:\n    \"\"\"Complete physics engine for humanoid robot simulation.\"\"\"\n\n    def __init__(self, num_links: int):\n        self.num_links = num_links\n        self.dt = 0.001  # 1ms time step\n        self.gravity = np.array([0, 0, -9.81])\n\n        # Initialize contact solver\n        self.contact_solver = ContactSolver(num_links, self.dt)\n\n        # Initialize collision detector\n        self.collision_detector = None\n\n        print(f\"Initialized humanoid physics engine for {num_links} links\")\n\n    def integrate_motion(self, bodies_state: List[dict], external_forces: List[np.ndarray], dt: float = None):\n        \"\"\"Integrate equations of motion for all bodies.\"\"\"\n        if dt is None:\n            dt = self.dt\n\n        for i, body in enumerate(bodies_state):\n            # Apply external forces\n            linear_force = external_forces[i][:3]\n            torque = external_forces[i][3:]\n\n            # Update linear motion (F = ma => a = F/m)\n            linear_acc = linear_force * body['inv_mass'] + self.gravity\n            body['linear_velocity'] += linear_acc * dt\n            body['position'] += body['linear_velocity'] * dt\n\n            # Update angular motion (\u03c4 = I\u03b1 => \u03b1 = I\u207b\xb9\u03c4)\n            angular_acc = body['inv_inertia'] @ torque\n            body['angular_velocity'] += angular_acc * dt\n\n            # Update orientation using quaternion integration\n            omega_quat = np.array([0, *body['angular_velocity']])\n            quat_deriv = 0.5 * self._quat_multiply(omega_quat, body['orientation'])\n            body['orientation'] += quat_deriv * dt\n            # Normalize quaternion\n            body['orientation'] /= np.linalg.norm(body['orientation'])\n\n    def _quat_multiply(self, q1: np.ndarray, q2: np.ndarray) -> np.ndarray:\n        \"\"\"Multiply two quaternions.\"\"\"\n        w1, x1, y1, z1 = q1\n        w2, x2, y2, z2 = q2\n\n        w = w1*w2 - x1*x2 - y1*y2 - z1*z2\n        x = w1*x2 + x1*w2 + y1*z2 - z1*y2\n        y = w1*y2 - x1*z2 + y1*w2 + z1*x2\n        z = w1*z2 + x1*y2 - y1*x2 + z1*w2\n\n        return np.array([w, x, y, z])\n\n    def simulate_step(self, bodies_state: List[dict], link_geometries: dict):\n        \"\"\"Perform one simulation step including collision detection and contact resolution.\"\"\"\n        # Detect collisions\n        collisions = self.collision_detector.update_robot_pose(\n            {i: {'position': bodies_state[i]['position'], 'orientation': bodies_state[i]['orientation'], 'geometry': link_geometries[f'link_{i}']}\n             for i in range(len(bodies_state))},\n            link_geometries\n        )\n\n        # Add ground collisions\n        ground_collisions = self.collision_detector.check_ground_collision(\n            {i: {'position': bodies_state[i]['position'], 'orientation': bodies_state[i]['orientation'], 'geometry': link_geometries[f'link_{i}']}\n             for i in range(len(bodies_state))},\n            link_geometries\n        )\n\n        all_collisions = collisions + ground_collisions\n\n        # Convert collisions to contact points\n        contact_points = []\n        for collision in all_collisions:\n            # This is a simplified mapping - in reality you'd have more detailed collision info\n            contact_points.append(ContactPoint(\n                position=collision.position,\n                normal=collision.normal,\n                penetration_depth=collision.depth,\n                body_indices=(self._get_link_index(collision.link_a), self._get_link_index(collision.link_b))\n            ))\n\n        # Solve contacts to get forces\n        contact_forces = self.contact_solver.solve_contacts(bodies_state, contact_points)\n\n        # Integrate motion with contact forces\n        self.integrate_motion(bodies_state, contact_forces)\n\n        return bodies_state\n\n    def _get_link_index(self, link_name: str) -> int:\n        \"\"\"Convert link name to index.\"\"\"\n        # Simplified mapping - in reality you'd have a proper mapping\n        if link_name.startswith('link_'):\n            return int(link_name.split('_')[1])\n        return 0  # Default\n\n# Example usage\ndef run_physics_simulation():\n    \"\"\"Run a complete physics simulation example.\"\"\"\n    # Initialize physics engine\n    engine = HumanoidPhysicsEngine(num_links=18)  # Example humanoid with 18 links\n\n    # Initialize body states (simplified)\n    bodies_state = []\n    for i in range(18):\n        body_state = {\n            'position': np.random.rand(3) * 0.1,  # Small random positions\n            'orientation': np.array([1.0, 0.0, 0.0, 0.0]),  # Identity quaternion\n            'linear_velocity': np.zeros(3),\n            'angular_velocity': np.zeros(3),\n            'inv_mass': 1.0,  # 1kg mass\n            'inv_inertia': np.eye(3)  # Identity inertia matrix\n        }\n        bodies_state.append(body_state)\n\n    # Initialize collision detector\n    link_names = [f'link_{i}' for i in range(18)]\n    engine.collision_detector = CollisionDetector(link_names)\n\n    # Initialize link geometries\n    link_geometries = {}\n    for i in range(18):\n        if i < 3:  # Torso/head links\n            link_geometries[f'link_{i}'] = {'type': 'capsule', 'radius': 0.1, 'length': 0.3}\n        elif i < 9:  # Arm links\n            link_geometries[f'link_{i}'] = {'type': 'capsule', 'radius': 0.05, 'length': 0.2}\n        else:  # Leg links\n            link_geometries[f'link_{i}'] = {'type': 'capsule', 'radius': 0.07, 'length': 0.3}\n\n    # Run simulation\n    print(\"Starting physics simulation...\")\n    for step in range(1000):\n        engine.simulate_step(bodies_state, link_geometries)\n\n        if step % 100 == 0:\n            print(f\"Simulation step: {step}\")\n\n    print(\"Physics simulation completed!\")\n\nif __name__ == \"__main__\":\n    run_physics_simulation()\n"})}),"\n",(0,o.jsx)(e.h2,{id:"performance-optimization-for-real-time-simulation",children:"Performance Optimization for Real-time Simulation"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-mermaid",children:'graph TD\n    A[Physics Simulation Pipeline] --\x3e B[Broad Phase Collision Detection]\n    A --\x3e C[Narrow Phase Collision Detection]\n    A --\x3e D[Constraint Solving]\n    A --\x3e E[Integration]\n\n    B --\x3e F[Spatial Hashing]\n    B --\x3e G[AABB Trees]\n    B --\x3e H[Grid-based Partitioning]\n\n    C --\x3e I[GJK Algorithm]\n    C --\x3e J[SAT Algorithm]\n    C --\x3e K[Ray Casting]\n\n    D --\x3e L[Projected Gauss-Seidel]\n    D --\x3e M[Sequential Impulses]\n    D --\x3e N[MLCP Solvers]\n\n    E --\x3e O[Symplectic Integrators]\n    E --\x3e P[Runge-Kutta Methods]\n    E --\x3e Q[Implicit Methods]\n\n    F --\x3e R[O(1) Query Time]\n    G --\x3e S[Log n Complexity]\n    H --\x3e T[Simple Implementation]\n\n    style A fill:#e1f5fe\n    style D fill:#f3e5f5\n    style E fill:#e8f5e8\n</mermaid>\n\n### Optimization Techniques for Humanoid Physics Simulation\n\n```python\nimport numpy as np\nimport numba\nfrom typing import List, Dict\nimport time\n\nclass OptimizedPhysicsEngine:\n    """High-performance physics engine optimized for humanoid robot simulation."""\n\n    def __init__(self, max_bodies: int = 100, dt: float = 0.001):\n        self.max_bodies = max_bodies\n        self.dt = dt\n        self.gravity = np.array([0.0, 0.0, -9.81], dtype=np.float32)\n\n        # Pre-allocate arrays for performance\n        self.positions = np.zeros((max_bodies, 3), dtype=np.float32)\n        self.velocities = np.zeros((max_bodies, 3), dtype=np.float32)\n        self.orientations = np.zeros((max_bodies, 4), dtype=np.float32)  # Quaternions\n        self.angular_velocities = np.zeros((max_bodies, 3), dtype=np.float32)\n        self.inv_masses = np.ones(max_bodies, dtype=np.float32)\n        self.inv_inertias = np.zeros((max_bodies, 3, 3), dtype=np.float32)\n\n        # Initialize identity inertias\n        for i in range(max_bodies):\n            self.inv_inertias[i] = np.eye(3, dtype=np.float32)\n\n        # Contact constraint data\n        self.max_contacts = 1000\n        self.contact_positions = np.zeros((self.max_contacts, 3), dtype=np.float32)\n        self.contact_normals = np.zeros((self.max_contacts, 3), dtype=np.float32)\n        self.contact_depths = np.zeros(self.max_contacts, dtype=np.float32)\n        self.contact_body_indices = np.zeros((self.max_contacts, 2), dtype=np.int32)\n\n        # Performance counters\n        self.broad_phase_time = 0.0\n        self.narrow_phase_time = 0.0\n        self.constraint_solve_time = 0.0\n        self.integration_time = 0.0\n\n        print(f"Initialized optimized physics engine with {max_bodies} max bodies, dt={dt}")\n\n    def integrate_motion_batch(self, num_bodies: int):\n        """High-performance batch integration of motion equations."""\n        start_time = time.time()\n\n        # Vectorized integration of linear motion\n        linear_acc = np.zeros_like(self.velocities[:num_bodies])\n\n        # Add gravity to acceleration\n        linear_acc[:, :] = self.gravity * self.inv_masses[:num_bodies, np.newaxis]\n\n        # Update velocities and positions\n        self.velocities[:num_bodies] += linear_acc * self.dt\n        self.positions[:num_bodies] += self.velocities[:num_bodies] * self.dt\n\n        # Vectorized integration of angular motion\n        # For simplicity, using a basic angular velocity update\n        self.angular_velocities[:num_bodies] *= 0.99  # Damping for stability\n\n        # Update orientations using quaternion integration\n        self._integrate_orientations(num_bodies)\n\n        self.integration_time += time.time() - start_time\n\n    @staticmethod\n    @numba.jit(nopython=True)\n    def _integrate_orientations_numba(orientations, angular_velocities, dt, num_bodies):\n        """Numba-optimized quaternion integration."""\n        for i in range(num_bodies):\n            # Create quaternion from angular velocity\n            omega_quat = np.array([0.0, angular_velocities[i, 0],\n                                  angular_velocities[i, 1], angular_velocities[i, 2]], dtype=np.float32)\n\n            # Multiply: dq/dt = 0.5 * \u03c9 * q\n            temp = np.zeros(4, dtype=np.float32)\n            temp[0] = -omega_quat[1]*orientations[i, 1] - omega_quat[2]*orientations[i, 2] - omega_quat[3]*orientations[i, 3]\n            temp[1] = omega_quat[0]*orientations[i, 1] + omega_quat[3]*orientations[i, 2] - omega_quat[2]*orientations[i, 3]\n            temp[2] = omega_quat[0]*orientations[i, 2] - omega_quat[3]*orientations[i, 1] + omega_quat[1]*orientations[i, 3]\n            temp[3] = omega_quat[0]*orientations[i, 3] + omega_quat[2]*orientations[i, 1] - omega_quat[1]*orientations[i, 2]\n\n            temp *= 0.5 * dt\n\n            # Update orientation\n            orientations[i] += temp\n\n            # Normalize quaternion\n            norm = np.sqrt(orientations[i, 0]**2 + orientations[i, 1]**2 +\n                          orientations[i, 2]**2 + orientations[i, 3]**2)\n            if norm > 0:\n                orientations[i] /= norm\n\n    def _integrate_orientations(self, num_bodies: int):\n        """Integrate orientations using optimized method."""\n        self._integrate_orientations_numba(\n            self.orientations, self.angular_velocities, self.dt, num_bodies\n        )\n\n    def solve_constraints_batch(self, num_contacts: int):\n        """Batch solve contact constraints with optimized algorithms."""\n        start_time = time.time()\n\n        if num_contacts == 0:\n            return\n\n        # Vectorized contact solving\n        for i in range(num_contacts):\n            body1_idx = self.contact_body_indices[i, 0]\n            body2_idx = self.contact_body_indices[i, 1]\n\n            # Get contact data\n            contact_pos = self.contact_positions[i]\n            contact_normal = self.contact_normals[i]\n            penetration_depth = self.contact_depths[i]\n\n            # Calculate relative velocity at contact\n            r1 = contact_pos - self.positions[body1_idx]\n            r2 = contact_pos - self.positions[body2_idx]\n\n            v1 = self.velocities[body1_idx] + np.cross(self.angular_velocities[body1_idx], r1)\n            v2 = self.velocities[body2_idx] + np.cross(self.angular_velocities[body2_idx], r2)\n            rel_vel = v1 - v2\n\n            # Normal velocity\n            vn = np.dot(rel_vel, contact_normal)\n\n            # Calculate effective mass\n            k_normal = (self.inv_masses[body1_idx] + self.inv_masses[body2_idx] +\n                       np.dot(contact_normal, np.cross(\n                           self.inv_inertias[body1_idx] @ np.cross(r1, contact_normal), r1)) +\n                       np.dot(contact_normal, np.cross(\n                           self.inv_inertias[body2_idx] @ np.cross(r2, contact_normal), r2)))\n\n            if k_normal > 0:\n                # Normal impulse\n                inv_k = 1.0 / k_normal\n                rest_impulse = max(0.0, -(1.0 + 0.2) * vn)  # 0.2 = restitution\n                pen_impulse = max(0.0, penetration_depth * 0.9 / (self.dt * self.dt))  # Penetration correction\n\n                normal_impulse = (rest_impulse + pen_impulse) * inv_k\n\n                # Apply impulse\n                impulse_vec = normal_impulse * contact_normal\n                self.velocities[body1_idx] -= self.inv_masses[body1_idx] * impulse_vec\n                self.velocities[body2_idx] += self.inv_masses[body2_idx] * impulse_vec\n\n                # Angular components\n                self.angular_velocities[body1_idx] -= self.inv_inertias[body1_idx] @ np.cross(r1, impulse_vec)\n                self.angular_velocities[body2_idx] -= self.inv_inertias[body2_idx] @ np.cross(r2, impulse_vec)\n\n        self.constraint_solve_time += time.time() - start_time\n\n    def reset_performance_counters(self):\n        """Reset all performance counters."""\n        self.broad_phase_time = 0.0\n        self.narrow_phase_time = 0.0\n        self.constraint_solve_time = 0.0\n        self.integration_time = 0.0\n\n    def get_performance_stats(self) -> Dict[str, float]:\n        """Get performance statistics."""\n        total_time = (self.broad_phase_time + self.narrow_phase_time +\n                     self.constraint_solve_time + self.integration_time)\n\n        return {\n            \'total_time\': total_time,\n            \'integration_time\': self.integration_time,\n            \'constraint_solve_time\': self.constraint_solve_time,\n            \'broad_phase_time\': self.broad_phase_time,\n            \'narrow_phase_time\': self.narrow_phase_time,\n            \'integration_percentage\': (self.integration_time / total_time * 100) if total_time > 0 else 0,\n            \'constraint_percentage\': (self.constraint_solve_time / total_time * 100) if total_time > 0 else 0\n        }\n\n# Example performance test\ndef performance_test():\n    """Test the performance of the optimized physics engine."""\n    print("Starting performance test...")\n\n    # Initialize engine\n    engine = OptimizedPhysicsEngine(max_bodies=50, dt=0.001)\n\n    # Initialize some bodies\n    num_bodies = 20\n    for i in range(num_bodies):\n        engine.positions[i] = np.random.rand(3).astype(np.float32) * 2.0\n        engine.velocities[i] = (np.random.rand(3).astype(np.float32) - 0.5) * 0.1\n        engine.orientations[i, 0] = 1.0  # Identity quaternion\n        engine.inv_masses[i] = 1.0 + np.random.rand().astype(np.float32) * 0.5  # 1.0-1.5 kg\n\n    # Simulate for a number of steps\n    num_steps = 1000\n    start_time = time.time()\n\n    for step in range(num_steps):\n        # Add some fake contacts for testing\n        num_contacts = min(10, step % 20)  # Varying number of contacts\n        for i in range(num_contacts):\n            engine.contact_positions[i] = engine.positions[i % num_bodies].copy()\n            engine.contact_normals[i] = np.array([0, 0, 1], dtype=np.float32)\n            engine.contact_depths[i] = 0.001\n            engine.contact_body_indices[i] = [i % num_bodies, (i+1) % num_bodies]\n\n        # Run simulation step\n        engine.solve_constraints_batch(num_contacts)\n        engine.integrate_motion_batch(num_bodies)\n\n    total_sim_time = time.time() - start_time\n\n    # Print performance stats\n    stats = engine.get_performance_stats()\n    print(f"\\nPerformance Results:")\n    print(f"Total simulation time: {total_sim_time:.4f}s for {num_steps} steps")\n    print(f"Average time per step: {total_sim_time/num_steps*1000:.3f}ms")\n    print(f"Steps per second: {num_steps/total_sim_time:.1f}")\n    print(f"Integration: {stats[\'integration_time\']:.4f}s ({stats[\'integration_percentage\']:.1f}%)")\n    print(f"Constraint solving: {stats[\'constraint_solve_time\']:.4f}s ({stats[\'constraint_percentage\']:.1f}%)")\n\n    return stats\n\nif __name__ == "__main__":\n    performance_test()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"integration-with-nvidia-isaac-sim",children:"Integration with NVIDIA Isaac Sim"}),"\n",(0,o.jsx)(e.p,{children:"When integrating with NVIDIA Isaac Sim, specific parameters and configurations are required to ensure optimal physics simulation performance:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-json",children:'{\n  "physics_sim_config": {\n    "engine": "PhysX",\n    "gravity": [0.0, 0.0, -9.81],\n    "timestep": 0.001,\n    "substeps": 1,\n    "solver_type": "TGS",\n    "solver_iterations": 4,\n    "collision_margin": 0.001,\n    "contact_offset": 0.02,\n    "gpu": {\n      "enabled": true,\n      "use_gpu_sim": true,\n      "gpu_feedback_mode": "all",\n      "gpu_collision_frame_count": 2\n    },\n    "scene_query_resolution": {\n      "default_buffer_size": 1024,\n      "max_hits_any_query_size": 128,\n      "max_hits_closest_query_size": 128\n    },\n    "articulation_solver": {\n      "position_iteration_count": 4,\n      "velocity_iteration_count": 1,\n      "projection_angle_tolerance": 0.05236,\n      "projection_linear_tolerance": 0.001,\n      "max_depenetration_velocity": 100.0\n    },\n    "humanoid_specific": {\n      "enable_character_controller": false,\n      "max_angular_speed": 50.0,\n      "sleep_threshold": 0.005,\n      "stabilization_threshold": 0.0,\n      "solver_batch_size": 32,\n      "enable_ccd": true,\n      "ccd_threshold": 0.05,\n      "ccd_max_passes": 2\n    }\n  }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:"Physics simulation and collision detection form the foundation of realistic humanoid robot digital twins. The implementation requires careful consideration of multiple factors:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Physics Engine Selection"}),": Choose appropriate algorithms based on real-time requirements vs. accuracy needs"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Collision Detection"}),": Implement efficient broad and narrow phase algorithms for complex multi-link systems"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Contact Resolution"}),": Use stable constraint solvers that handle multiple simultaneous contacts"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Performance Optimization"}),": Apply batching, vectorization, and GPU acceleration where possible"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Integration"}),": Configure parameters appropriately for the target simulation environment"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"The examples provided demonstrate advanced techniques for implementing physics simulation that can handle the complex requirements of humanoid robot systems, including real-time performance, stability, and accuracy. Proper implementation of these systems enables effective testing and development of humanoid robot control algorithms in simulation before deployment on physical hardware."}),"\n",(0,o.jsx)(e.h2,{id:"advanced-topics-in-humanoid-physics-simulation",children:"Advanced Topics in Humanoid Physics Simulation"}),"\n",(0,o.jsx)(e.h3,{id:"multi-body-dynamics-for-humanoid-robots",children:"Multi-Body Dynamics for Humanoid Robots"}),"\n",(0,o.jsx)(e.p,{children:"For humanoid robots with complex kinematic structures, the equations of motion become significantly more complex. The articulated body algorithm (ABA) is commonly used to efficiently compute the forward dynamics of multi-body systems:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-cpp",children:"// Advanced articulated body algorithm implementation\n#include <Eigen/Dense>\n#include <vector>\n\nstruct ArticulatedBody {\n    Eigen::Matrix3d inertia;      // 3x3 inertia matrix\n    double mass;                  // Mass of the body\n    Eigen::Vector3d com;          // Center of mass\n    Eigen::Matrix6d I_articulated; // Articulated body inertia\n    Eigen::Vector6d pA;           // Articulated bias force\n    Eigen::Matrix6d IA;           // Articulated inertia\n    Eigen::VectorXd S;            // Motion subspace vector\n    Eigen::MatrixXd U;            // U matrix for ABA\n    double d;                     // d scalar for ABA\n    Eigen::VectorXd u;            // u vector for ABA\n};\n\nclass HumanoidDynamicsSolver {\nprivate:\n    std::vector<ArticulatedBody> bodies;\n    std::vector<int> parent;      // Parent index for each body\n    std::vector<Eigen::Matrix4d> transforms;  // Transforms from parent to child\n    std::vector<Eigen::Vector6d> v;          // Velocities\n    std::vector<Eigen::Vector6d> c;          // Coriolis accelerations\n    std::vector<Eigen::Vector6d> a;          // Accelerations\n    std::vector<double> q;                   // Joint positions\n    std::vector<double> qd;                  // Joint velocities\n    std::vector<double> qdd;                 // Joint accelerations\n    std::vector<double> tau;                 // Joint torques\n\npublic:\n    HumanoidDynamicsSolver(int num_bodies) {\n        bodies.resize(num_bodies);\n        parent.resize(num_bodies);\n        transforms.resize(num_bodies);\n        v.resize(num_bodies);\n        c.resize(num_bodies);\n        a.resize(num_bodies);\n        q.resize(num_bodies-1);  // Root has 6 DOF, others have 1 each\n        qd.resize(num_bodies-1);\n        qdd.resize(num_bodies-1);\n        tau.resize(num_bodies-1);\n    }\n\n    void computeForwardDynamics() {\n        // 1. Initialize root\n        a[0] = Eigen::Vector6d::Zero();\n        IA[0] = bodies[0].I_articulated;\n        pA[0] = -bodies[0].pA;\n\n        // 2. Forward recursion to compute articulated inertias\n        for (int i = 1; i < bodies.size(); i++) {\n            int pa = parent[i];\n            Eigen::Matrix6d X_pa_i = transformWrench(transforms[i]);\n\n            // Articulated body inertia\n            IA[i] = bodies[i].I_articulated;\n\n            // Propagate articulated inertia\n            IA[i] = IA[i] + X_pa_i.transpose() * IA[pa] * X_pa_i;\n\n            // Bias force\n            pA[i] = bodies[i].pA + X_pa_i.transpose() * (pA[pa] + IA[i] * c[i]);\n        }\n\n        // 3. Backward recursion to compute joint accelerations\n        for (int i = bodies.size()-1; i >= 0; i--) {\n            Eigen::Matrix6d X_pa_i = transformWrench(transforms[i]);\n            Eigen::Vector6d U_i = IA[i] * S[i];\n            double d_i = S[i].transpose() * U_i;\n            Eigen::Vector6d u_i = tau[i] - S[i].transpose() * pA[i];\n\n            if (i == 0) {\n                // Root body - 6 DOF\n                Eigen::Matrix6d root_inertia = IA[0];\n                Eigen::Vector6d root_bias = pA[0];\n                qdd.segment(0, 6) = root_inertia.inverse() * (Eigen::Vector6d::Zero() - root_bias);\n            } else {\n                qdd[i-1] = (u_i - U_i.transpose() * a[parent[i]]) / d_i;\n            }\n        }\n\n        // 4. Forward recursion to compute body accelerations\n        for (int i = 1; i < bodies.size(); i++) {\n            int pa = parent[i];\n            Eigen::Matrix6d X_pa_i = transformWrench(transforms[i]);\n            a[i] = X_pa_i * a[pa] + c[i] + S[i] * qdd[i-1];\n        }\n    }\n\n    Eigen::Matrix6d transformWrench(const Eigen::Matrix4d& X) {\n        // Transform a 6D spatial force vector\n        Eigen::Matrix6d X_transform = Eigen::Matrix6d::Zero();\n        X_transform.block<3,3>(0,0) = X.block<3,3>(0,0);\n        X_transform.block<3,3>(0,3) = skew(X.block<3,1>(0,3)) * X.block<3,3>(0,0);\n        X_transform.block<3,3>(3,0) = Eigen::Matrix3d::Zero();\n        X_transform.block<3,3>(3,3) = X.block<3,3>(0,0);\n\n        return X_transform;\n    }\n\n    Eigen::Matrix3d skew(const Eigen::Vector3d& v) {\n        Eigen::Matrix3d S;\n        S << 0, -v(2), v(1),\n             v(2), 0, -v(0),\n             -v(1), v(0), 0;\n        return S;\n    }\n\n    void updateKinematics() {\n        // Update transforms and velocities based on current joint positions and velocities\n        // This is called before dynamics computation\n    }\n};\n"})}),"\n",(0,o.jsx)(e.h3,{id:"real-time-physics-simulation-considerations",children:"Real-time Physics Simulation Considerations"}),"\n",(0,o.jsx)(e.p,{children:"For real-time humanoid simulation, several optimization strategies are essential:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Fixed Time Step Integration"}),": Ensures deterministic behavior and stability"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Parallel Processing"}),": Utilize multi-threading for collision detection and constraint solving"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Approximation Techniques"}),": Use simplified models when computational budget is tight"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Caching"}),": Pre-compute and cache expensive calculations when possible"]}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import threading\nimport queue\nfrom concurrent.futures import ThreadPoolExecutor\nimport numpy as np\n\nclass RealtimePhysicsSimulator:\n    """Real-time physics simulator optimized for humanoid robots."""\n\n    def __init__(self, target_frequency=1000):  # 1kHz target\n        self.target_frequency = target_frequency\n        self.dt = 1.0 / target_frequency\n        self.current_time = 0.0\n\n        # Thread pools for different physics tasks\n        self.collision_pool = ThreadPoolExecutor(max_workers=2, thread_name_prefix="collision")\n        self.constraint_pool = ThreadPoolExecutor(max_workers=2, thread_name_prefix="constraint")\n        self.integration_pool = ThreadPoolExecutor(max_workers=1, thread_name_prefix="integration")\n\n        # Fixed-size buffers for real-time performance\n        self.max_bodies = 100\n        self.max_contacts = 1000\n\n        # Real-time safety margins\n        self.computation_budget = 0.8 * self.dt  # Use only 80% of time step\n\n        print(f"Initialized real-time physics simulator at {target_frequency}Hz")\n\n    def simulate_frame(self, bodies_state, contact_constraints):\n        """Simulate one physics frame with real-time guarantees."""\n        start_time = time.perf_counter()\n\n        # Perform collision detection in parallel\n        collision_future = self.collision_pool.submit(\n            self.parallel_collision_detection, bodies_state\n        )\n\n        # Process constraints while collision detection runs\n        constraint_result = self.solve_constraints(contact_constraints)\n\n        # Wait for collision detection to complete\n        new_collisions = collision_future.result()\n\n        # Integrate motion\n        integrated_state = self.integrate_motion(bodies_state, self.dt)\n\n        # Check real-time performance\n        frame_time = time.perf_counter() - start_time\n        if frame_time > self.computation_budget:\n            print(f"Warning: Physics frame took {frame_time*1000:.2f}ms, budget was {self.computation_budget*1000:.2f}ms")\n\n        return integrated_state, new_collisions\n\n    def parallel_collision_detection(self, bodies_state):\n        """Perform collision detection using parallel processing."""\n        # Split bodies into chunks for parallel processing\n        num_threads = 4\n        chunk_size = len(bodies_state) // num_threads\n        futures = []\n\n        for i in range(num_threads):\n            start_idx = i * chunk_size\n            end_idx = start_idx + chunk_size if i < num_threads - 1 else len(bodies_state)\n            chunk = bodies_state[start_idx:end_idx]\n\n            future = self.collision_pool.submit(\n                self.collision_detection_worker, chunk, bodies_state, start_idx\n            )\n            futures.append(future)\n\n        # Collect results\n        all_collisions = []\n        for future in futures:\n            collisions = future.result()\n            all_collisions.extend(collisions)\n\n        return all_collisions\n\n    def collision_detection_worker(self, local_bodies, all_bodies, start_idx):\n        """Worker function for parallel collision detection."""\n        collisions = []\n\n        for i, body_a in enumerate(local_bodies):\n            for j, body_b in enumerate(all_bodies):\n                if i + start_idx == j:  # Skip self-collision\n                    continue\n\n                # Perform collision check\n                if self.broad_phase_check(body_a, body_b):\n                    collision = self.narrow_phase_check(body_a, body_b)\n                    if collision:\n                        collisions.append(collision)\n\n        return collisions\n\n    def broad_phase_check(self, body_a, body_b):\n        """Fast broad-phase collision check."""\n        # Simple sphere-based broad phase\n        pos_a = body_a[\'position\']\n        pos_b = body_b[\'position\']\n        dist_sq = np.sum((pos_a - pos_b)**2)\n\n        # Estimate bounding sphere radius\n        radius_a = body_a.get(\'bounding_radius\', 0.1)\n        radius_b = body_b.get(\'bounding_radius\', 0.1)\n        threshold_sq = (radius_a + radius_b + 0.01)**2\n\n        return dist_sq < threshold_sq\n\n    def narrow_phase_check(self, body_a, body_b):\n        """Detailed narrow-phase collision check."""\n        # Placeholder for actual narrow-phase algorithm\n        # In practice, this would use GJK, SAT, or other algorithms\n        return None\n\n    def solve_constraints(self, constraints):\n        """Solve physics constraints."""\n        # Parallel constraint solving\n        return self.constraint_pool.submit(\n            self.constraint_solver_worker, constraints\n        ).result()\n\n    def constraint_solver_worker(self, constraints):\n        """Worker for constraint solving."""\n        # Solve constraints using iterative methods\n        max_iterations = 10\n        for iteration in range(max_iterations):\n            for constraint in constraints:\n                self.solve_single_constraint(constraint)\n\n        return constraints\n\n    def solve_single_constraint(self, constraint):\n        """Solve a single physics constraint."""\n        # Implementation of constraint solving algorithm\n        pass\n\n    def integrate_motion(self, bodies_state, dt):\n        """Integrate equations of motion."""\n        # Use fixed-coefficient integration for real-time stability\n        for body in bodies_state:\n            # Semi-implicit Euler integration\n            body[\'velocity\'] += body[\'acceleration\'] * dt\n            body[\'position\'] += body[\'velocity\'] * dt\n\n            # Integrate orientation (simplified)\n            omega = body.get(\'angular_velocity\', np.zeros(3))\n            orientation = body.get(\'orientation\', np.array([1, 0, 0, 0]))\n\n            # Quaternion integration\n            q_dot = 0.5 * self.quat_multiply(\n                np.concatenate([[0], omega]),\n                orientation\n            )\n            orientation += q_dot * dt\n            orientation = orientation / np.linalg.norm(orientation)\n            body[\'orientation\'] = orientation\n\n        return bodies_state\n\n    def quat_multiply(self, q1, q2):\n        """Quaternion multiplication."""\n        w1, x1, y1, z1 = q1\n        w2, x2, y2, z2 = q2\n\n        w = w1*w2 - x1*x2 - y1*y2 - z1*z2\n        x = w1*x2 + x1*w2 + y1*z2 - z1*y2\n        y = w1*y2 - x1*z2 + y1*w2 + z1*x2\n        z = w1*z2 + x1*y2 - y1*x2 + z1*w2\n\n        return np.array([w, x, y, z])\n\n    def shutdown(self):\n        """Clean up resources."""\n        self.collision_pool.shutdown(wait=True)\n        self.constraint_pool.shutdown(wait=True)\n        self.integration_pool.shutdown(wait=True)\n\n# Real-time simulation loop\ndef run_realtime_simulation():\n    """Run a real-time physics simulation loop."""\n    simulator = RealtimePhysicsSimulator(target_frequency=1000)\n\n    # Initialize humanoid state\n    bodies_state = initialize_humanoid_state()\n\n    # Timing control\n    import time\n    next_frame_time = time.time()\n\n    for frame in range(10000):  # Run for 10 seconds at 1kHz\n        current_time = time.time()\n\n        if current_time < next_frame_time:\n            # Sleep to maintain timing\n            time.sleep(next_frame_time - current_time)\n\n        # Perform physics simulation\n        bodies_state, collisions = simulator.simulate_frame(bodies_state, [])\n\n        # Update timing\n        next_frame_time += simulator.dt\n\n        if frame % 1000 == 0:\n            print(f"Frame {frame}, real-time factor: {(time.time() - current_time) / simulator.dt:.2f}x")\n\ndef initialize_humanoid_state():\n    """Initialize a humanoid robot state for simulation."""\n    # Placeholder for humanoid initialization\n    return []\n'})}),"\n",(0,o.jsx)(e.h3,{id:"isaac-sim-performance-tuning",children:"Isaac Sim Performance Tuning"}),"\n",(0,o.jsx)(e.p,{children:"For optimal performance in Isaac Sim, specific configurations are required:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-json",children:'{\n  "isaac_sim_physics_config": {\n    "physics_properties": {\n      "solver_type": "TGS",\n      "solver_position_iteration_count": 8,\n      "solver_velocity_iteration_count": 1,\n      "sleep_threshold": 0.005,\n      "stabilization_threshold": 0.0,\n      "max_depenetration_velocity": 100.0,\n      "use_enhanced_determinism": false,\n      "gpu_max_particles": 1048576,\n      "gpu_max_particle_contacts": 1048576\n    },\n    "scene_properties": {\n      "gravity": [0.0, 0.0, -9.81],\n      "enable_gpu_physics": true,\n      "broadphase_type": "MBP",\n      "collision_stack_size": 64000000,\n      "use_gpu_dynamic_scene": true,\n      "gpu_max_rigid_contact_count": 524288,\n      "gpu_max_rigid_patch_count": 33554432,\n      "gpu_found_lost_pairs_capacity": 1048576,\n      "gpu_found_lost_aggregate_pairs_capacity": 1048576,\n      "gpu_total_aggregate_pairs_capacity": 1048576\n    },\n    "humanoid_robot_properties": {\n      "enable_character_controller": false,\n      "max_angular_speed": 50.0,\n      "solver_batch_size": 32,\n      "enable_ccd": true,\n      "ccd_threshold": 0.05,\n      "ccd_max_passes": 2,\n      "solver_frequency": 240,\n      "use_fabric": true,\n      "enable_kinematic_pairs": true,\n      "enable_gpu_feedback": true,\n      "gpu_feedback_mode": "all"\n    },\n    "optimization_settings": {\n      "max_linear_velocity": 100.0,\n      "max_angular_velocity": 50.0,\n      "max_depenetration_velocity": 100.0,\n      "bounce_threshold_velocity": 2.0,\n      "friction_correlation_model": "patch",\n      "gpu_sim_frame_timeout": 2000,\n      "thread_count": 4,\n      "enable_pcm": true,\n      "pcm_max_pairs": 1048576\n    }\n  }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"advanced-contact-modeling-for-humanoid-locomotion",children:"Advanced Contact Modeling for Humanoid Locomotion"}),"\n",(0,o.jsx)(e.p,{children:"For humanoid robots, special attention must be paid to foot-ground contact modeling, which is critical for stable locomotion:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"import numpy as np\nfrom scipy.spatial import ConvexHull\nfrom typing import List, Tuple\n\nclass FootContactModel:\n    \"\"\"Advanced foot contact model for humanoid locomotion.\"\"\"\n\n    def __init__(self, foot_geometry: dict):\n        self.foot_geometry = foot_geometry\n        self.contact_points = self._generate_contact_points(foot_geometry)\n        self.pressure_distribution = self._calculate_pressure_distribution()\n\n    def _generate_contact_points(self, geometry: dict) -> np.ndarray:\n        \"\"\"Generate contact points based on foot geometry.\"\"\"\n        if geometry['type'] == 'rectangular':\n            # Generate points along the perimeter and center\n            length = geometry['length']\n            width = geometry['width']\n\n            # Perimeter points\n            points = []\n            # Front edge\n            for i in range(5):\n                x = -length/2 + i * length/4\n                points.append([x, width/2, 0])\n\n            # Back edge\n            for i in range(5):\n                x = -length/2 + i * length/4\n                points.append([x, -width/2, 0])\n\n            # Side edges (excluding corners already covered)\n            for i in range(3):\n                y = -width/2 + (i+1) * width/4\n                points.append([length/2, y, 0])\n                points.append([-length/2, y, 0])\n\n            # Center point\n            points.append([0, 0, 0])\n\n            return np.array(points)\n\n        elif geometry['type'] == 'elliptical':\n            # Generate points in elliptical pattern\n            a = geometry['semi_major_axis']\n            b = geometry['semi_minor_axis']\n\n            points = []\n            # Create grid and keep only points inside ellipse\n            for x in np.linspace(-a, a, 7):\n                for y in np.linspace(-b, b, 5):\n                    if (x**2)/(a**2) + (y**2)/(b**2) <= 1:\n                        points.append([x, y, 0])\n\n            return np.array(points)\n\n    def _calculate_pressure_distribution(self) -> np.ndarray:\n        \"\"\"Calculate default pressure distribution across contact points.\"\"\"\n        # For a foot, pressure is typically higher at heel and forefoot\n        n_points = len(self.contact_points)\n        pressures = np.zeros(n_points)\n\n        for i, point in enumerate(self.contact_points):\n            x, y, z = point\n\n            # Pressure based on position (heuristic model)\n            if x < -0.1:  # Heel area\n                pressures[i] = 0.8\n            elif x > 0.1:  # Toe area\n                pressures[i] = 0.6\n            else:  # Arch area\n                pressures[i] = 0.3\n\n        # Normalize\n        pressures = pressures / np.sum(pressures)\n        return pressures\n\n    def calculate_contact_forces(self, foot_pose: dict, ground_normal: np.ndarray,\n                                total_force: float) -> List[Tuple[np.ndarray, float]]:\n        \"\"\"Calculate distributed contact forces based on foot pose and loading.\"\"\"\n        contact_forces = []\n\n        # Transform contact points to world coordinates\n        world_points = self._transform_to_world(self.contact_points, foot_pose)\n\n        # Calculate pressure at each point based on orientation\n        for i, (world_point, pressure) in enumerate(zip(world_points, self.pressure_distribution)):\n            # Adjust pressure based on local ground contact\n            local_normal = self._adjust_normal_for_local_geometry(world_point, ground_normal)\n\n            # Calculate force magnitude based on pressure and total load\n            force_magnitude = total_force * pressure\n\n            # Apply force in direction of adjusted normal\n            force_vector = force_magnitude * local_normal\n            contact_forces.append((world_point, force_vector))\n\n        return contact_forces\n\n    def _transform_to_world(self, local_points: np.ndarray, pose: dict) -> np.ndarray:\n        \"\"\"Transform points from local foot frame to world frame.\"\"\"\n        position = np.array(pose['position'])\n        orientation = np.array(pose['orientation'])  # Quaternion [w, x, y, z]\n\n        # Convert quaternion to rotation matrix\n        rotation_matrix = self._quaternion_to_rotation_matrix(orientation)\n\n        # Transform points\n        world_points = []\n        for point in local_points:\n            world_point = position + rotation_matrix @ point\n            world_points.append(world_point)\n\n        return np.array(world_points)\n\n    def _quaternion_to_rotation_matrix(self, q: np.ndarray) -> np.ndarray:\n        \"\"\"Convert quaternion to rotation matrix.\"\"\"\n        w, x, y, z = q\n\n        # Normalize quaternion\n        norm = np.sqrt(w*w + x*x + y*y + z*z)\n        w, x, y, z = w/norm, x/norm, y/norm, z/norm\n\n        return np.array([\n            [1 - 2*(y*y + z*z), 2*(x*y - w*z), 2*(x*z + w*y)],\n            [2*(x*y + w*z), 1 - 2*(x*x + z*z), 2*(y*z - w*x)],\n            [2*(x*z - w*y), 2*(y*z + w*x), 1 - 2*(x*x + y*y)]\n        ])\n\n    def _adjust_normal_for_local_geometry(self, point: np.ndarray, ground_normal: np.ndarray) -> np.ndarray:\n        \"\"\"Adjust contact normal based on local foot geometry.\"\"\"\n        # For now, return ground normal; in a full implementation,\n        # this would consider the local surface normal of the foot\n        return ground_normal\n\nclass AdvancedLocomotionPhysics:\n    \"\"\"Physics system for advanced humanoid locomotion.\"\"\"\n\n    def __init__(self, robot_mass: float = 80.0):\n        self.robot_mass = robot_mass\n        self.gravity = 9.81\n        self.total_weight = robot_mass * self.gravity\n\n        # Initialize foot contact models\n        self.left_foot_model = FootContactModel({\n            'type': 'rectangular',\n            'length': 0.25,\n            'width': 0.10\n        })\n\n        self.right_foot_model = FootContactModel({\n            'type': 'rectangular',\n            'length': 0.25,\n            'width': 0.10\n        })\n\n    def calculate_ground_reactions(self, robot_state: dict) -> dict:\n        \"\"\"Calculate ground reaction forces for both feet.\"\"\"\n        left_foot_pose = robot_state.get('left_foot_pose', {'position': [0,0,0], 'orientation': [1,0,0,0]})\n        right_foot_pose = robot_state.get('right_foot_pose', {'position': [0,0,0], 'orientation': [1,0,0,0]})\n\n        # Determine weight distribution based on center of mass position\n        com_position = np.array(robot_state.get('com_position', [0,0,0]))\n        left_foot_pos = np.array(left_foot_pose['position'])\n        right_foot_pos = np.array(right_foot_pose['position'])\n\n        # Simple weight distribution based on distance to each foot\n        dist_to_left = np.linalg.norm(com_position[:2] - left_foot_pos[:2])\n        dist_to_right = np.linalg.norm(com_position[:2] - right_foot_pos[:2])\n\n        # Weight distribution (inverse to distance, normalized)\n        left_weight_ratio = dist_to_right / (dist_to_left + dist_to_right)\n        right_weight_ratio = dist_to_left / (dist_to_left + dist_to_right)\n\n        left_force = self.total_weight * left_weight_ratio\n        right_force = self.total_weight * right_weight_ratio\n\n        # Calculate contact forces for each foot\n        left_contacts = self.left_foot_model.calculate_contact_forces(\n            left_foot_pose, np.array([0, 0, 1]), left_force\n        )\n\n        right_contacts = self.right_foot_model.calculate_contact_forces(\n            right_foot_pose, np.array([0, 0, 1]), right_force\n        )\n\n        return {\n            'left_foot_contacts': left_contacts,\n            'right_foot_contacts': right_contacts,\n            'total_left_force': left_force,\n            'total_right_force': right_force\n        }\n\n    def update_balance_control(self, robot_state: dict) -> dict:\n        \"\"\"Update balance control based on physics calculations.\"\"\"\n        ground_reactions = self.calculate_ground_reactions(robot_state)\n\n        # Calculate center of pressure\n        cop_left = self._calculate_center_of_pressure(ground_reactions['left_foot_contacts'])\n        cop_right = self._calculate_center_of_pressure(ground_reactions['right_foot_contacts'])\n\n        # Calculate zero moment point (ZMP)\n        zmp = self._calculate_zmp(robot_state, ground_reactions)\n\n        return {\n            'center_of_pressure': {'left': cop_left, 'right': cop_right},\n            'zero_moment_point': zmp,\n            'ground_reactions': ground_reactions\n        }\n\n    def _calculate_center_of_pressure(self, contacts: List[Tuple[np.ndarray, float]]) -> np.ndarray:\n        \"\"\"Calculate center of pressure from contact forces.\"\"\"\n        if not contacts:\n            return np.array([0, 0, 0])\n\n        total_force = np.array([0.0, 0.0, 0.0])\n        moment = np.array([0.0, 0.0, 0.0])\n\n        for point, force in contacts:\n            total_force += force\n            moment += np.cross(point[:3], force)  # Only use first 3 components (position)\n\n        if abs(total_force[2]) > 1e-6:  # Avoid division by zero\n            cop_x = moment[1] / total_force[2]  # M_y / F_z\n            cop_y = -moment[0] / total_force[2]  # -M_x / F_z\n            return np.array([cop_x, cop_y, 0])\n        else:\n            return np.array([0, 0, 0])\n\n    def _calculate_zmp(self, robot_state: dict, ground_reactions: dict) -> np.ndarray:\n        \"\"\"Calculate Zero Moment Point for balance control.\"\"\"\n        # Simplified ZMP calculation\n        # ZMP = (\u03a3(Fi * xi) + \u03a3(Ti)) / \u03a3(Fi_z)\n        # where Fi is force at contact i, xi is position, Ti is torque\n\n        all_contacts = (\n            ground_reactions['left_foot_contacts'] +\n            ground_reactions['right_foot_contacts']\n        )\n\n        if not all_contacts:\n            return np.array([0, 0, 0])\n\n        total_moment_x = 0.0\n        total_moment_y = 0.0\n        total_force_z = 0.0\n\n        com_height = robot_state.get('com_position', [0, 0, 0.8])[2]\n\n        for point, force in all_contacts:\n            # Moments about x and y axes\n            total_moment_x += point[1] * force[2] - point[2] * force[1]  # y*Fz - z*Fy\n            total_moment_y += point[2] * force[0] - point[0] * force[2]  # z*Fx - x*Fz\n            total_force_z += force[2]  # Fz\n\n        if abs(total_force_z) > 1e-6:\n            zmp_x = -total_moment_y / total_force_z\n            zmp_y = total_moment_x / total_force_z\n            return np.array([zmp_x, zmp_y, 0])\n        else:\n            return np.array([0, 0, 0])\n\n# Example usage\ndef example_locomotion_physics():\n    \"\"\"Example of advanced locomotion physics in action.\"\"\"\n    locomotion_physics = AdvancedLocomotionPhysics(robot_mass=80.0)\n\n    # Sample robot state\n    robot_state = {\n        'com_position': [0.0, 0.0, 0.85],  # Center of mass at 85cm height\n        'left_foot_pose': {\n            'position': [-0.1, 0.1, 0.0],\n            'orientation': [1.0, 0.0, 0.0, 0.0]\n        },\n        'right_foot_pose': {\n            'position': [0.1, -0.1, 0.0],\n            'orientation': [1.0, 0.0, 0.0, 0.0]\n        }\n    }\n\n    balance_info = locomotion_physics.update_balance_control(robot_state)\n\n    print(\"Balance Control Information:\")\n    print(f\"Center of Pressure (Left): {balance_info['center_of_pressure']['left']}\")\n    print(f\"Center of Pressure (Right): {balance_info['center_of_pressure']['right']}\")\n    print(f\"Zero Moment Point: {balance_info['zero_moment_point']}\")\n    print(f\"Total Left Force: {balance_info['ground_reactions']['total_left_force']:.2f}N\")\n    print(f\"Total Right Force: {balance_info['ground_reactions']['total_right_force']:.2f}N\")\n\nif __name__ == \"__main__\":\n    example_locomotion_physics()\n"})}),"\n",(0,o.jsx)(e.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,o.jsx)(e.p,{children:"Physics simulation for humanoid robots in digital twin environments requires sophisticated implementations that balance computational efficiency with physical accuracy. The systems described in this chapter provide the foundation for realistic simulation of humanoid robot dynamics, including collision detection, contact resolution, and real-time performance optimization. Proper implementation of these physics systems enables safe and effective development of humanoid robot control algorithms in simulation before deployment on physical hardware."})]})}function d(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(_,{...n})}):_(n)}},8453(n,e,i){i.d(e,{R:()=>a,x:()=>r});var t=i(6540);const o={},s=t.createContext(o);function a(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:a(n.components),t.createElement(s.Provider,{value:e},n.children)}}}]);